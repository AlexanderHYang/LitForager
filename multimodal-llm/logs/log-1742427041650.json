[
  {
    "timestamp": 64,
    "eventType": "Socket connected",
    "eventData": "{\n  \"socketId\": \"HtmEB0tHOw0kIxbKAAAB\"\n}"
  },
  {
    "timestamp": 1341,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0,\n      \"y\": 0,\n      \"z\": 0,\n      \"index\": 0\n    }\n  ]\n}"
  },
  {
    "timestamp": 1348,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0,\n      \"y\": 0,\n      \"z\": 0,\n      \"index\": 0\n    }\n  ]\n}"
  },
  {
    "timestamp": 2193,
    "eventType": "clearNodeSelection() called",
    "eventData": "{\n  \"selectedIds\": []\n}"
  },
  {
    "timestamp": 4758,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  }\n}"
  },
  {
    "timestamp": 4758,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n    \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n    \"x\": 0,\n    \"y\": 0,\n    \"z\": 0,\n    \"index\": 0\n  }\n}"
  },
  {
    "timestamp": 4758,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 4778,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  }\n}"
  },
  {
    "timestamp": 4778,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 4778,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 4778,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 5020,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  }\n}"
  },
  {
    "timestamp": 5020,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n    \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n    \"x\": 0,\n    \"y\": 0,\n    \"z\": 0,\n    \"index\": 0\n  }\n}"
  },
  {
    "timestamp": 5020,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 5233,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  }\n}"
  },
  {
    "timestamp": 5235,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  }\n}"
  },
  {
    "timestamp": 5330,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  }\n}"
  },
  {
    "timestamp": 5331,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  }\n}"
  },
  {
    "timestamp": 5331,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  }\n}"
  },
  {
    "timestamp": 5466,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  }\n}"
  },
  {
    "timestamp": 5466,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 5466,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 5466,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 5990,
    "eventType": "addRecommendationsFromSelectedPapers() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n  ]\n}"
  },
  {
    "timestamp": 10778,
    "eventType": "addPapersToGraph() called",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\"\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\"\n    }\n  ],\n  \"prevPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0,\n      \"y\": 0,\n      \"z\": 0,\n      \"index\": 0\n    }\n  ]\n}"
  },
  {
    "timestamp": 10778,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.2,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.058411139008582795,\n      \"_y\": -0.10482432370265984,\n      \"_z\": 0.16000000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.1557299959937127,\n      \"_y\": 0.09668592631711312,\n      \"_z\": 0.08000000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.11339873726534194,\n      \"_y\": 0.16474442748277088,\n      \"_z\": 1.2246467991473533e-17\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.1459146700678658,\n      \"_y\": -0.11094552293349141,\n      \"_z\": -0.08\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.07706050711183576,\n      \"_y\": -0.0919873808936134,\n      \"_z\": -0.16000000000000003\n    }\n  ]\n}"
  },
  {
    "timestamp": 10778,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0,\n      \"y\": 0,\n      \"z\": 0,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.058411139008582795,\n      \"y\": -0.10482432370265984,\n      \"z\": 0.16000000000000003,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.1557299959937127,\n      \"y\": 0.09668592631711312,\n      \"z\": 0.08000000000000002,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.11339873726534194,\n      \"y\": 0.16474442748277088,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.1459146700678658,\n      \"y\": -0.11094552293349141,\n      \"z\": -0.08,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07706050711183576,\n      \"y\": -0.0919873808936134,\n      \"z\": -0.16000000000000003,\n      \"index\": 5\n    }\n  ]\n}"
  },
  {
    "timestamp": 10790,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0,\n      \"y\": 0,\n      \"z\": 0,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.058411139008582795,\n      \"y\": -0.10482432370265984,\n      \"z\": 0.16000000000000003,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.1557299959937127,\n      \"y\": 0.09668592631711312,\n      \"z\": 0.08000000000000002,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.11339873726534194,\n      \"y\": 0.16474442748277088,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.1459146700678658,\n      \"y\": -0.11094552293349141,\n      \"z\": -0.08,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07706050711183576,\n      \"y\": -0.0919873808936134,\n      \"z\": -0.16000000000000003,\n      \"index\": 5\n    }\n  ]\n}"
  },
  {
    "timestamp": 10791,
    "eventType": "generateLinkData() finished",
    "eventData": "{\n  \"newLinkData\": {\n    \"citationLinkData\": [\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n      }\n    ],\n    \"recommendationLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      }\n    ],\n    \"authorLinkData\": [],\n    \"userLinkData\": []\n  }\n}"
  },
  {
    "timestamp": 10791,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 10793,
    "eventType": "addPapersToGraph() finished",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.058411139008582795,\n      \"y\": -0.10482432370265984,\n      \"z\": 0.16000000000000003,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.1557299959937127,\n      \"y\": 0.09668592631711312,\n      \"z\": 0.08000000000000002,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.11339873726534194,\n      \"y\": 0.16474442748277088,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.1459146700678658,\n      \"y\": -0.11094552293349141,\n      \"z\": -0.08,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07706050711183576,\n      \"y\": -0.0919873808936134,\n      \"z\": -0.16000000000000003,\n      \"index\": 5\n    }\n  ],\n  \"currPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0,\n      \"y\": 0,\n      \"z\": 0,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.058411139008582795,\n      \"y\": -0.10482432370265984,\n      \"z\": 0.16000000000000003,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.1557299959937127,\n      \"y\": 0.09668592631711312,\n      \"z\": 0.08000000000000002,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.11339873726534194,\n      \"y\": 0.16474442748277088,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.1459146700678658,\n      \"y\": -0.11094552293349141,\n      \"z\": -0.08,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07706050711183576,\n      \"y\": -0.0919873808936134,\n      \"z\": -0.16000000000000003,\n      \"index\": 5\n    }\n  ]\n}"
  },
  {
    "timestamp": 10793,
    "eventType": "setLinkType() called",
    "eventData": "{\n  \"currLinkType\": \"recommendation\",\n  \"newLinkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 10793,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type recommendation\"\n}"
  },
  {
    "timestamp": 10793,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 11552,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.017675033391726252,\n    \"_y\": -0.060200195783257415,\n    \"_z\": 0.09800950321132258\n  }\n}"
  },
  {
    "timestamp": 11552,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n    \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n    \"x\": 0.017675033391726252,\n    \"y\": -0.060200195783257415,\n    \"z\": 0.09800950321132258,\n    \"index\": 1\n  }\n}"
  },
  {
    "timestamp": 11552,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 11563,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.017675033391726252,\n    \"_y\": -0.060200195783257415,\n    \"_z\": 0.09800950321132258\n  }\n}"
  },
  {
    "timestamp": 11563,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 11563,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 11563,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 12152,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.09491425920429389,\n    \"_y\": 0.06225411523965695,\n    \"_z\": 0.03458614265913876\n  }\n}"
  },
  {
    "timestamp": 12152,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n    \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n    \"x\": 0.09491425920429389,\n    \"y\": 0.06225411523965695,\n    \"z\": 0.03458614265913876,\n    \"index\": 2\n  }\n}"
  },
  {
    "timestamp": 12152,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 12280,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.09490980039131389,\n    \"_y\": 0.06226434312277203,\n    \"_z\": 0.034458438342853004\n  }\n}"
  },
  {
    "timestamp": 12281,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.09490980039131389,\n    \"_y\": 0.06226434312277203,\n    \"_z\": 0.034458438342853004\n  }\n}"
  },
  {
    "timestamp": 12346,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.09490625918837796,\n    \"_y\": 0.06226849146986413,\n    \"_z\": 0.034396194861631826\n  }\n}"
  },
  {
    "timestamp": 12347,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.09490625918837796,\n    \"_y\": 0.06226849146986413,\n    \"_z\": 0.034396194861631826\n  }\n}"
  },
  {
    "timestamp": 12347,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.09490625918837796,\n    \"_y\": 0.06226849146986413,\n    \"_z\": 0.034396194861631826\n  }\n}"
  },
  {
    "timestamp": 12535,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.0948952039580824,\n    \"_y\": 0.06227708814478018,\n    \"_z\": 0.034246066305090514\n  }\n}"
  },
  {
    "timestamp": 12535,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 12535,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 12535,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 13631,
    "eventType": "addRecommendationsFromSelectedPapers() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n  ]\n}"
  },
  {
    "timestamp": 17696,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.000537784852928818,\n    \"_y\": -0.00023014450681463415,\n    \"_z\": 0.00014164965515853675\n  }\n}"
  },
  {
    "timestamp": 17696,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n    \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n    \"x\": -0.000537784852928818,\n    \"y\": -0.00023014450681463415,\n    \"z\": 0.00014164965515853675,\n    \"index\": 0\n  }\n}"
  },
  {
    "timestamp": 17697,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 17928,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0005377626658679468,\n    \"_y\": -0.0002302558048486481,\n    \"_z\": 0.00014167249481540574\n  }\n}"
  },
  {
    "timestamp": 17929,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0005377626658679468,\n    \"_y\": -0.0002302558048486481,\n    \"_z\": 0.00014167249481540574\n  }\n}"
  },
  {
    "timestamp": 18079,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0005377517502864708,\n    \"_y\": -0.00023031056724923,\n    \"_z\": 0.00014168373283877312\n  }\n}"
  },
  {
    "timestamp": 18082,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0009351559092978694,\n    \"_y\": -0.00023028502125849794,\n    \"_z\": 0.00014140757882646156\n  }\n}"
  },
  {
    "timestamp": 18095,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0009351559092978694,\n    \"_y\": -0.00023028502125849794,\n    \"_z\": 0.00014140757882646156\n  }\n}"
  },
  {
    "timestamp": 18098,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0031208342516551475,\n    \"_y\": -0.00023025748903488587,\n    \"_z\": 0.00013685008632396219\n  }\n}"
  },
  {
    "timestamp": 18112,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0031208342516551475,\n    \"_y\": -0.00023025748903488587,\n    \"_z\": 0.00013685008632396219\n  }\n}"
  },
  {
    "timestamp": 18112,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0031208342516551475,\n    \"_y\": -0.00023025748903488587,\n    \"_z\": 0.00013685008632396219\n  }\n}"
  },
  {
    "timestamp": 18114,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.01017405384851049,\n    \"_y\": -0.00023014103733327087,\n    \"_z\": 0.00008983996046967675\n  }\n}"
  },
  {
    "timestamp": 18129,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.01017405384851049,\n    \"_y\": -0.00023014103733327087,\n    \"_z\": 0.00008983996046967675\n  }\n}"
  },
  {
    "timestamp": 18130,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.024027315561449037,\n    \"_y\": -0.00022966943886454995,\n    \"_z\": -0.0001234079162028631\n  }\n}"
  },
  {
    "timestamp": 18145,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.024027315561449037,\n    \"_y\": -0.00022966943886454995,\n    \"_z\": -0.0001234079162028631\n  }\n}"
  },
  {
    "timestamp": 18148,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.04245893530247162,\n    \"_y\": -0.00022862139537788774,\n    \"_z\": -0.0006090022496433942\n  }\n}"
  },
  {
    "timestamp": 18162,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.04245893530247162,\n    \"_y\": -0.00022862139537788774,\n    \"_z\": -0.0006090022496433942\n  }\n}"
  },
  {
    "timestamp": 18165,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.06276247895953606,\n    \"_y\": -0.00022696326284527625,\n    \"_z\": -0.001384410627747142\n  }\n}"
  },
  {
    "timestamp": 18178,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.06276247895953606,\n    \"_y\": -0.00022696326284527625,\n    \"_z\": -0.001384410627747142\n  }\n}"
  },
  {
    "timestamp": 18181,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.08239643148777435,\n    \"_y\": -0.0002248902406575888,\n    \"_z\": -0.0023582496495006618\n  }\n}"
  },
  {
    "timestamp": 18195,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.08239643148777435,\n    \"_y\": -0.0002248902406575888,\n    \"_z\": -0.0023582496495006618\n  }\n}"
  },
  {
    "timestamp": 18198,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.10088371731040428,\n    \"_y\": 0.0013619716968820631,\n    \"_z\": -0.003488147775737756\n  }\n}"
  },
  {
    "timestamp": 18211,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10088371731040428,\n    \"_y\": 0.0013619716968820631,\n    \"_z\": -0.003488147775737756\n  }\n}"
  },
  {
    "timestamp": 18215,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.11877243838903855,\n    \"_y\": 0.005321113368539626,\n    \"_z\": -0.004806534182375484\n  }\n}"
  },
  {
    "timestamp": 18230,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11877243838903855,\n    \"_y\": 0.005321113368539626,\n    \"_z\": -0.004806534182375484\n  }\n}"
  },
  {
    "timestamp": 18232,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.13398516423699808,\n    \"_y\": 0.010461077069907003,\n    \"_z\": -0.006092052701955848\n  }\n}"
  },
  {
    "timestamp": 18246,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.13398516423699808,\n    \"_y\": 0.010461077069907003,\n    \"_z\": -0.006092052701955848\n  }\n}"
  },
  {
    "timestamp": 18248,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.14627945668694925,\n    \"_y\": 0.016582492714791112,\n    \"_z\": -0.007263875827288442\n  }\n}"
  },
  {
    "timestamp": 18262,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.14627945668694925,\n    \"_y\": 0.016582492714791112,\n    \"_z\": -0.007263875827288442\n  }\n}"
  },
  {
    "timestamp": 18265,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.15632288403508615,\n    \"_y\": 0.023190357698170953,\n    \"_z\": -0.008336783880463057\n  }\n}"
  },
  {
    "timestamp": 18278,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.15632288403508615,\n    \"_y\": 0.023190357698170953,\n    \"_z\": -0.008336783880463057\n  }\n}"
  },
  {
    "timestamp": 18282,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.16445505119559717,\n    \"_y\": 0.02924921826836329,\n    \"_z\": -0.00928717994140666\n  }\n}"
  },
  {
    "timestamp": 18295,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.16445505119559717,\n    \"_y\": 0.02924921826836329,\n    \"_z\": -0.00928717994140666\n  }\n}"
  },
  {
    "timestamp": 18298,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17046125478742075,\n    \"_y\": 0.03424504862543803,\n    \"_z\": -0.010038904873749428\n  }\n}"
  },
  {
    "timestamp": 18312,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17046125478742075,\n    \"_y\": 0.03424504862543803,\n    \"_z\": -0.010038904873749428\n  }\n}"
  },
  {
    "timestamp": 18312,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n    \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n    \"x\": -0.17046125478742075,\n    \"y\": 0.03424504862543803,\n    \"z\": -0.010038904873749428,\n    \"index\": 0\n  }\n}"
  },
  {
    "timestamp": 18312,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 18313,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17046125478742075,\n    \"_y\": 0.03424504862543803,\n    \"_z\": -0.010038904873749428\n  }\n}"
  },
  {
    "timestamp": 18315,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17423836387393427,\n    \"_y\": 0.03792319351252776,\n    \"_z\": -0.01053890588702839\n  }\n}"
  },
  {
    "timestamp": 18332,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17612691469190073,\n    \"_y\": 0.03976226502475005,\n    \"_z\": -0.01078890639366787\n  }\n}"
  },
  {
    "timestamp": 18348,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17707119382617426,\n    \"_y\": 0.04068180078086119,\n    \"_z\": -0.01091390664698761\n  }\n}"
  },
  {
    "timestamp": 18365,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17754332966802072,\n    \"_y\": 0.041141568658916765,\n    \"_z\": -0.01097640677364748\n  }\n}"
  },
  {
    "timestamp": 18382,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17777940131423425,\n    \"_y\": 0.04137145259794455,\n    \"_z\": -0.011007656836977416\n  }\n}"
  },
  {
    "timestamp": 18398,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 18413,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 18413,
    "eventType": "node onPickUpTrigger - node is already being dragged",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 18414,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 18557,
    "eventType": "addPapersToGraph() called",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\"\n    }\n  ],\n  \"prevPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.11276853790330046,\n      \"y\": -0.022518048285781102,\n      \"z\": 0.0684062254936319,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": -0.06283390780422683,\n      \"y\": 0.05679360462252261,\n      \"z\": 0.01579294117353907,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.12149235679980049,\n      \"y\": 0.1425740280468134,\n      \"z\": 0.0008507083985970703,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.17021638210556103,\n      \"y\": -0.0674009831083447,\n      \"z\": -0.05281088083056544,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.08329800282324325,\n      \"y\": 0.0012497907050303364,\n      \"z\": -0.07562006816286163,\n      \"index\": 5\n    }\n  ]\n}"
  },
  {
    "timestamp": 18557,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.2,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.11340592467060398,\n      \"_y\": -0.039231317204566206,\n      \"_z\": 0.16000000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.06803993576881462,\n      \"_y\": -0.1702074238703341,\n      \"_z\": 0.08000000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.1819988559103192,\n      \"_y\": 0.08292416081779107,\n      \"_z\": 1.2246467991473533e-17\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.08379300438289508,\n      \"_y\": 0.16302985130487033,\n      \"_z\": -0.08\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.10401875920847585,\n      \"_y\": -0.05983391791224372,\n      \"_z\": -0.16000000000000003\n    }\n  ]\n}"
  },
  {
    "timestamp": 18557,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.11276853790330046,\n      \"y\": -0.022518048285781102,\n      \"z\": 0.0684062254936319,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": -0.06283390780422683,\n      \"y\": 0.05679360462252261,\n      \"z\": 0.01579294117353907,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.12149235679980049,\n      \"y\": 0.1425740280468134,\n      \"z\": 0.0008507083985970703,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.17021638210556103,\n      \"y\": -0.0674009831083447,\n      \"z\": -0.05281088083056544,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.08329800282324325,\n      \"y\": 0.0012497907050303364,\n      \"z\": -0.07562006816286163,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.11340592467060398,\n      \"y\": -0.039231317204566206,\n      \"z\": 0.16000000000000003,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.06803993576881462,\n      \"y\": -0.1702074238703341,\n      \"z\": 0.08000000000000002,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.1819988559103192,\n      \"y\": 0.08292416081779107,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.08379300438289508,\n      \"y\": 0.16302985130487033,\n      \"z\": -0.08,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.10401875920847585,\n      \"y\": -0.05983391791224372,\n      \"z\": -0.16000000000000003,\n      \"index\": 10\n    }\n  ]\n}"
  },
  {
    "timestamp": 18571,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.11276853790330046,\n      \"y\": -0.022518048285781102,\n      \"z\": 0.0684062254936319,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": -0.06283390780422683,\n      \"y\": 0.05679360462252261,\n      \"z\": 0.01579294117353907,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.12149235679980049,\n      \"y\": 0.1425740280468134,\n      \"z\": 0.0008507083985970703,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.17021638210556103,\n      \"y\": -0.0674009831083447,\n      \"z\": -0.05281088083056544,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.08329800282324325,\n      \"y\": 0.0012497907050303364,\n      \"z\": -0.07562006816286163,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.11340592467060398,\n      \"y\": -0.039231317204566206,\n      \"z\": 0.16000000000000003,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.06803993576881462,\n      \"y\": -0.1702074238703341,\n      \"z\": 0.08000000000000002,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.1819988559103192,\n      \"y\": 0.08292416081779107,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.08379300438289508,\n      \"y\": 0.16302985130487033,\n      \"z\": -0.08,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.10401875920847585,\n      \"y\": -0.05983391791224372,\n      \"z\": -0.16000000000000003,\n      \"index\": 10\n    }\n  ]\n}"
  },
  {
    "timestamp": 18573,
    "eventType": "generateLinkData() finished",
    "eventData": "{\n  \"newLinkData\": {\n    \"citationLinkData\": [\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n      }\n    ],\n    \"recommendationLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      }\n    ],\n    \"authorLinkData\": [\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      }\n    ],\n    \"userLinkData\": []\n  }\n}"
  },
  {
    "timestamp": 18573,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 18574,
    "eventType": "addPapersToGraph() finished",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.11340592467060398,\n      \"y\": -0.039231317204566206,\n      \"z\": 0.16000000000000003,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.06803993576881462,\n      \"y\": -0.1702074238703341,\n      \"z\": 0.08000000000000002,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.1819988559103192,\n      \"y\": 0.08292416081779107,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.08379300438289508,\n      \"y\": 0.16302985130487033,\n      \"z\": -0.08,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.10401875920847585,\n      \"y\": -0.05983391791224372,\n      \"z\": -0.16000000000000003,\n      \"index\": 10\n    }\n  ],\n  \"currPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.11276853790330046,\n      \"y\": -0.022518048285781102,\n      \"z\": 0.0684062254936319,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": -0.06283390780422683,\n      \"y\": 0.05679360462252261,\n      \"z\": 0.01579294117353907,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.12149235679980049,\n      \"y\": 0.1425740280468134,\n      \"z\": 0.0008507083985970703,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.17021638210556103,\n      \"y\": -0.0674009831083447,\n      \"z\": -0.05281088083056544,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.08329800282324325,\n      \"y\": 0.0012497907050303364,\n      \"z\": -0.07562006816286163,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.11340592467060398,\n      \"y\": -0.039231317204566206,\n      \"z\": 0.16000000000000003,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.06803993576881462,\n      \"y\": -0.1702074238703341,\n      \"z\": 0.08000000000000002,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.1819988559103192,\n      \"y\": 0.08292416081779107,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.08379300438289508,\n      \"y\": 0.16302985130487033,\n      \"z\": -0.08,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.10401875920847585,\n      \"y\": -0.05983391791224372,\n      \"z\": -0.16000000000000003,\n      \"index\": 10\n    }\n  ]\n}"
  },
  {
    "timestamp": 18574,
    "eventType": "setLinkType() called",
    "eventData": "{\n  \"currLinkType\": \"recommendation\",\n  \"newLinkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 18574,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type recommendation\"\n}"
  },
  {
    "timestamp": 18574,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 18632,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 18632,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n    \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n    \"x\": -0.17789743341205072,\n    \"y\": 0.041486394567458444,\n    \"z\": -0.01102328163581174,\n    \"index\": 0\n  }\n}"
  },
  {
    "timestamp": 18632,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 18643,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 18644,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 18644,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 18644,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 20683,
    "eventType": "changeLinkType() called",
    "eventData": "{\n  \"currentLinkType\": \"recommendation\",\n  \"newLinkType\": \"citation\"\n}"
  },
  {
    "timestamp": 20683,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type citation\"\n}"
  },
  {
    "timestamp": 20683,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"citation\"\n}"
  },
  {
    "timestamp": 20819,
    "eventType": "changeLinkType() called",
    "eventData": "{\n  \"currentLinkType\": \"citation\",\n  \"newLinkType\": \"author\"\n}"
  },
  {
    "timestamp": 20819,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type author\"\n}"
  },
  {
    "timestamp": 20819,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"author\"\n}"
  },
  {
    "timestamp": 20979,
    "eventType": "changeLinkType() called",
    "eventData": "{\n  \"currentLinkType\": \"author\",\n  \"newLinkType\": \"custom\"\n}"
  },
  {
    "timestamp": 20979,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type custom\"\n}"
  },
  {
    "timestamp": 20979,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 21081,
    "eventType": "changeLinkType() called",
    "eventData": "{\n  \"currentLinkType\": \"custom\",\n  \"newLinkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 21081,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type recommendation\"\n}"
  },
  {
    "timestamp": 21081,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 21233,
    "eventType": "changeLinkType() called",
    "eventData": "{\n  \"currentLinkType\": \"recommendation\",\n  \"newLinkType\": \"citation\"\n}"
  },
  {
    "timestamp": 21233,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type citation\"\n}"
  },
  {
    "timestamp": 21233,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"citation\"\n}"
  },
  {
    "timestamp": 21604,
    "eventType": "changeLinkType() called",
    "eventData": "{\n  \"currentLinkType\": \"citation\",\n  \"newLinkType\": \"author\"\n}"
  },
  {
    "timestamp": 21604,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type author\"\n}"
  },
  {
    "timestamp": 21604,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"author\"\n}"
  },
  {
    "timestamp": 22685,
    "eventType": "changeLinkType() called",
    "eventData": "{\n  \"currentLinkType\": \"author\",\n  \"newLinkType\": \"custom\"\n}"
  },
  {
    "timestamp": 22685,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type custom\"\n}"
  },
  {
    "timestamp": 22685,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 46222,
    "eventType": "clearNodeSelection() called",
    "eventData": "{\n  \"selectedIds\": []\n}"
  },
  {
    "timestamp": 55052,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.045183849529759214,\n    \"_y\": 0.09436818022836241,\n    \"_z\": 0.015677833893669457\n  }\n}"
  },
  {
    "timestamp": 55052,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n    \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n    \"x\": 0.045183849529759214,\n    \"y\": 0.09436818022836241,\n    \"z\": 0.015677833893669457,\n    \"index\": 8\n  }\n}"
  },
  {
    "timestamp": 55052,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 55247,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.045183849529759214,\n    \"_y\": 0.09436818022836241,\n    \"_z\": 0.015677833893669457\n  }\n}"
  },
  {
    "timestamp": 55247,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.045183849529759214,\n    \"_y\": 0.09436818022836241,\n    \"_z\": 0.015677833893669457\n  }\n}"
  },
  {
    "timestamp": 55345,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.045183849529759214,\n    \"_y\": 0.09436818022836241,\n    \"_z\": 0.015677833893669457\n  }\n}"
  },
  {
    "timestamp": 55345,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.045183849529759214,\n    \"_y\": 0.09436818022836241,\n    \"_z\": 0.015677833893669457\n  }\n}"
  },
  {
    "timestamp": 55346,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.045183849529759214,\n    \"_y\": 0.09436818022836241,\n    \"_z\": 0.015677833893669457\n  }\n}"
  },
  {
    "timestamp": 55568,
    "eventType": "addRecommendationsFromSelectedPapers() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n  ]\n}"
  },
  {
    "timestamp": 55929,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.045183849529759214,\n    \"_y\": 0.09436818022836241,\n    \"_z\": 0.015677833893669457\n  }\n}"
  },
  {
    "timestamp": 55929,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 55929,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 55929,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 58670,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17691116490150907,\n    \"_y\": 0.15413079335629698,\n    \"_z\": 0.03616189252803527\n  }\n}"
  },
  {
    "timestamp": 58670,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n    \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n    \"x\": -0.17691116490150907,\n    \"y\": 0.15413079335629698,\n    \"z\": 0.03616189252803527,\n    \"index\": 3\n  }\n}"
  },
  {
    "timestamp": 58670,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 58678,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17691116490150907,\n    \"_y\": 0.15413079335629698,\n    \"_z\": 0.03616189252803527\n  }\n}"
  },
  {
    "timestamp": 58678,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 58678,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 58678,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 59397,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0177794009833431,\n    \"_y\": 0.17602016279345528,\n    \"_z\": -0.014771898788081906\n  }\n}"
  },
  {
    "timestamp": 59397,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n    \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n    \"x\": -0.0177794009833431,\n    \"y\": 0.17602016279345528,\n    \"z\": -0.014771898788081906,\n    \"index\": 9\n  }\n}"
  },
  {
    "timestamp": 59397,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 60444,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0177794009833431,\n    \"_y\": 0.17602016279345528,\n    \"_z\": -0.014771898788081906\n  }\n}"
  },
  {
    "timestamp": 60444,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 60444,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 60444,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 62122,
    "eventType": "addPapersToGraph() called",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\"\n    }\n  ],\n  \"prevPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.17896648060872697,\n      \"y\": 0.04264951080425209,\n      \"z\": 0.10982179948134402,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": -0.07116143054451302,\n      \"y\": 0.05197906037438905,\n      \"z\": 0.03265315167733542,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.17691116490150907,\n      \"y\": 0.15413079335629698,\n      \"z\": 0.03616189252803527,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.14578769542553172,\n      \"y\": -0.07797908968428648,\n      \"z\": 0.0004158552999789052,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.12474050208516725,\n      \"y\": 0.06394788149148214,\n      \"z\": -0.12025103887599427,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.04777084008923937,\n      \"y\": 0.03903085613992762,\n      \"z\": 0.14718921362515985,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.026437940951640766,\n      \"y\": -0.03577518155896713,\n      \"z\": 0.04660240446529065,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.045183849529759214,\n      \"y\": 0.09436818022836241,\n      \"z\": 0.015677833893669457,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.0177794009833431,\n      \"y\": 0.17602016279345528,\n      \"z\": -0.014771898788081906,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.1055540281191906,\n      \"y\": -0.009031715521440577,\n      \"z\": -0.1019592369804594,\n      \"index\": 10\n    }\n  ]\n}"
  },
  {
    "timestamp": 62122,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.2,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.05466475590521753,\n      \"_y\": 0.10682586045440019,\n      \"_z\": 0.16000000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.1590542095799448,\n      \"_y\": -0.09111398583586935,\n      \"_z\": 0.08000000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.10749730136243406,\n      \"_y\": -0.16865446984824933,\n      \"_z\": 1.2246467991473533e-17\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.14974968755028245,\n      \"_y\": 0.1057120195559274,\n      \"_z\": -0.08\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.07375674789862151,\n      \"_y\": 0.09465697089712512,\n      \"_z\": -0.16000000000000003\n    }\n  ]\n}"
  },
  {
    "timestamp": 62123,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.17896648060872697,\n      \"y\": 0.04264951080425209,\n      \"z\": 0.10982179948134402,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": -0.07116143054451302,\n      \"y\": 0.05197906037438905,\n      \"z\": 0.03265315167733542,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.17691116490150907,\n      \"y\": 0.15413079335629698,\n      \"z\": 0.03616189252803527,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.14578769542553172,\n      \"y\": -0.07797908968428648,\n      \"z\": 0.0004158552999789052,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.12474050208516725,\n      \"y\": 0.06394788149148214,\n      \"z\": -0.12025103887599427,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.04777084008923937,\n      \"y\": 0.03903085613992762,\n      \"z\": 0.14718921362515985,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.026437940951640766,\n      \"y\": -0.03577518155896713,\n      \"z\": 0.04660240446529065,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.045183849529759214,\n      \"y\": 0.09436818022836241,\n      \"z\": 0.015677833893669457,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.0177794009833431,\n      \"y\": 0.17602016279345528,\n      \"z\": -0.014771898788081906,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.1055540281191906,\n      \"y\": -0.009031715521440577,\n      \"z\": -0.1019592369804594,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.05466475590521753,\n      \"y\": 0.10682586045440019,\n      \"z\": 0.16000000000000003,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.1590542095799448,\n      \"y\": -0.09111398583586935,\n      \"z\": 0.08000000000000002,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.10749730136243406,\n      \"y\": -0.16865446984824933,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.14974968755028245,\n      \"y\": 0.1057120195559274,\n      \"z\": -0.08,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.07375674789862151,\n      \"y\": 0.09465697089712512,\n      \"z\": -0.16000000000000003,\n      \"index\": 15\n    }\n  ]\n}"
  },
  {
    "timestamp": 62137,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.17896648060872697,\n      \"y\": 0.04264951080425209,\n      \"z\": 0.10982179948134402,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": -0.07116143054451302,\n      \"y\": 0.05197906037438905,\n      \"z\": 0.03265315167733542,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.17691116490150907,\n      \"y\": 0.15413079335629698,\n      \"z\": 0.03616189252803527,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.14578769542553172,\n      \"y\": -0.07797908968428648,\n      \"z\": 0.0004158552999789052,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.12474050208516725,\n      \"y\": 0.06394788149148214,\n      \"z\": -0.12025103887599427,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.04777084008923937,\n      \"y\": 0.03903085613992762,\n      \"z\": 0.14718921362515985,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.026437940951640766,\n      \"y\": -0.03577518155896713,\n      \"z\": 0.04660240446529065,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.045183849529759214,\n      \"y\": 0.09436818022836241,\n      \"z\": 0.015677833893669457,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.0177794009833431,\n      \"y\": 0.17602016279345528,\n      \"z\": -0.014771898788081906,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.1055540281191906,\n      \"y\": -0.009031715521440577,\n      \"z\": -0.1019592369804594,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.05466475590521753,\n      \"y\": 0.10682586045440019,\n      \"z\": 0.16000000000000003,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.1590542095799448,\n      \"y\": -0.09111398583586935,\n      \"z\": 0.08000000000000002,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.10749730136243406,\n      \"y\": -0.16865446984824933,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.14974968755028245,\n      \"y\": 0.1057120195559274,\n      \"z\": -0.08,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.07375674789862151,\n      \"y\": 0.09465697089712512,\n      \"z\": -0.16000000000000003,\n      \"index\": 15\n    }\n  ]\n}"
  },
  {
    "timestamp": 62138,
    "eventType": "generateLinkData() finished",
    "eventData": "{\n  \"newLinkData\": {\n    \"citationLinkData\": [\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n      }\n    ],\n    \"recommendationLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\"\n      }\n    ],\n    \"authorLinkData\": [\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      }\n    ],\n    \"userLinkData\": []\n  }\n}"
  },
  {
    "timestamp": 62138,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 62139,
    "eventType": "addPapersToGraph() finished",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.05466475590521753,\n      \"y\": 0.10682586045440019,\n      \"z\": 0.16000000000000003,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.1590542095799448,\n      \"y\": -0.09111398583586935,\n      \"z\": 0.08000000000000002,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.10749730136243406,\n      \"y\": -0.16865446984824933,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.14974968755028245,\n      \"y\": 0.1057120195559274,\n      \"z\": -0.08,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.07375674789862151,\n      \"y\": 0.09465697089712512,\n      \"z\": -0.16000000000000003,\n      \"index\": 15\n    }\n  ],\n  \"currPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.17896648060872697,\n      \"y\": 0.04264951080425209,\n      \"z\": 0.10982179948134402,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": -0.07116143054451302,\n      \"y\": 0.05197906037438905,\n      \"z\": 0.03265315167733542,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.17691116490150907,\n      \"y\": 0.15413079335629698,\n      \"z\": 0.03616189252803527,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.14578769542553172,\n      \"y\": -0.07797908968428648,\n      \"z\": 0.0004158552999789052,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.12474050208516725,\n      \"y\": 0.06394788149148214,\n      \"z\": -0.12025103887599427,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.04777084008923937,\n      \"y\": 0.03903085613992762,\n      \"z\": 0.14718921362515985,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.026437940951640766,\n      \"y\": -0.03577518155896713,\n      \"z\": 0.04660240446529065,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.045183849529759214,\n      \"y\": 0.09436818022836241,\n      \"z\": 0.015677833893669457,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.0177794009833431,\n      \"y\": 0.17602016279345528,\n      \"z\": -0.014771898788081906,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.1055540281191906,\n      \"y\": -0.009031715521440577,\n      \"z\": -0.1019592369804594,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.05466475590521753,\n      \"y\": 0.10682586045440019,\n      \"z\": 0.16000000000000003,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.1590542095799448,\n      \"y\": -0.09111398583586935,\n      \"z\": 0.08000000000000002,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.10749730136243406,\n      \"y\": -0.16865446984824933,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.14974968755028245,\n      \"y\": 0.1057120195559274,\n      \"z\": -0.08,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.07375674789862151,\n      \"y\": 0.09465697089712512,\n      \"z\": -0.16000000000000003,\n      \"index\": 15\n    }\n  ]\n}"
  },
  {
    "timestamp": 62139,
    "eventType": "setLinkType() called",
    "eventData": "{\n  \"currLinkType\": \"custom\",\n  \"newLinkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 62139,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type recommendation\"\n}"
  },
  {
    "timestamp": 62139,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 62498,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09827279403228921,\n    \"_y\": 0.053249516619030955,\n    \"_z\": 0.1418933570942985\n  }\n}"
  },
  {
    "timestamp": 62498,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n    \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n    \"x\": -0.09827279403228921,\n    \"y\": 0.053249516619030955,\n    \"z\": 0.1418933570942985,\n    \"index\": 6\n  }\n}"
  },
  {
    "timestamp": 62498,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 62514,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09827279403228921,\n    \"_y\": 0.053249516619030955,\n    \"_z\": 0.1418933570942985\n  }\n}"
  },
  {
    "timestamp": 62514,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 62514,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 62514,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 62520,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.08506629449624334,\n    \"_y\": 0.06964101545971019,\n    \"_z\": 0.012411471475002066\n  }\n}"
  },
  {
    "timestamp": 62520,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n    \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n    \"x\": -0.08506629449624334,\n    \"y\": 0.06964101545971019,\n    \"z\": 0.012411471475002066,\n    \"index\": 2\n  }\n}"
  },
  {
    "timestamp": 62520,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 62536,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.08498450027050305,\n    \"_y\": 0.07046801015936892,\n    \"_z\": 0.012391541379929632\n  }\n}"
  },
  {
    "timestamp": 62536,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 62536,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 62536,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 63935,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09361576159060774,\n    \"_y\": 0.22649213549714078,\n    \"_z\": -0.01049264229381288\n  }\n}"
  },
  {
    "timestamp": 63935,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n    \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n    \"x\": -0.09361576159060774,\n    \"y\": 0.22649213549714078,\n    \"z\": -0.01049264229381288,\n    \"index\": 9\n  }\n}"
  },
  {
    "timestamp": 63935,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 64164,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09680197058078707,\n    \"_y\": 0.2292741262842762,\n    \"_z\": -0.010088658214249781\n  }\n}"
  },
  {
    "timestamp": 64165,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09680197058078707,\n    \"_y\": 0.2292741262842762,\n    \"_z\": -0.010088658214249781\n  }\n}"
  },
  {
    "timestamp": 64278,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09833867977804847,\n    \"_y\": 0.23081266168064768,\n    \"_z\": -0.009961256056680762\n  }\n}"
  },
  {
    "timestamp": 64281,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0976643790734325,\n    \"_y\": 0.23092151128732272,\n    \"_z\": -0.010126835232751279\n  }\n}"
  },
  {
    "timestamp": 64295,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0976643790734325,\n    \"_y\": 0.23092151128732272,\n    \"_z\": -0.010126835232751279\n  }\n}"
  },
  {
    "timestamp": 64296,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09718903203134877,\n    \"_y\": 0.2348222553082616,\n    \"_z\": -0.010832217088119893\n  }\n}"
  },
  {
    "timestamp": 64312,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09718903203134877,\n    \"_y\": 0.2348222553082616,\n    \"_z\": -0.010832217088119893\n  }\n}"
  },
  {
    "timestamp": 64312,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09718903203134877,\n    \"_y\": 0.2348222553082616,\n    \"_z\": -0.010832217088119893\n  }\n}"
  },
  {
    "timestamp": 64317,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0968859386873756,\n    \"_y\": 0.24344212257348605,\n    \"_z\": -0.012258605132030158\n  }\n}"
  },
  {
    "timestamp": 64329,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0968859386873756,\n    \"_y\": 0.24344212257348605,\n    \"_z\": -0.012258605132030158\n  }\n}"
  },
  {
    "timestamp": 64331,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09665313784604412,\n    \"_y\": 0.2555616095014722,\n    \"_z\": -0.014305371357278733\n  }\n}"
  },
  {
    "timestamp": 64345,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09665313784604412,\n    \"_y\": 0.2555616095014722,\n    \"_z\": -0.014305371357278733\n  }\n}"
  },
  {
    "timestamp": 64348,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09644651089434964,\n    \"_y\": 0.26977614008866857,\n    \"_z\": -0.016809546886162666\n  }\n}"
  },
  {
    "timestamp": 64360,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09644651089434964,\n    \"_y\": 0.26977614008866857,\n    \"_z\": -0.016809546886162666\n  }\n}"
  },
  {
    "timestamp": 64364,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09625267658954006,\n    \"_y\": 0.28460458361589025,\n    \"_z\": -0.019547307429985908\n  }\n}"
  },
  {
    "timestamp": 64378,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09625267658954006,\n    \"_y\": 0.28460458361589025,\n    \"_z\": -0.019547307429985908\n  }\n}"
  },
  {
    "timestamp": 64381,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09605111230736119,\n    \"_y\": 0.3004585250564725,\n    \"_z\": -0.022633702991681007\n  }\n}"
  },
  {
    "timestamp": 64396,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09605111230736119,\n    \"_y\": 0.3004585250564725,\n    \"_z\": -0.022633702991681007\n  }\n}"
  },
  {
    "timestamp": 64398,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0958250989449535,\n    \"_y\": 0.317904774779907,\n    \"_z\": -0.026232262639479545\n  }\n}"
  },
  {
    "timestamp": 64411,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0958250989449535,\n    \"_y\": 0.317904774779907,\n    \"_z\": -0.026232262639479545\n  }\n}"
  },
  {
    "timestamp": 64415,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0951474351120506,\n    \"_y\": 0.3387015356966169,\n    \"_z\": -0.030795157453195957\n  }\n}"
  },
  {
    "timestamp": 64427,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0951474351120506,\n    \"_y\": 0.3387015356966169,\n    \"_z\": -0.030795157453195957\n  }\n}"
  },
  {
    "timestamp": 64430,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09145029310708386,\n    \"_y\": 0.363296483392349,\n    \"_z\": -0.036426645269768146\n  }\n}"
  },
  {
    "timestamp": 64444,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09145029310708386,\n    \"_y\": 0.363296483392349,\n    \"_z\": -0.036426645269768146\n  }\n}"
  },
  {
    "timestamp": 64448,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0815583770406757,\n    \"_y\": 0.3896464898534925,\n    \"_z\": -0.04261292753197422\n  }\n}"
  },
  {
    "timestamp": 64460,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.0815583770406757,\n    \"_y\": 0.3896464898534925,\n    \"_z\": -0.04261292753197422\n  }\n}"
  },
  {
    "timestamp": 64465,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.06552057203476769,\n    \"_y\": 0.4152386232563169,\n    \"_z\": -0.04884845999457112\n  }\n}"
  },
  {
    "timestamp": 64479,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.06552057203476769,\n    \"_y\": 0.4152386232563169,\n    \"_z\": -0.04884845999457112\n  }\n}"
  },
  {
    "timestamp": 64481,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.045342328516892016,\n    \"_y\": 0.43775824152909826,\n    \"_z\": -0.05463187073745003\n  }\n}"
  },
  {
    "timestamp": 64494,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.045342328516892016,\n    \"_y\": 0.43775824152909826,\n    \"_z\": -0.05463187073745003\n  }\n}"
  },
  {
    "timestamp": 64498,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.02318088881544289,\n    \"_y\": 0.4561117484518201,\n    \"_z\": -0.059673725193517116\n  }\n}"
  },
  {
    "timestamp": 64510,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.02318088881544289,\n    \"_y\": 0.4561117484518201,\n    \"_z\": -0.059673725193517116\n  }\n}"
  },
  {
    "timestamp": 64513,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.00008828457317766603,\n    \"_y\": 0.46981403672181676,\n    \"_z\": -0.06376475331761113\n  }\n}"
  },
  {
    "timestamp": 64526,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.00008828457317766603,\n    \"_y\": 0.46981403672181676,\n    \"_z\": -0.06376475331761113\n  }\n}"
  },
  {
    "timestamp": 64533,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.02380954900694443,\n    \"_y\": 0.48005488955461095,\n    \"_z\": -0.06723813203551045\n  }\n}"
  },
  {
    "timestamp": 64543,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.02380954900694443,\n    \"_y\": 0.48005488955461095,\n    \"_z\": -0.06723813203551045\n  }\n}"
  },
  {
    "timestamp": 64548,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.04805682839763714,\n    \"_y\": 0.4881364002176435,\n    \"_z\": -0.07048201051928273\n  }\n}"
  },
  {
    "timestamp": 64560,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.04805682839763714,\n    \"_y\": 0.4881364002176435,\n    \"_z\": -0.07048201051928273\n  }\n}"
  },
  {
    "timestamp": 64564,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.07089553454828812,\n    \"_y\": 0.4944004907556684,\n    \"_z\": -0.07347612318970433\n  }\n}"
  },
  {
    "timestamp": 64577,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.07089553454828812,\n    \"_y\": 0.4944004907556684,\n    \"_z\": -0.07347612318970433\n  }\n}"
  },
  {
    "timestamp": 64581,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.09297707730842186,\n    \"_y\": 0.49969612502538274,\n    \"_z\": -0.07648793843962422\n  }\n}"
  },
  {
    "timestamp": 64594,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.09297707730842186,\n    \"_y\": 0.49969612502538274,\n    \"_z\": -0.07648793843962422\n  }\n}"
  },
  {
    "timestamp": 64597,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.11538189703536583,\n    \"_y\": 0.5044240548559339,\n    \"_z\": -0.07971234110571614\n  }\n}"
  },
  {
    "timestamp": 64609,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.11538189703536583,\n    \"_y\": 0.5044240548559339,\n    \"_z\": -0.07971234110571614\n  }\n}"
  },
  {
    "timestamp": 64614,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.13714571351123406,\n    \"_y\": 0.508145441050163,\n    \"_z\": -0.08288676900245419\n  }\n}"
  },
  {
    "timestamp": 64626,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.13714571351123406,\n    \"_y\": 0.508145441050163,\n    \"_z\": -0.08288676900245419\n  }\n}"
  },
  {
    "timestamp": 64631,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.15893220955443932,\n    \"_y\": 0.5106131925531537,\n    \"_z\": -0.08597238225318661\n  }\n}"
  },
  {
    "timestamp": 64643,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.15893220955443932,\n    \"_y\": 0.5106131925531537,\n    \"_z\": -0.08597238225318661\n  }\n}"
  },
  {
    "timestamp": 64648,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.18069749379468514,\n    \"_y\": 0.5117212428995283,\n    \"_z\": -0.08891633761502972\n  }\n}"
  },
  {
    "timestamp": 64664,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.18069749379468514,\n    \"_y\": 0.5117212428995283,\n    \"_z\": -0.08891633761502972\n  }\n}"
  },
  {
    "timestamp": 64664,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.2024052819044645,\n    \"_y\": 0.5117598667093427,\n    \"_z\": -0.09181059760429135\n  }\n}"
  },
  {
    "timestamp": 64679,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.2024052819044645,\n    \"_y\": 0.5117598667093427,\n    \"_z\": -0.09181059760429135\n  }\n}"
  },
  {
    "timestamp": 64680,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.22403655255151345,\n    \"_y\": 0.5108767344900281,\n    \"_z\": -0.09470071879603138\n  }\n}"
  },
  {
    "timestamp": 64694,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.22403655255151345,\n    \"_y\": 0.5108767344900281,\n    \"_z\": -0.09470071879603138\n  }\n}"
  },
  {
    "timestamp": 64698,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.2441329514415319,\n    \"_y\": 0.508896697992912,\n    \"_z\": -0.0972515703497099\n  }\n}"
  },
  {
    "timestamp": 64712,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.2441329514415319,\n    \"_y\": 0.508896697992912,\n    \"_z\": -0.0972515703497099\n  }\n}"
  },
  {
    "timestamp": 64714,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.26311480307889534,\n    \"_y\": 0.505342592234245,\n    \"_z\": -0.09932901201225987\n  }\n}"
  },
  {
    "timestamp": 64729,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.26311480307889534,\n    \"_y\": 0.505342592234245,\n    \"_z\": -0.09932901201225987\n  }\n}"
  },
  {
    "timestamp": 64731,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.2822959950001295,\n    \"_y\": 0.49990536713086675,\n    \"_z\": -0.10107054797388783\n  }\n}"
  },
  {
    "timestamp": 64745,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.2822959950001295,\n    \"_y\": 0.49990536713086675,\n    \"_z\": -0.10107054797388783\n  }\n}"
  },
  {
    "timestamp": 64748,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.30083068514180733,\n    \"_y\": 0.49319974028550695,\n    \"_z\": -0.1025163145122694\n  }\n}"
  },
  {
    "timestamp": 64762,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.30083068514180733,\n    \"_y\": 0.49319974028550695,\n    \"_z\": -0.1025163145122694\n  }\n}"
  },
  {
    "timestamp": 64764,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.3176137735874708,\n    \"_y\": 0.48524769091092657,\n    \"_z\": -0.10340767217256298\n  }\n}"
  },
  {
    "timestamp": 64779,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.3176137735874708,\n    \"_y\": 0.48524769091092657,\n    \"_z\": -0.10340767217256298\n  }\n}"
  },
  {
    "timestamp": 64781,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.33321487212491585,\n    \"_y\": 0.47564050995790075,\n    \"_z\": -0.10371795905210247\n  }\n}"
  },
  {
    "timestamp": 64795,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.33321487212491585,\n    \"_y\": 0.47564050995790075,\n    \"_z\": -0.10371795905210247\n  }\n}"
  },
  {
    "timestamp": 64798,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.3479508688480909,\n    \"_y\": 0.4638162448354871,\n    \"_z\": -0.10334399206020108\n  }\n}"
  },
  {
    "timestamp": 64811,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.3479508688480909,\n    \"_y\": 0.4638162448354871,\n    \"_z\": -0.10334399206020108\n  }\n}"
  },
  {
    "timestamp": 64815,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.36200968230081154,\n    \"_y\": 0.44912167334043096,\n    \"_z\": -0.10216262427546254\n  }\n}"
  },
  {
    "timestamp": 64828,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.36200968230081154,\n    \"_y\": 0.44912167334043096,\n    \"_z\": -0.10216262427546254\n  }\n}"
  },
  {
    "timestamp": 64831,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.3754571607143934,\n    \"_y\": 0.43154330992185186,\n    \"_z\": -0.100254888212459\n  }\n}"
  },
  {
    "timestamp": 64845,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.3754571607143934,\n    \"_y\": 0.43154330992185186,\n    \"_z\": -0.100254888212459\n  }\n}"
  },
  {
    "timestamp": 64848,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.3875098308355863,\n    \"_y\": 0.412513111466995,\n    \"_z\": -0.09788286921955815\n  }\n}"
  },
  {
    "timestamp": 64861,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.3875098308355863,\n    \"_y\": 0.412513111466995,\n    \"_z\": -0.09788286921955815\n  }\n}"
  },
  {
    "timestamp": 64864,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.3980572899611051,\n    \"_y\": 0.39379939877473424,\n    \"_z\": -0.09550801900603047\n  }\n}"
  },
  {
    "timestamp": 64878,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.3980572899611051,\n    \"_y\": 0.39379939877473424,\n    \"_z\": -0.09550801900603047\n  }\n}"
  },
  {
    "timestamp": 64881,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.4078290393383558,\n    \"_y\": 0.37518199228726934,\n    \"_z\": -0.09325758603789082\n  }\n}"
  },
  {
    "timestamp": 64894,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.4078290393383558,\n    \"_y\": 0.37518199228726934,\n    \"_z\": -0.09325758603789082\n  }\n}"
  },
  {
    "timestamp": 64898,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.41751577759099556,\n    \"_y\": 0.3568957194038541,\n    \"_z\": -0.09137403828479519\n  }\n}"
  },
  {
    "timestamp": 64910,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.41751577759099556,\n    \"_y\": 0.3568957194038541,\n    \"_z\": -0.09137403828479519\n  }\n}"
  },
  {
    "timestamp": 64914,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.42710850441766335,\n    \"_y\": 0.33909419619523595,\n    \"_z\": -0.08987378192521801\n  }\n}"
  },
  {
    "timestamp": 64926,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.42710850441766335,\n    \"_y\": 0.33909419619523595,\n    \"_z\": -0.08987378192521801\n  }\n}"
  },
  {
    "timestamp": 64930,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.4366462906630094,\n    \"_y\": 0.3211296691843183,\n    \"_z\": -0.08861304310538044\n  }\n}"
  },
  {
    "timestamp": 64943,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.4366462906630094,\n    \"_y\": 0.3211296691843183,\n    \"_z\": -0.08861304310538044\n  }\n}"
  },
  {
    "timestamp": 64947,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.4461014648706968,\n    \"_y\": 0.30341574990235876,\n    \"_z\": -0.08766550806738606\n  }\n}"
  },
  {
    "timestamp": 64961,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.4461014648706968,\n    \"_y\": 0.30341574990235876,\n    \"_z\": -0.08766550806738606\n  }\n}"
  },
  {
    "timestamp": 64963,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.455439858678108,\n    \"_y\": 0.28653979742013524,\n    \"_z\": -0.08711903778292408\n  }\n}"
  },
  {
    "timestamp": 64978,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.455439858678108,\n    \"_y\": 0.28653979742013524,\n    \"_z\": -0.08711903778292408\n  }\n}"
  },
  {
    "timestamp": 64981,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.4643012514145429,\n    \"_y\": 0.27082705938302587,\n    \"_z\": -0.08688539130069485\n  }\n}"
  },
  {
    "timestamp": 64994,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.4643012514145429,\n    \"_y\": 0.27082705938302587,\n    \"_z\": -0.08688539130069485\n  }\n}"
  },
  {
    "timestamp": 64997,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.4728759905130918,\n    \"_y\": 0.2560560151287229,\n    \"_z\": -0.08694980902053585\n  }\n}"
  },
  {
    "timestamp": 65011,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.4728759905130918,\n    \"_y\": 0.2560560151287229,\n    \"_z\": -0.08694980902053585\n  }\n}"
  },
  {
    "timestamp": 65015,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.4823250403435285,\n    \"_y\": 0.24131991409741949,\n    \"_z\": -0.08753086117483845\n  }\n}"
  },
  {
    "timestamp": 65027,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.4823250403435285,\n    \"_y\": 0.24131991409741949,\n    \"_z\": -0.08753086117483845\n  }\n}"
  },
  {
    "timestamp": 65031,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.4928672393591459,\n    \"_y\": 0.2261901765414388,\n    \"_z\": -0.08865103361584416\n  }\n}"
  },
  {
    "timestamp": 65044,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.4928672393591459,\n    \"_y\": 0.2261901765414388,\n    \"_z\": -0.08865103361584416\n  }\n}"
  },
  {
    "timestamp": 65048,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.5039012511999662,\n    \"_y\": 0.21086658977948736,\n    \"_z\": -0.09015325320340863\n  }\n}"
  },
  {
    "timestamp": 65061,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5039012511999662,\n    \"_y\": 0.21086658977948736,\n    \"_z\": -0.09015325320340863\n  }\n}"
  },
  {
    "timestamp": 65064,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.5147575815947111,\n    \"_y\": 0.196218509907356,\n    \"_z\": -0.09191984546758404\n  }\n}"
  },
  {
    "timestamp": 65077,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5147575815947111,\n    \"_y\": 0.196218509907356,\n    \"_z\": -0.09191984546758404\n  }\n}"
  },
  {
    "timestamp": 65080,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.5250971695215757,\n    \"_y\": 0.18305790119849752,\n    \"_z\": -0.09390323845125904\n  }\n}"
  },
  {
    "timestamp": 65094,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5250971695215757,\n    \"_y\": 0.18305790119849752,\n    \"_z\": -0.09390323845125904\n  }\n}"
  },
  {
    "timestamp": 65097,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.5344027658731992,\n    \"_y\": 0.17255510830365728,\n    \"_z\": -0.09599710864402523\n  }\n}"
  },
  {
    "timestamp": 65110,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5344027658731992,\n    \"_y\": 0.17255510830365728,\n    \"_z\": -0.09599710864402523\n  }\n}"
  },
  {
    "timestamp": 65114,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.5417738338739927,\n    \"_y\": 0.1653180166431577,\n    \"_z\": -0.0978592620549368\n  }\n}"
  },
  {
    "timestamp": 65127,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5417738338739927,\n    \"_y\": 0.1653180166431577,\n    \"_z\": -0.0978592620549368\n  }\n}"
  },
  {
    "timestamp": 65130,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.547150560262924,\n    \"_y\": 0.16050680422269414,\n    \"_z\": -0.09931066123224964\n  }\n}"
  },
  {
    "timestamp": 65145,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.547150560262924,\n    \"_y\": 0.16050680422269414,\n    \"_z\": -0.09931066123224964\n  }\n}"
  },
  {
    "timestamp": 65148,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 65163,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 65163,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 65163,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 65163,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 65313,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 65313,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n    \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n    \"x\": 0.5511693140299375,\n    \"y\": 0.15767232769214223,\n    \"z\": -0.10050514576412907,\n    \"index\": 9\n  }\n}"
  },
  {
    "timestamp": 65313,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 65329,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 65329,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 65329,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 65329,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 65852,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 65852,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n    \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n    \"x\": 0.5511693140299375,\n    \"y\": 0.15767232769214223,\n    \"z\": -0.10050514576412907,\n    \"index\": 9\n  }\n}"
  },
  {
    "timestamp": 65852,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 66078,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 66078,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 66145,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 66145,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 66145,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 66387,
    "eventType": "addRecommendationsFromSelectedPapers() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n  ]\n}"
  },
  {
    "timestamp": 66732,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.5511693140299375,\n    \"_y\": 0.15767232769214223,\n    \"_z\": -0.10050514576412907\n  }\n}"
  },
  {
    "timestamp": 66732,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 66732,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 66732,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 67321,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10744215020383806,\n    \"_y\": 0.1268571168710419,\n    \"_z\": -0.052215705898591314\n  }\n}"
  },
  {
    "timestamp": 67321,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n    \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n    \"x\": -0.10744215020383806,\n    \"y\": 0.1268571168710419,\n    \"z\": -0.052215705898591314,\n    \"index\": 3\n  }\n}"
  },
  {
    "timestamp": 67321,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 67647,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10713082749721328,\n    \"_y\": 0.12633275418523982,\n    \"_z\": -0.05225213922454268\n  }\n}"
  },
  {
    "timestamp": 67648,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10713082749721328,\n    \"_y\": 0.12633275418523982,\n    \"_z\": -0.05225213922454268\n  }\n}"
  },
  {
    "timestamp": 67729,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10707087759229515,\n    \"_y\": 0.1262302688388016,\n    \"_z\": -0.052260109098667074\n  }\n}"
  },
  {
    "timestamp": 67729,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10707087759229515,\n    \"_y\": 0.1262302688388016,\n    \"_z\": -0.052260109098667074\n  }\n}"
  },
  {
    "timestamp": 67730,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10707087759229515,\n    \"_y\": 0.1262302688388016,\n    \"_z\": -0.052260109098667074\n  }\n}"
  },
  {
    "timestamp": 67905,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10696196594969788,\n    \"_y\": 0.12604347491032747,\n    \"_z\": -0.05227537635415586\n  }\n}"
  },
  {
    "timestamp": 67905,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 67905,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 67905,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 71685,
    "eventType": "addPapersToGraph() called",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\"\n    }\n  ],\n  \"prevPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.08380829861339262,\n      \"y\": 0.08454006162718873,\n      \"z\": 0.03583519585078482,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.01420769325505532,\n      \"y\": 0.08425384549028062,\n      \"z\": -0.04661226162870499,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.10659723455151922,\n      \"y\": 0.12540998328149566,\n      \"z\": -0.05233358079088573,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.061465156890892166,\n      \"y\": 0.019435746676694794,\n      \"z\": 0.030585145478344334,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.10044608943539249,\n      \"y\": 0.08584766504193453,\n      \"z\": -0.09843101090613007,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.03772231298137265,\n      \"y\": 0.1591546876855868,\n      \"z\": 0.04930088874401473,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.09243712141514375,\n      \"y\": 0.0164622664278991,\n      \"z\": -0.08503572547544817,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.045698845127241726,\n      \"y\": 0.19173552615490144,\n      \"z\": -0.048914791886869806,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.5511693140299375,\n      \"y\": 0.15767232769214223,\n      \"z\": -0.10050514576412907,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.08298812824986335,\n      \"y\": 0.02076452094905285,\n      \"z\": -0.08780909062891276,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.0032085208483095423,\n      \"y\": 0.2867270223257976,\n      \"z\": 0.028040339504408537,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.05605650123028815,\n      \"y\": 0.20317128037383586,\n      \"z\": 0.06817162919154185,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.15282934862332798,\n      \"y\": 0.18350137325778995,\n      \"z\": 0.009996132370858482,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.11461442748216907,\n      \"y\": 0.24041793230239786,\n      \"z\": -0.12475017424412688,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.0020538128208182384,\n      \"y\": 0.2867120633342738,\n      \"z\": -0.10400314301945274,\n      \"index\": 15\n    }\n  ]\n}"
  },
  {
    "timestamp": 71686,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.2,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.10862027347340843,\n      \"_y\": 0.05100623678102474,\n      \"_z\": 0.16000000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.08566117027303073,\n      \"_y\": 0.16205605174585377,\n      \"_z\": 0.08000000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.17220703103953827,\n      \"_y\": -0.10170908740396561,\n      \"_z\": 1.2246467991473533e-17\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.10056669900409951,\n      \"_y\": -0.15325253358890628,\n      \"_z\": -0.08\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.09710662023836437,\n      \"_y\": 0.07050038514704783,\n      \"_z\": -0.16000000000000003\n    }\n  ]\n}"
  },
  {
    "timestamp": 71686,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.08380829861339262,\n      \"y\": 0.08454006162718873,\n      \"z\": 0.03583519585078482,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.01420769325505532,\n      \"y\": 0.08425384549028062,\n      \"z\": -0.04661226162870499,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.10659723455151922,\n      \"y\": 0.12540998328149566,\n      \"z\": -0.05233358079088573,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.061465156890892166,\n      \"y\": 0.019435746676694794,\n      \"z\": 0.030585145478344334,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.10044608943539249,\n      \"y\": 0.08584766504193453,\n      \"z\": -0.09843101090613007,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.03772231298137265,\n      \"y\": 0.1591546876855868,\n      \"z\": 0.04930088874401473,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.09243712141514375,\n      \"y\": 0.0164622664278991,\n      \"z\": -0.08503572547544817,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.045698845127241726,\n      \"y\": 0.19173552615490144,\n      \"z\": -0.048914791886869806,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.5511693140299375,\n      \"y\": 0.15767232769214223,\n      \"z\": -0.10050514576412907,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.08298812824986335,\n      \"y\": 0.02076452094905285,\n      \"z\": -0.08780909062891276,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.0032085208483095423,\n      \"y\": 0.2867270223257976,\n      \"z\": 0.028040339504408537,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.05605650123028815,\n      \"y\": 0.20317128037383586,\n      \"z\": 0.06817162919154185,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.15282934862332798,\n      \"y\": 0.18350137325778995,\n      \"z\": 0.009996132370858482,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.11461442748216907,\n      \"y\": 0.24041793230239786,\n      \"z\": -0.12475017424412688,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.0020538128208182384,\n      \"y\": 0.2867120633342738,\n      \"z\": -0.10400314301945274,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.10862027347340843,\n      \"y\": 0.05100623678102474,\n      \"z\": 0.16000000000000003,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": -0.08566117027303073,\n      \"y\": 0.16205605174585377,\n      \"z\": 0.08000000000000002,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": -0.17220703103953827,\n      \"y\": -0.10170908740396561,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.10056669900409951,\n      \"y\": -0.15325253358890628,\n      \"z\": -0.08,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.09710662023836437,\n      \"y\": 0.07050038514704783,\n      \"z\": -0.16000000000000003,\n      \"index\": 20\n    }\n  ]\n}"
  },
  {
    "timestamp": 71706,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.08380829861339262,\n      \"y\": 0.08454006162718873,\n      \"z\": 0.03583519585078482,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.01420769325505532,\n      \"y\": 0.08425384549028062,\n      \"z\": -0.04661226162870499,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.10659723455151922,\n      \"y\": 0.12540998328149566,\n      \"z\": -0.05233358079088573,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.061465156890892166,\n      \"y\": 0.019435746676694794,\n      \"z\": 0.030585145478344334,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.10044608943539249,\n      \"y\": 0.08584766504193453,\n      \"z\": -0.09843101090613007,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.03772231298137265,\n      \"y\": 0.1591546876855868,\n      \"z\": 0.04930088874401473,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.09243712141514375,\n      \"y\": 0.0164622664278991,\n      \"z\": -0.08503572547544817,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.045698845127241726,\n      \"y\": 0.19173552615490144,\n      \"z\": -0.048914791886869806,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.5511693140299375,\n      \"y\": 0.15767232769214223,\n      \"z\": -0.10050514576412907,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.08298812824986335,\n      \"y\": 0.02076452094905285,\n      \"z\": -0.08780909062891276,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.0032085208483095423,\n      \"y\": 0.2867270223257976,\n      \"z\": 0.028040339504408537,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.05605650123028815,\n      \"y\": 0.20317128037383586,\n      \"z\": 0.06817162919154185,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.15282934862332798,\n      \"y\": 0.18350137325778995,\n      \"z\": 0.009996132370858482,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.11461442748216907,\n      \"y\": 0.24041793230239786,\n      \"z\": -0.12475017424412688,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.0020538128208182384,\n      \"y\": 0.2867120633342738,\n      \"z\": -0.10400314301945274,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.10862027347340843,\n      \"y\": 0.05100623678102474,\n      \"z\": 0.16000000000000003,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": -0.08566117027303073,\n      \"y\": 0.16205605174585377,\n      \"z\": 0.08000000000000002,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": -0.17220703103953827,\n      \"y\": -0.10170908740396561,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.10056669900409951,\n      \"y\": -0.15325253358890628,\n      \"z\": -0.08,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.09710662023836437,\n      \"y\": 0.07050038514704783,\n      \"z\": -0.16000000000000003,\n      \"index\": 20\n    }\n  ]\n}"
  },
  {
    "timestamp": 71708,
    "eventType": "generateLinkData() finished",
    "eventData": "{\n  \"newLinkData\": {\n    \"citationLinkData\": [\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n      }\n    ],\n    \"recommendationLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      }\n    ],\n    \"authorLinkData\": [\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      }\n    ],\n    \"userLinkData\": []\n  }\n}"
  },
  {
    "timestamp": 71708,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 71709,
    "eventType": "addPapersToGraph() finished",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.10862027347340843,\n      \"y\": 0.05100623678102474,\n      \"z\": 0.16000000000000003,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": -0.08566117027303073,\n      \"y\": 0.16205605174585377,\n      \"z\": 0.08000000000000002,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": -0.17220703103953827,\n      \"y\": -0.10170908740396561,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.10056669900409951,\n      \"y\": -0.15325253358890628,\n      \"z\": -0.08,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.09710662023836437,\n      \"y\": 0.07050038514704783,\n      \"z\": -0.16000000000000003,\n      \"index\": 20\n    }\n  ],\n  \"currPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.08380829861339262,\n      \"y\": 0.08454006162718873,\n      \"z\": 0.03583519585078482,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.01420769325505532,\n      \"y\": 0.08425384549028062,\n      \"z\": -0.04661226162870499,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.10659723455151922,\n      \"y\": 0.12540998328149566,\n      \"z\": -0.05233358079088573,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.061465156890892166,\n      \"y\": 0.019435746676694794,\n      \"z\": 0.030585145478344334,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.10044608943539249,\n      \"y\": 0.08584766504193453,\n      \"z\": -0.09843101090613007,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": -0.03772231298137265,\n      \"y\": 0.1591546876855868,\n      \"z\": 0.04930088874401473,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.09243712141514375,\n      \"y\": 0.0164622664278991,\n      \"z\": -0.08503572547544817,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.045698845127241726,\n      \"y\": 0.19173552615490144,\n      \"z\": -0.048914791886869806,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.5511693140299375,\n      \"y\": 0.15767232769214223,\n      \"z\": -0.10050514576412907,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.08298812824986335,\n      \"y\": 0.02076452094905285,\n      \"z\": -0.08780909062891276,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.0032085208483095423,\n      \"y\": 0.2867270223257976,\n      \"z\": 0.028040339504408537,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.05605650123028815,\n      \"y\": 0.20317128037383586,\n      \"z\": 0.06817162919154185,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.15282934862332798,\n      \"y\": 0.18350137325778995,\n      \"z\": 0.009996132370858482,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.11461442748216907,\n      \"y\": 0.24041793230239786,\n      \"z\": -0.12475017424412688,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.0020538128208182384,\n      \"y\": 0.2867120633342738,\n      \"z\": -0.10400314301945274,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.10862027347340843,\n      \"y\": 0.05100623678102474,\n      \"z\": 0.16000000000000003,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": -0.08566117027303073,\n      \"y\": 0.16205605174585377,\n      \"z\": 0.08000000000000002,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": -0.17220703103953827,\n      \"y\": -0.10170908740396561,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.10056669900409951,\n      \"y\": -0.15325253358890628,\n      \"z\": -0.08,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.09710662023836437,\n      \"y\": 0.07050038514704783,\n      \"z\": -0.16000000000000003,\n      \"index\": 20\n    }\n  ]\n}"
  },
  {
    "timestamp": 71709,
    "eventType": "setLinkType() called",
    "eventData": "{\n  \"currLinkType\": \"recommendation\",\n  \"newLinkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 71709,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type recommendation\"\n}"
  },
  {
    "timestamp": 71709,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 76362,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 76362,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n    \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n    \"x\": -0.17789743341205072,\n    \"y\": 0.041486394567458444,\n    \"z\": -0.01102328163581174,\n    \"index\": 0\n  }\n}"
  },
  {
    "timestamp": 76362,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 76596,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 76596,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 76676,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 76676,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 76676,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 76799,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17789743341205072,\n    \"_y\": 0.041486394567458444,\n    \"_z\": -0.01102328163581174\n  }\n}"
  },
  {
    "timestamp": 76800,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 76800,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 76800,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 77089,
    "eventType": "addRecommendationsFromSelectedPapers() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n  ]\n}"
  },
  {
    "timestamp": 77793,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.026971989471769504,\n    \"_y\": 0.065791813797116,\n    \"_z\": -0.07140012591082114\n  }\n}"
  },
  {
    "timestamp": 77793,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n    \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n    \"x\": 0.026971989471769504,\n    \"y\": 0.065791813797116,\n    \"z\": -0.07140012591082114,\n    \"index\": 5\n  }\n}"
  },
  {
    "timestamp": 77793,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 78051,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.02696469383107328,\n    \"_y\": 0.06579151213030902,\n    \"_z\": -0.07140169409189696\n  }\n}"
  },
  {
    "timestamp": 78051,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 78051,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 78051,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 78051,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.014474402071049336,\n    \"_y\": 0.08768019332579684,\n    \"_z\": -0.040338113813750104\n  }\n}"
  },
  {
    "timestamp": 78051,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n    \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n    \"x\": 0.014474402071049336,\n    \"y\": 0.08768019332579684,\n    \"z\": -0.040338113813750104,\n    \"index\": 1\n  }\n}"
  },
  {
    "timestamp": 78051,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 78062,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.014474402071049336,\n    \"_y\": 0.08768019332579684,\n    \"_z\": -0.040338113813750104\n  }\n}"
  },
  {
    "timestamp": 78062,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 78062,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 78062,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 83525,
    "eventType": "addPapersToGraph() called",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\"\n    }\n  ],\n  \"prevPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.014473349347095515,\n      \"y\": 0.08768228481294407,\n      \"z\": -0.0403391766686948,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.22704293206189974,\n      \"y\": 0.1072683853234789,\n      \"z\": -0.06864591425848976,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.1559122995456502,\n      \"y\": 0.07488873052838893,\n      \"z\": -0.03401219588847514,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.03633692715026824,\n      \"y\": 0.08027116785287161,\n      \"z\": -0.00767330212393115,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.026948629422220014,\n      \"y\": 0.06579105966878422,\n      \"z\": -0.07140590592777141,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.20418421289392086,\n      \"y\": 0.09193517655633694,\n      \"z\": 0.05031145680080939,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.1964021342153946,\n      \"y\": 0.013739110241204867,\n      \"z\": -0.13811779980349198,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.18275794264673953,\n      \"y\": 0.19833575745067059,\n      \"z\": -0.11767613594020734,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.5511693140299375,\n      \"y\": 0.15767232769214223,\n      \"z\": -0.10050514576412907,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.02962137958361095,\n      \"y\": 0.051161876041023104,\n      \"z\": -0.03427312482199797,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.08414160004324167,\n      \"y\": 0.25719562338525875,\n      \"z\": -0.08106287891163873,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.17750370037110597,\n      \"y\": 0.2764963146388356,\n      \"z\": -0.02197503307897435,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.2334122547586903,\n      \"y\": 0.2868679404391176,\n      \"z\": -0.055269678336151415,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.2375867703392531,\n      \"y\": 0.20992217897201668,\n      \"z\": -0.21657906021957696,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": 0.08843694054018707,\n      \"y\": 0.20337852971825224,\n      \"z\": -0.18083324645635449,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.35476248631713714,\n      \"y\": 0.13642564450474698,\n      \"z\": -0.073570671669389,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.3565564324405372,\n      \"y\": 0.1373261247261259,\n      \"z\": -0.033621067337867364,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.36774143291855765,\n      \"y\": 0.10060112988818651,\n      \"z\": -0.04485363344936705,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.356657044262082,\n      \"y\": 0.08323129943883235,\n      \"z\": -0.0791381100764957,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.3581160138999636,\n      \"y\": 0.11299790672207702,\n      \"z\": -0.10581807495676626,\n      \"index\": 20\n    }\n  ]\n}"
  },
  {
    "timestamp": 83526,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 4,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.2,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.10681362016257975,\n      \"_y\": 0.07804390141301329,\n      \"_z\": 0.15000000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.10673384169218103,\n      \"_y\": -0.16157935213890554,\n      \"_z\": 0.05\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.1664390941194426,\n      \"_y\": -0.09898498850178918,\n      \"_z\": -0.050000000000000024\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.06217528763136241,\n      \"_y\": 0.11676572103129135,\n      \"_z\": -0.15000000000000002\n    }\n  ]\n}"
  },
  {
    "timestamp": 83526,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.014473349347095515,\n      \"y\": 0.08768228481294407,\n      \"z\": -0.0403391766686948,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.22704293206189974,\n      \"y\": 0.1072683853234789,\n      \"z\": -0.06864591425848976,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.1559122995456502,\n      \"y\": 0.07488873052838893,\n      \"z\": -0.03401219588847514,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.03633692715026824,\n      \"y\": 0.08027116785287161,\n      \"z\": -0.00767330212393115,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.026948629422220014,\n      \"y\": 0.06579105966878422,\n      \"z\": -0.07140590592777141,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.20418421289392086,\n      \"y\": 0.09193517655633694,\n      \"z\": 0.05031145680080939,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.1964021342153946,\n      \"y\": 0.013739110241204867,\n      \"z\": -0.13811779980349198,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.18275794264673953,\n      \"y\": 0.19833575745067059,\n      \"z\": -0.11767613594020734,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.5511693140299375,\n      \"y\": 0.15767232769214223,\n      \"z\": -0.10050514576412907,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.02962137958361095,\n      \"y\": 0.051161876041023104,\n      \"z\": -0.03427312482199797,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.08414160004324167,\n      \"y\": 0.25719562338525875,\n      \"z\": -0.08106287891163873,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.17750370037110597,\n      \"y\": 0.2764963146388356,\n      \"z\": -0.02197503307897435,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.2334122547586903,\n      \"y\": 0.2868679404391176,\n      \"z\": -0.055269678336151415,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.2375867703392531,\n      \"y\": 0.20992217897201668,\n      \"z\": -0.21657906021957696,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": 0.08843694054018707,\n      \"y\": 0.20337852971825224,\n      \"z\": -0.18083324645635449,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.35476248631713714,\n      \"y\": 0.13642564450474698,\n      \"z\": -0.073570671669389,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.3565564324405372,\n      \"y\": 0.1373261247261259,\n      \"z\": -0.033621067337867364,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.36774143291855765,\n      \"y\": 0.10060112988818651,\n      \"z\": -0.04485363344936705,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.356657044262082,\n      \"y\": 0.08323129943883235,\n      \"z\": -0.0791381100764957,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.3581160138999636,\n      \"y\": 0.11299790672207702,\n      \"z\": -0.10581807495676626,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10681362016257975,\n      \"y\": 0.07804390141301329,\n      \"z\": 0.15000000000000002,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10673384169218103,\n      \"y\": -0.16157935213890554,\n      \"z\": 0.05,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.1664390941194426,\n      \"y\": -0.09898498850178918,\n      \"z\": -0.050000000000000024,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.06217528763136241,\n      \"y\": 0.11676572103129135,\n      \"z\": -0.15000000000000002,\n      \"index\": 24\n    }\n  ]\n}"
  },
  {
    "timestamp": 83545,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.014473349347095515,\n      \"y\": 0.08768228481294407,\n      \"z\": -0.0403391766686948,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.22704293206189974,\n      \"y\": 0.1072683853234789,\n      \"z\": -0.06864591425848976,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.1559122995456502,\n      \"y\": 0.07488873052838893,\n      \"z\": -0.03401219588847514,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.03633692715026824,\n      \"y\": 0.08027116785287161,\n      \"z\": -0.00767330212393115,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.026948629422220014,\n      \"y\": 0.06579105966878422,\n      \"z\": -0.07140590592777141,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.20418421289392086,\n      \"y\": 0.09193517655633694,\n      \"z\": 0.05031145680080939,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.1964021342153946,\n      \"y\": 0.013739110241204867,\n      \"z\": -0.13811779980349198,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.18275794264673953,\n      \"y\": 0.19833575745067059,\n      \"z\": -0.11767613594020734,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.5511693140299375,\n      \"y\": 0.15767232769214223,\n      \"z\": -0.10050514576412907,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.02962137958361095,\n      \"y\": 0.051161876041023104,\n      \"z\": -0.03427312482199797,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.08414160004324167,\n      \"y\": 0.25719562338525875,\n      \"z\": -0.08106287891163873,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.17750370037110597,\n      \"y\": 0.2764963146388356,\n      \"z\": -0.02197503307897435,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.2334122547586903,\n      \"y\": 0.2868679404391176,\n      \"z\": -0.055269678336151415,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.2375867703392531,\n      \"y\": 0.20992217897201668,\n      \"z\": -0.21657906021957696,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": 0.08843694054018707,\n      \"y\": 0.20337852971825224,\n      \"z\": -0.18083324645635449,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.35476248631713714,\n      \"y\": 0.13642564450474698,\n      \"z\": -0.073570671669389,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.3565564324405372,\n      \"y\": 0.1373261247261259,\n      \"z\": -0.033621067337867364,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.36774143291855765,\n      \"y\": 0.10060112988818651,\n      \"z\": -0.04485363344936705,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.356657044262082,\n      \"y\": 0.08323129943883235,\n      \"z\": -0.0791381100764957,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.3581160138999636,\n      \"y\": 0.11299790672207702,\n      \"z\": -0.10581807495676626,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10681362016257975,\n      \"y\": 0.07804390141301329,\n      \"z\": 0.15000000000000002,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10673384169218103,\n      \"y\": -0.16157935213890554,\n      \"z\": 0.05,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.1664390941194426,\n      \"y\": -0.09898498850178918,\n      \"z\": -0.050000000000000024,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.06217528763136241,\n      \"y\": 0.11676572103129135,\n      \"z\": -0.15000000000000002,\n      \"index\": 24\n    }\n  ]\n}"
  },
  {
    "timestamp": 83547,
    "eventType": "generateLinkData() finished",
    "eventData": "{\n  \"newLinkData\": {\n    \"citationLinkData\": [\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n      }\n    ],\n    \"recommendationLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"41163e665789ee13f2db5e442eea15fcb188c01c\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"f99c4e2092b186a815140e888768de9845b356c4\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      }\n    ],\n    \"authorLinkData\": [\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      }\n    ],\n    \"userLinkData\": []\n  }\n}"
  },
  {
    "timestamp": 83547,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 83547,
    "eventType": "addPapersToGraph() finished",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10681362016257975,\n      \"y\": 0.07804390141301329,\n      \"z\": 0.15000000000000002,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10673384169218103,\n      \"y\": -0.16157935213890554,\n      \"z\": 0.05,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.1664390941194426,\n      \"y\": -0.09898498850178918,\n      \"z\": -0.050000000000000024,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.06217528763136241,\n      \"y\": 0.11676572103129135,\n      \"z\": -0.15000000000000002,\n      \"index\": 24\n    }\n  ],\n  \"currPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.17789743341205072,\n      \"y\": 0.041486394567458444,\n      \"z\": -0.01102328163581174,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.014473349347095515,\n      \"y\": 0.08768228481294407,\n      \"z\": -0.0403391766686948,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.22704293206189974,\n      \"y\": 0.1072683853234789,\n      \"z\": -0.06864591425848976,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.1559122995456502,\n      \"y\": 0.07488873052838893,\n      \"z\": -0.03401219588847514,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.03633692715026824,\n      \"y\": 0.08027116785287161,\n      \"z\": -0.00767330212393115,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.026948629422220014,\n      \"y\": 0.06579105966878422,\n      \"z\": -0.07140590592777141,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.20418421289392086,\n      \"y\": 0.09193517655633694,\n      \"z\": 0.05031145680080939,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.1964021342153946,\n      \"y\": 0.013739110241204867,\n      \"z\": -0.13811779980349198,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.18275794264673953,\n      \"y\": 0.19833575745067059,\n      \"z\": -0.11767613594020734,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.5511693140299375,\n      \"y\": 0.15767232769214223,\n      \"z\": -0.10050514576412907,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.02962137958361095,\n      \"y\": 0.051161876041023104,\n      \"z\": -0.03427312482199797,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.08414160004324167,\n      \"y\": 0.25719562338525875,\n      \"z\": -0.08106287891163873,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.17750370037110597,\n      \"y\": 0.2764963146388356,\n      \"z\": -0.02197503307897435,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.2334122547586903,\n      \"y\": 0.2868679404391176,\n      \"z\": -0.055269678336151415,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.2375867703392531,\n      \"y\": 0.20992217897201668,\n      \"z\": -0.21657906021957696,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": 0.08843694054018707,\n      \"y\": 0.20337852971825224,\n      \"z\": -0.18083324645635449,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.35476248631713714,\n      \"y\": 0.13642564450474698,\n      \"z\": -0.073570671669389,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.3565564324405372,\n      \"y\": 0.1373261247261259,\n      \"z\": -0.033621067337867364,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.36774143291855765,\n      \"y\": 0.10060112988818651,\n      \"z\": -0.04485363344936705,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.356657044262082,\n      \"y\": 0.08323129943883235,\n      \"z\": -0.0791381100764957,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.3581160138999636,\n      \"y\": 0.11299790672207702,\n      \"z\": -0.10581807495676626,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10681362016257975,\n      \"y\": 0.07804390141301329,\n      \"z\": 0.15000000000000002,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10673384169218103,\n      \"y\": -0.16157935213890554,\n      \"z\": 0.05,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.1664390941194426,\n      \"y\": -0.09898498850178918,\n      \"z\": -0.050000000000000024,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.06217528763136241,\n      \"y\": 0.11676572103129135,\n      \"z\": -0.15000000000000002,\n      \"index\": 24\n    }\n  ]\n}"
  },
  {
    "timestamp": 83547,
    "eventType": "setLinkType() called",
    "eventData": "{\n  \"currLinkType\": \"recommendation\",\n  \"newLinkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 83547,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type recommendation\"\n}"
  },
  {
    "timestamp": 83547,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 86519,
    "eventType": "Socket - on unpinNodes",
    "eventData": "{\n  \"data\": {\n    \"info\": \"Event: \\\"unpinNodes\\\"\"\n  }\n}"
  },
  {
    "timestamp": 86520,
    "eventType": "unpinNodes() called",
    "eventData": "{\n  \"pinnedNodeIds\": [\n    \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n    \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n  ]\n}"
  },
  {
    "timestamp": 86871,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.06841830437151111,\n    \"_y\": 0.24427768117640652,\n    \"_z\": -0.11390237577716239\n  }\n}"
  },
  {
    "timestamp": 86871,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n    \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n    \"x\": 0.06841830437151111,\n    \"y\": 0.24427768117640652,\n    \"z\": -0.11390237577716239,\n    \"index\": 11\n  }\n}"
  },
  {
    "timestamp": 86871,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 87162,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.06884402743496223,\n    \"_y\": 0.24453362184736452,\n    \"_z\": -0.11415850327527946\n  }\n}"
  },
  {
    "timestamp": 87163,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.06884402743496223,\n    \"_y\": 0.24453362184736452,\n    \"_z\": -0.11415850327527946\n  }\n}"
  },
  {
    "timestamp": 87310,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.0689992997774375,\n    \"_y\": 0.24463853583378817,\n    \"_z\": -0.11425796146910128\n  }\n}"
  },
  {
    "timestamp": 87314,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.06780569407189854,\n    \"_y\": 0.2446008738348011,\n    \"_z\": -0.1141610545516212\n  }\n}"
  },
  {
    "timestamp": 87326,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.06780569407189854,\n    \"_y\": 0.2446008738348011,\n    \"_z\": -0.1141610545516212\n  }\n}"
  },
  {
    "timestamp": 87330,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.06495401601339348,\n    \"_y\": 0.2445948537656788,\n    \"_z\": -0.1140087125301559\n  }\n}"
  },
  {
    "timestamp": 87344,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.06495401601339348,\n    \"_y\": 0.2445948537656788,\n    \"_z\": -0.1140087125301559\n  }\n}"
  },
  {
    "timestamp": 87348,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.059405434532413565,\n    \"_y\": 0.24462192917556802,\n    \"_z\": -0.11376909068228794\n  }\n}"
  },
  {
    "timestamp": 87360,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.059405434532413565,\n    \"_y\": 0.24462192917556802,\n    \"_z\": -0.11376909068228794\n  }\n}"
  },
  {
    "timestamp": 87361,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.059405434532413565,\n    \"_y\": 0.24462192917556802,\n    \"_z\": -0.11376909068228794\n  }\n}"
  },
  {
    "timestamp": 87364,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.04912669735992917,\n    \"_y\": 0.2450438928076748,\n    \"_z\": -0.11347449472548557\n  }\n}"
  },
  {
    "timestamp": 87376,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.04912669735992917,\n    \"_y\": 0.2450438928076748,\n    \"_z\": -0.11347449472548557\n  }\n}"
  },
  {
    "timestamp": 87381,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.034598884759793364,\n    \"_y\": 0.2460195016333584,\n    \"_z\": -0.11326494342090679\n  }\n}"
  },
  {
    "timestamp": 87394,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.034598884759793364,\n    \"_y\": 0.2460195016333584,\n    \"_z\": -0.11326494342090679\n  }\n}"
  },
  {
    "timestamp": 87396,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.01869576168744483,\n    \"_y\": 0.24688598925561944,\n    \"_z\": -0.11315657100083423\n  }\n}"
  },
  {
    "timestamp": 87409,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.01869576168744483,\n    \"_y\": 0.24688598925561944,\n    \"_z\": -0.11315657100083423\n  }\n}"
  },
  {
    "timestamp": 87413,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.0021055794836453423,\n    \"_y\": 0.24767961765022317,\n    \"_z\": -0.11320105841757847\n  }\n}"
  },
  {
    "timestamp": 87426,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.0021055794836453423,\n    \"_y\": 0.24767961765022317,\n    \"_z\": -0.11320105841757847\n  }\n}"
  },
  {
    "timestamp": 87431,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.01482114905459217,\n    \"_y\": 0.24914569819660226,\n    \"_z\": -0.11355234584214283\n  }\n}"
  },
  {
    "timestamp": 87442,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.01482114905459217,\n    \"_y\": 0.24914569819660226,\n    \"_z\": -0.11355234584214283\n  }\n}"
  },
  {
    "timestamp": 87446,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.03078050689739517,\n    \"_y\": 0.25093459004850427,\n    \"_z\": -0.11412319815160823\n  }\n}"
  },
  {
    "timestamp": 87460,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.03078050689739517,\n    \"_y\": 0.25093459004850427,\n    \"_z\": -0.11412319815160823\n  }\n}"
  },
  {
    "timestamp": 87463,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.046241950820808925,\n    \"_y\": 0.2532320212790493,\n    \"_z\": -0.11494698649646831\n  }\n}"
  },
  {
    "timestamp": 87477,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.046241950820808925,\n    \"_y\": 0.2532320212790493,\n    \"_z\": -0.11494698649646831\n  }\n}"
  },
  {
    "timestamp": 87480,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.06106202175808481,\n    \"_y\": 0.2561323832938198,\n    \"_z\": -0.11602225056292606\n  }\n}"
  },
  {
    "timestamp": 87495,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.06106202175808481,\n    \"_y\": 0.2561323832938198,\n    \"_z\": -0.11602225056292606\n  }\n}"
  },
  {
    "timestamp": 87498,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.07480215525222353,\n    \"_y\": 0.25896419996709863,\n    \"_z\": -0.11718266731502605\n  }\n}"
  },
  {
    "timestamp": 87512,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.07480215525222353,\n    \"_y\": 0.25896419996709863,\n    \"_z\": -0.11718266731502605\n  }\n}"
  },
  {
    "timestamp": 87515,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.08687075098944239,\n    \"_y\": 0.26176256353349725,\n    \"_z\": -0.11836573010685039\n  }\n}"
  },
  {
    "timestamp": 87529,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.08687075098944239,\n    \"_y\": 0.26176256353349725,\n    \"_z\": -0.11836573010685039\n  }\n}"
  },
  {
    "timestamp": 87531,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09698208292913965,\n    \"_y\": 0.264189500755978,\n    \"_z\": -0.1194483627975185\n  }\n}"
  },
  {
    "timestamp": 87545,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09698208292913965,\n    \"_y\": 0.264189500755978,\n    \"_z\": -0.1194483627975185\n  }\n}"
  },
  {
    "timestamp": 87547,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.10499910509181551,\n    \"_y\": 0.26608108396024743,\n    \"_z\": -0.12034937641026569\n  }\n}"
  },
  {
    "timestamp": 87563,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10499910509181551,\n    \"_y\": 0.26608108396024743,\n    \"_z\": -0.12034937641026569\n  }\n}"
  },
  {
    "timestamp": 87564,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.11085780208898119,\n    \"_y\": 0.26735915655584375,\n    \"_z\": -0.12101390859486652\n  }\n}"
  },
  {
    "timestamp": 87581,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.11378715058756403,\n    \"_y\": 0.2679981928536419,\n    \"_z\": -0.12134617468716694\n  }\n}"
  },
  {
    "timestamp": 87596,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11378715058756403,\n    \"_y\": 0.2679981928536419,\n    \"_z\": -0.12134617468716694\n  }\n}"
  },
  {
    "timestamp": 87596,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n    \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n    \"x\": -0.11378715058756403,\n    \"y\": 0.2679981928536419,\n    \"z\": -0.12134617468716694,\n    \"index\": 11\n  }\n}"
  },
  {
    "timestamp": 87596,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 87596,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11378715058756403,\n    \"_y\": 0.2679981928536419,\n    \"_z\": -0.12134617468716694\n  }\n}"
  },
  {
    "timestamp": 87598,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.11673541611028246,\n    \"_y\": 0.2682948898741726,\n    \"_z\": -0.12163239619137836\n  }\n}"
  },
  {
    "timestamp": 87611,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11673541611028246,\n    \"_y\": 0.2682948898741726,\n    \"_z\": -0.12163239619137836\n  }\n}"
  },
  {
    "timestamp": 87614,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.12006296833944849,\n    \"_y\": 0.2684138756463055,\n    \"_z\": -0.12192978984119487\n  }\n}"
  },
  {
    "timestamp": 87627,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.12006296833944849,\n    \"_y\": 0.2684138756463055,\n    \"_z\": -0.12192978984119487\n  }\n}"
  },
  {
    "timestamp": 87631,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.1243133792836719,\n    \"_y\": 0.26879036838502923,\n    \"_z\": -0.12237032032014919\n  }\n}"
  },
  {
    "timestamp": 87643,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1243133792836719,\n    \"_y\": 0.26879036838502923,\n    \"_z\": -0.12237032032014919\n  }\n}"
  },
  {
    "timestamp": 87647,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.12974878272009424,\n    \"_y\": 0.2699988376566891,\n    \"_z\": -0.12309649860860897\n  }\n}"
  },
  {
    "timestamp": 87662,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.12974878272009424,\n    \"_y\": 0.2699988376566891,\n    \"_z\": -0.12309649860860897\n  }\n}"
  },
  {
    "timestamp": 87662,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.12974878272009424,\n    \"_y\": 0.2699988376566891,\n    \"_z\": -0.12309649860860897\n  }\n}"
  },
  {
    "timestamp": 87664,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.13650130351973108,\n    \"_y\": 0.2719630342194561,\n    \"_z\": -0.12412251061203075\n  }\n}"
  },
  {
    "timestamp": 87679,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.13650130351973108,\n    \"_y\": 0.2719630342194561,\n    \"_z\": -0.12412251061203075\n  }\n}"
  },
  {
    "timestamp": 87681,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.14427763095093302,\n    \"_y\": 0.27393210346193353,\n    \"_z\": -0.12529098144175602\n  }\n}"
  },
  {
    "timestamp": 87693,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.14427763095093302,\n    \"_y\": 0.27393210346193353,\n    \"_z\": -0.12529098144175602\n  }\n}"
  },
  {
    "timestamp": 87696,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.15183557441425852,\n    \"_y\": 0.27519704813451806,\n    \"_z\": -0.12633737823369098\n  }\n}"
  },
  {
    "timestamp": 87710,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.15183557441425852,\n    \"_y\": 0.27519704813451806,\n    \"_z\": -0.12633737823369098\n  }\n}"
  },
  {
    "timestamp": 87713,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.1589105935950332,\n    \"_y\": 0.27611411029787103,\n    \"_z\": -0.12729883840682102\n  }\n}"
  },
  {
    "timestamp": 87727,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1589105935950332,\n    \"_y\": 0.27611411029787103,\n    \"_z\": -0.12729883840682102\n  }\n}"
  },
  {
    "timestamp": 87730,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.16537203511190943,\n    \"_y\": 0.27686246151418725,\n    \"_z\": -0.12818909338118625\n  }\n}"
  },
  {
    "timestamp": 87744,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.16537203511190943,\n    \"_y\": 0.27686246151418725,\n    \"_z\": -0.12818909338118625\n  }\n}"
  },
  {
    "timestamp": 87744,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n    \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n    \"x\": -0.16537203511190943,\n    \"y\": 0.27686246151418725,\n    \"z\": -0.12818909338118625,\n    \"index\": 11\n  }\n}"
  },
  {
    "timestamp": 87744,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 87744,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.16537203511190943,\n    \"_y\": 0.27686246151418725,\n    \"_z\": -0.12818909338118625\n  }\n}"
  },
  {
    "timestamp": 87747,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17042451223326258,\n    \"_y\": 0.2775502097079281,\n    \"_z\": -0.12892208150031162\n  }\n}"
  },
  {
    "timestamp": 87765,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17295075079393915,\n    \"_y\": 0.2778940838047985,\n    \"_z\": -0.1292885755598743\n  }\n}"
  },
  {
    "timestamp": 87779,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17295075079393915,\n    \"_y\": 0.2778940838047985,\n    \"_z\": -0.1292885755598743\n  }\n}"
  },
  {
    "timestamp": 87780,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.175302437152391,\n    \"_y\": 0.27839632744283715,\n    \"_z\": -0.1296746720969875\n  }\n}"
  },
  {
    "timestamp": 87798,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17647828033161692,\n    \"_y\": 0.2786474418112759,\n    \"_z\": -0.1298677166402538\n  }\n}"
  },
  {
    "timestamp": 87815,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17706619819593958,\n    \"_y\": 0.27877299899549524,\n    \"_z\": -0.12996423891188694\n  }\n}"
  },
  {
    "timestamp": 87831,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.1773601608533912,\n    \"_y\": 0.2788357775876049,\n    \"_z\": -0.1300125037729938\n  }\n}"
  },
  {
    "timestamp": 87847,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17750713845682672,\n    \"_y\": 0.27886717433424035,\n    \"_z\": -0.13003663620354725\n  }\n}"
  },
  {
    "timestamp": 87864,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17758063098383478,\n    \"_y\": 0.2788828652569775,\n    \"_z\": -0.13004869869353367\n  }\n}"
  },
  {
    "timestamp": 87880,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.1776173772473388,\n    \"_y\": 0.27889071816892663,\n    \"_z\": -0.13005473366381717\n  }\n}"
  },
  {
    "timestamp": 87896,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17763575037909082,\n    \"_y\": 0.2788946371743206,\n    \"_z\": -0.13005775114895893\n  }\n}"
  },
  {
    "timestamp": 87911,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17763575037909082,\n    \"_y\": 0.2788946371743206,\n    \"_z\": -0.13005775114895893\n  }\n}"
  },
  {
    "timestamp": 87913,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17801929881763986,\n    \"_y\": 0.2785308998295788,\n    \"_z\": -0.13003412535788608\n  }\n}"
  },
  {
    "timestamp": 87929,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17801929881763986,\n    \"_y\": 0.2785308998295788,\n    \"_z\": -0.13003412535788608\n  }\n}"
  },
  {
    "timestamp": 87930,
    "eventType": "node onPickUpTrigger - node is already being dragged",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17801929881763986,\n    \"_y\": 0.2785308998295788,\n    \"_z\": -0.13003412535788608\n  }\n}"
  },
  {
    "timestamp": 87930,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17801929881763986,\n    \"_y\": 0.2785308998295788,\n    \"_z\": -0.13003412535788608\n  }\n}"
  },
  {
    "timestamp": 88246,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17801929881763986,\n    \"_y\": 0.2785308998295788,\n    \"_z\": -0.13003412535788608\n  }\n}"
  },
  {
    "timestamp": 88246,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 88246,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 88246,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 89095,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17801929881763986,\n    \"_y\": 0.2785308998295788,\n    \"_z\": -0.13003412535788608\n  }\n}"
  },
  {
    "timestamp": 89095,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n    \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n    \"x\": -0.17801929881763986,\n    \"y\": 0.2785308998295788,\n    \"z\": -0.13003412535788608,\n    \"index\": 11\n  }\n}"
  },
  {
    "timestamp": 89095,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 89279,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17801929881763986,\n    \"_y\": 0.2785308998295788,\n    \"_z\": -0.13003412535788608\n  }\n}"
  },
  {
    "timestamp": 89279,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17801929881763986,\n    \"_y\": 0.2785308998295788,\n    \"_z\": -0.13003412535788608\n  }\n}"
  },
  {
    "timestamp": 89280,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17801929881763986,\n    \"_y\": 0.2785308998295788,\n    \"_z\": -0.13003412535788608\n  }\n}"
  },
  {
    "timestamp": 89281,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17801041027498773,\n    \"_y\": 0.2788876187273983,\n    \"_z\": -0.13010407140853\n  }\n}"
  },
  {
    "timestamp": 89297,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17800596972895197,\n    \"_y\": 0.2790659707257275,\n    \"_z\": -0.13013904443385196\n  }\n}"
  },
  {
    "timestamp": 89314,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17800374945593408,\n    \"_y\": 0.27915515417547265,\n    \"_z\": -0.13015653094651294\n  }\n}"
  },
  {
    "timestamp": 89330,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.17800263931942514,\n    \"_y\": 0.27919973844976465,\n    \"_z\": -0.13016527047755314\n  }\n}"
  },
  {
    "timestamp": 89346,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17800263931942514,\n    \"_y\": 0.27919973844976465,\n    \"_z\": -0.13016527047755314\n  }\n}"
  },
  {
    "timestamp": 89346,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17800263931942514,\n    \"_y\": 0.27919973844976465,\n    \"_z\": -0.13016527047755314\n  }\n}"
  },
  {
    "timestamp": 89346,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17800263931942514,\n    \"_y\": 0.27919973844976465,\n    \"_z\": -0.13016527047755314\n  }\n}"
  },
  {
    "timestamp": 89483,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.17800263931942514,\n    \"_y\": 0.27919973844976465,\n    \"_z\": -0.13016527047755314\n  }\n}"
  },
  {
    "timestamp": 89483,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 89483,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 89483,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 92653,
    "eventType": "Socket - on recommendByReferences",
    "eventData": "{\n  \"data\": {\n    \"info\": \"Event: \\\"recommendByReferences\\\"\"\n  }\n}"
  },
  {
    "timestamp": 92653,
    "eventType": "addReferencesFromSelectedPaper() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"95e706662b99267d21a1ccc7ed380d1cd0e06057\"\n  ],\n  \"currPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.07730153136762265,\n      \"y\": 0.05630937491199285,\n      \"z\": -0.019030459053187905,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.0036752406467722987,\n      \"y\": 0.12747724388893555,\n      \"z\": -0.07582362598365255,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.11818624528882166,\n      \"y\": 0.14312443313139067,\n      \"z\": -0.08775431735246733,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.18183148203605737,\n      \"y\": 0.08467653761521703,\n      \"z\": -0.006178188984774709,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.09057114696059344,\n      \"y\": 0.1704079073562667,\n      \"z\": 0.01916084079766927,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07746379187621519,\n      \"y\": 0.03954610941633035,\n      \"z\": -0.13151532772623434,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14534262955404204,\n      \"y\": 0.2242995897276167,\n      \"z\": 0.005198204093079035,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.15814996090235917,\n      \"y\": 0.09886423019640385,\n      \"z\": -0.20501337846723858,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.029160162978676834,\n      \"y\": 0.22043593315798402,\n      \"z\": -0.12502066551318286,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.23801302786956602,\n      \"y\": 0.14261297944317564,\n      \"z\": -0.11374495139246653,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.11110622983109451,\n      \"y\": 0.022014968236792977,\n      \"z\": -0.1188283259262903,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.17800263931942514,\n      \"y\": 0.27919973844976465,\n      \"z\": -0.13016527047755314,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.022031901897732672,\n      \"y\": 0.33126246936159653,\n      \"z\": -0.09107099638038445,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.12062065642603162,\n      \"y\": 0.2929713985848971,\n      \"z\": -0.17383680083458034,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.09748040014196227,\n      \"y\": 0.21712247041620752,\n      \"z\": -0.22922993031317915,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.02310895690315683,\n      \"y\": 0.19562838083617137,\n      \"z\": -0.2309488655193905,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.28583364454174814,\n      \"y\": 0.13334197106496348,\n      \"z\": -0.0031841705120095347,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.24269203642482023,\n      \"y\": 0.18569259145102052,\n      \"z\": -0.012699295581278162,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.28786637366661566,\n      \"y\": 0.08064375481941734,\n      \"z\": -0.020321835236568095,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.2805999587536829,\n      \"y\": 0.04273483473752998,\n      \"z\": -0.054881973266359324,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.25538806478753917,\n      \"y\": 0.020522557754677397,\n      \"z\": -0.07658511328400303,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": 0.0013728352906430877,\n      \"y\": 0.10698403734977259,\n      \"z\": 0.07711005706413954,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": 0.021899963539719503,\n      \"y\": -0.008093614734505249,\n      \"z\": 0.07008187019316851,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.04807173939261283,\n      \"y\": -0.06397197272014925,\n      \"z\": -0.009700273912109283,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.050150342327420605,\n      \"y\": 0.057928205662022454,\n      \"z\": -0.057511130218052,\n      \"index\": 24\n    }\n  ]\n}"
  },
  {
    "timestamp": 96689,
    "eventType": "addPapersToGraph() called",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\"\n    }\n  ],\n  \"prevPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.07729032136477061,\n      \"y\": 0.056333482808716855,\n      \"z\": -0.019032383727788996,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.0036329021702705784,\n      \"y\": 0.1274562186636893,\n      \"z\": -0.07579233909937688,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.11812602930323039,\n      \"y\": 0.1431722400863599,\n      \"z\": -0.08775976952339956,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.18182031354505293,\n      \"y\": 0.0847460292008459,\n      \"z\": -0.00623262570594164,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.09053601332500909,\n      \"y\": 0.17042216827764228,\n      \"z\": 0.019171808690580414,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07745052556196072,\n      \"y\": 0.039587471533306835,\n      \"z\": -0.13153005910389173,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14532143310774112,\n      \"y\": 0.22433941479099778,\n      \"z\": 0.00519262136317546,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.15808773327139752,\n      \"y\": 0.0990086502479199,\n      \"z\": -0.2050650630236594,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.029104898446926493,\n      \"y\": 0.22048167040119648,\n      \"z\": -0.1250017469406521,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.23798472006857144,\n      \"y\": 0.14266206074963336,\n      \"z\": -0.11376833839854682,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.11110034394298969,\n      \"y\": 0.02205714535573967,\n      \"z\": -0.11886603065883902,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.17800263931942514,\n      \"y\": 0.27919973844976465,\n      \"z\": -0.13016527047755314,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.021885836026074617,\n      \"y\": 0.3312578855144837,\n      \"z\": -0.09102706406122377,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.1205679172858783,\n      \"y\": 0.29301455167257173,\n      \"z\": -0.17383015471033883,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.09740222979849125,\n      \"y\": 0.21716366497138012,\n      \"z\": -0.2292192623936967,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.023241336174634704,\n      \"y\": 0.19562248596761603,\n      \"z\": -0.23090764199636785,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.28580178035699855,\n      \"y\": 0.1334263418920025,\n      \"z\": -0.003246758337452944,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.24267296259123233,\n      \"y\": 0.18575439634295943,\n      \"z\": -0.012733043020194295,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.28784618879770635,\n      \"y\": 0.08072113077429709,\n      \"z\": -0.020413731257233527,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.28058257383562263,\n      \"y\": 0.042830915122791614,\n      \"z\": -0.05498741571801334,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.2553557641453731,\n      \"y\": 0.020628125731457236,\n      \"z\": -0.07668175620828768,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": 0.0013921172859166942,\n      \"y\": 0.10690413094868292,\n      \"z\": 0.07716210889432819,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": 0.021975240731932858,\n      \"y\": -0.008115188994125333,\n      \"z\": 0.07009786525839977,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.04817236844431942,\n      \"y\": -0.06400332962916312,\n      \"z\": -0.009675413688096626,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.05015736201712925,\n      \"y\": 0.057859780486198185,\n      \"z\": -0.057478263255616224,\n      \"index\": 24\n    }\n  ]\n}"
  },
  {
    "timestamp": 96690,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.2,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.11360601073437589,\n      \"_y\": 0.03864808307045599,\n      \"_z\": 0.16000000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.06716445689472866,\n      \"_y\": 0.17055478805954447,\n      \"_z\": 0.08000000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.18242254438833713,\n      \"_y\": -0.08198789727078731,\n      \"_z\": 1.2246467991473533e-17\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.08295419823200749,\n      \"_y\": -0.16345825459634886,\n      \"_z\": -0.08\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.10432483200452466,\n      \"_y\": 0.05929864608258527,\n      \"_z\": -0.16000000000000003\n    }\n  ]\n}"
  },
  {
    "timestamp": 96690,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.07729032136477061,\n      \"y\": 0.056333482808716855,\n      \"z\": -0.019032383727788996,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.0036329021702705784,\n      \"y\": 0.1274562186636893,\n      \"z\": -0.07579233909937688,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.11812602930323039,\n      \"y\": 0.1431722400863599,\n      \"z\": -0.08775976952339956,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.18182031354505293,\n      \"y\": 0.0847460292008459,\n      \"z\": -0.00623262570594164,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.09053601332500909,\n      \"y\": 0.17042216827764228,\n      \"z\": 0.019171808690580414,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07745052556196072,\n      \"y\": 0.039587471533306835,\n      \"z\": -0.13153005910389173,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14532143310774112,\n      \"y\": 0.22433941479099778,\n      \"z\": 0.00519262136317546,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.15808773327139752,\n      \"y\": 0.0990086502479199,\n      \"z\": -0.2050650630236594,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.029104898446926493,\n      \"y\": 0.22048167040119648,\n      \"z\": -0.1250017469406521,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.23798472006857144,\n      \"y\": 0.14266206074963336,\n      \"z\": -0.11376833839854682,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.11110034394298969,\n      \"y\": 0.02205714535573967,\n      \"z\": -0.11886603065883902,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.17800263931942514,\n      \"y\": 0.27919973844976465,\n      \"z\": -0.13016527047755314,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.021885836026074617,\n      \"y\": 0.3312578855144837,\n      \"z\": -0.09102706406122377,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.1205679172858783,\n      \"y\": 0.29301455167257173,\n      \"z\": -0.17383015471033883,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.09740222979849125,\n      \"y\": 0.21716366497138012,\n      \"z\": -0.2292192623936967,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.023241336174634704,\n      \"y\": 0.19562248596761603,\n      \"z\": -0.23090764199636785,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.28580178035699855,\n      \"y\": 0.1334263418920025,\n      \"z\": -0.003246758337452944,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.24267296259123233,\n      \"y\": 0.18575439634295943,\n      \"z\": -0.012733043020194295,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.28784618879770635,\n      \"y\": 0.08072113077429709,\n      \"z\": -0.020413731257233527,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.28058257383562263,\n      \"y\": 0.042830915122791614,\n      \"z\": -0.05498741571801334,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.2553557641453731,\n      \"y\": 0.020628125731457236,\n      \"z\": -0.07668175620828768,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": 0.0013921172859166942,\n      \"y\": 0.10690413094868292,\n      \"z\": 0.07716210889432819,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": 0.021975240731932858,\n      \"y\": -0.008115188994125333,\n      \"z\": 0.07009786525839977,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.04817236844431942,\n      \"y\": -0.06400332962916312,\n      \"z\": -0.009675413688096626,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.05015736201712925,\n      \"y\": 0.057859780486198185,\n      \"z\": -0.057478263255616224,\n      \"index\": 24\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.11360601073437589,\n      \"y\": 0.03864808307045599,\n      \"z\": 0.16000000000000003,\n      \"index\": 25\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.06716445689472866,\n      \"y\": 0.17055478805954447,\n      \"z\": 0.08000000000000002,\n      \"index\": 26\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.18242254438833713,\n      \"y\": -0.08198789727078731,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 27\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.08295419823200749,\n      \"y\": -0.16345825459634886,\n      \"z\": -0.08,\n      \"index\": 28\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": 0.10432483200452466,\n      \"y\": 0.05929864608258527,\n      \"z\": -0.16000000000000003,\n      \"index\": 29\n    }\n  ]\n}"
  },
  {
    "timestamp": 96712,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.07729032136477061,\n      \"y\": 0.056333482808716855,\n      \"z\": -0.019032383727788996,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.0036329021702705784,\n      \"y\": 0.1274562186636893,\n      \"z\": -0.07579233909937688,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.11812602930323039,\n      \"y\": 0.1431722400863599,\n      \"z\": -0.08775976952339956,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.18182031354505293,\n      \"y\": 0.0847460292008459,\n      \"z\": -0.00623262570594164,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.09053601332500909,\n      \"y\": 0.17042216827764228,\n      \"z\": 0.019171808690580414,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07745052556196072,\n      \"y\": 0.039587471533306835,\n      \"z\": -0.13153005910389173,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14532143310774112,\n      \"y\": 0.22433941479099778,\n      \"z\": 0.00519262136317546,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.15808773327139752,\n      \"y\": 0.0990086502479199,\n      \"z\": -0.2050650630236594,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.029104898446926493,\n      \"y\": 0.22048167040119648,\n      \"z\": -0.1250017469406521,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.23798472006857144,\n      \"y\": 0.14266206074963336,\n      \"z\": -0.11376833839854682,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.11110034394298969,\n      \"y\": 0.02205714535573967,\n      \"z\": -0.11886603065883902,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.17800263931942514,\n      \"y\": 0.27919973844976465,\n      \"z\": -0.13016527047755314,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.021885836026074617,\n      \"y\": 0.3312578855144837,\n      \"z\": -0.09102706406122377,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.1205679172858783,\n      \"y\": 0.29301455167257173,\n      \"z\": -0.17383015471033883,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.09740222979849125,\n      \"y\": 0.21716366497138012,\n      \"z\": -0.2292192623936967,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.023241336174634704,\n      \"y\": 0.19562248596761603,\n      \"z\": -0.23090764199636785,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.28580178035699855,\n      \"y\": 0.1334263418920025,\n      \"z\": -0.003246758337452944,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.24267296259123233,\n      \"y\": 0.18575439634295943,\n      \"z\": -0.012733043020194295,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.28784618879770635,\n      \"y\": 0.08072113077429709,\n      \"z\": -0.020413731257233527,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.28058257383562263,\n      \"y\": 0.042830915122791614,\n      \"z\": -0.05498741571801334,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.2553557641453731,\n      \"y\": 0.020628125731457236,\n      \"z\": -0.07668175620828768,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": 0.0013921172859166942,\n      \"y\": 0.10690413094868292,\n      \"z\": 0.07716210889432819,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": 0.021975240731932858,\n      \"y\": -0.008115188994125333,\n      \"z\": 0.07009786525839977,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.04817236844431942,\n      \"y\": -0.06400332962916312,\n      \"z\": -0.009675413688096626,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.05015736201712925,\n      \"y\": 0.057859780486198185,\n      \"z\": -0.057478263255616224,\n      \"index\": 24\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.11360601073437589,\n      \"y\": 0.03864808307045599,\n      \"z\": 0.16000000000000003,\n      \"index\": 25\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.06716445689472866,\n      \"y\": 0.17055478805954447,\n      \"z\": 0.08000000000000002,\n      \"index\": 26\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.18242254438833713,\n      \"y\": -0.08198789727078731,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 27\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.08295419823200749,\n      \"y\": -0.16345825459634886,\n      \"z\": -0.08,\n      \"index\": 28\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": 0.10432483200452466,\n      \"y\": 0.05929864608258527,\n      \"z\": -0.16000000000000003,\n      \"index\": 29\n    }\n  ]\n}"
  },
  {
    "timestamp": 96716,
    "eventType": "generateLinkData() finished",
    "eventData": "{\n  \"newLinkData\": {\n    \"citationLinkData\": [\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      }\n    ],\n    \"recommendationLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"41163e665789ee13f2db5e442eea15fcb188c01c\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"f99c4e2092b186a815140e888768de9845b356c4\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      }\n    ],\n    \"authorLinkData\": [\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      }\n    ],\n    \"userLinkData\": []\n  }\n}"
  },
  {
    "timestamp": 96716,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 96716,
    "eventType": "addPapersToGraph() finished",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.11360601073437589,\n      \"y\": 0.03864808307045599,\n      \"z\": 0.16000000000000003,\n      \"index\": 25\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.06716445689472866,\n      \"y\": 0.17055478805954447,\n      \"z\": 0.08000000000000002,\n      \"index\": 26\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.18242254438833713,\n      \"y\": -0.08198789727078731,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 27\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.08295419823200749,\n      \"y\": -0.16345825459634886,\n      \"z\": -0.08,\n      \"index\": 28\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": 0.10432483200452466,\n      \"y\": 0.05929864608258527,\n      \"z\": -0.16000000000000003,\n      \"index\": 29\n    }\n  ],\n  \"currPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.07729032136477061,\n      \"y\": 0.056333482808716855,\n      \"z\": -0.019032383727788996,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.0036329021702705784,\n      \"y\": 0.1274562186636893,\n      \"z\": -0.07579233909937688,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.11812602930323039,\n      \"y\": 0.1431722400863599,\n      \"z\": -0.08775976952339956,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.18182031354505293,\n      \"y\": 0.0847460292008459,\n      \"z\": -0.00623262570594164,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.09053601332500909,\n      \"y\": 0.17042216827764228,\n      \"z\": 0.019171808690580414,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07745052556196072,\n      \"y\": 0.039587471533306835,\n      \"z\": -0.13153005910389173,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14532143310774112,\n      \"y\": 0.22433941479099778,\n      \"z\": 0.00519262136317546,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.15808773327139752,\n      \"y\": 0.0990086502479199,\n      \"z\": -0.2050650630236594,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.029104898446926493,\n      \"y\": 0.22048167040119648,\n      \"z\": -0.1250017469406521,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.23798472006857144,\n      \"y\": 0.14266206074963336,\n      \"z\": -0.11376833839854682,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.11110034394298969,\n      \"y\": 0.02205714535573967,\n      \"z\": -0.11886603065883902,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.17800263931942514,\n      \"y\": 0.27919973844976465,\n      \"z\": -0.13016527047755314,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.021885836026074617,\n      \"y\": 0.3312578855144837,\n      \"z\": -0.09102706406122377,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.1205679172858783,\n      \"y\": 0.29301455167257173,\n      \"z\": -0.17383015471033883,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.09740222979849125,\n      \"y\": 0.21716366497138012,\n      \"z\": -0.2292192623936967,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.023241336174634704,\n      \"y\": 0.19562248596761603,\n      \"z\": -0.23090764199636785,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.28580178035699855,\n      \"y\": 0.1334263418920025,\n      \"z\": -0.003246758337452944,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.24267296259123233,\n      \"y\": 0.18575439634295943,\n      \"z\": -0.012733043020194295,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.28784618879770635,\n      \"y\": 0.08072113077429709,\n      \"z\": -0.020413731257233527,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.28058257383562263,\n      \"y\": 0.042830915122791614,\n      \"z\": -0.05498741571801334,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.2553557641453731,\n      \"y\": 0.020628125731457236,\n      \"z\": -0.07668175620828768,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": 0.0013921172859166942,\n      \"y\": 0.10690413094868292,\n      \"z\": 0.07716210889432819,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": 0.021975240731932858,\n      \"y\": -0.008115188994125333,\n      \"z\": 0.07009786525839977,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.04817236844431942,\n      \"y\": -0.06400332962916312,\n      \"z\": -0.009675413688096626,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.05015736201712925,\n      \"y\": 0.057859780486198185,\n      \"z\": -0.057478263255616224,\n      \"index\": 24\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.11360601073437589,\n      \"y\": 0.03864808307045599,\n      \"z\": 0.16000000000000003,\n      \"index\": 25\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.06716445689472866,\n      \"y\": 0.17055478805954447,\n      \"z\": 0.08000000000000002,\n      \"index\": 26\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.18242254438833713,\n      \"y\": -0.08198789727078731,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 27\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.08295419823200749,\n      \"y\": -0.16345825459634886,\n      \"z\": -0.08,\n      \"index\": 28\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": 0.10432483200452466,\n      \"y\": 0.05929864608258527,\n      \"z\": -0.16000000000000003,\n      \"index\": 29\n    }\n  ]\n}"
  },
  {
    "timestamp": 96716,
    "eventType": "setLinkType() called",
    "eventData": "{\n  \"currLinkType\": \"recommendation\",\n  \"newLinkType\": \"citation\"\n}"
  },
  {
    "timestamp": 96716,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type citation\"\n}"
  },
  {
    "timestamp": 96716,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"citation\"\n}"
  },
  {
    "timestamp": 96716,
    "eventType": "addReferencesFromSelectedPaper() finished",
    "eventData": "{\n  \"selectedIds\": [],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.07729032136477061,\n      \"y\": 0.056333482808716855,\n      \"z\": -0.019032383727788996,\n      \"index\": 0\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.0036329021702705784,\n      \"y\": 0.1274562186636893,\n      \"z\": -0.07579233909937688,\n      \"index\": 1\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.11812602930323039,\n      \"y\": 0.1431722400863599,\n      \"z\": -0.08775976952339956,\n      \"index\": 2\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.18182031354505293,\n      \"y\": 0.0847460292008459,\n      \"z\": -0.00623262570594164,\n      \"index\": 3\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.09053601332500909,\n      \"y\": 0.17042216827764228,\n      \"z\": 0.019171808690580414,\n      \"index\": 4\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.07745052556196072,\n      \"y\": 0.039587471533306835,\n      \"z\": -0.13153005910389173,\n      \"index\": 5\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14532143310774112,\n      \"y\": 0.22433941479099778,\n      \"z\": 0.00519262136317546,\n      \"index\": 6\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.15808773327139752,\n      \"y\": 0.0990086502479199,\n      \"z\": -0.2050650630236594,\n      \"index\": 7\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.029104898446926493,\n      \"y\": 0.22048167040119648,\n      \"z\": -0.1250017469406521,\n      \"index\": 8\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.23798472006857144,\n      \"y\": 0.14266206074963336,\n      \"z\": -0.11376833839854682,\n      \"index\": 9\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.11110034394298969,\n      \"y\": 0.02205714535573967,\n      \"z\": -0.11886603065883902,\n      \"index\": 10\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.17800263931942514,\n      \"y\": 0.27919973844976465,\n      \"z\": -0.13016527047755314,\n      \"index\": 11\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.021885836026074617,\n      \"y\": 0.3312578855144837,\n      \"z\": -0.09102706406122377,\n      \"index\": 12\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.1205679172858783,\n      \"y\": 0.29301455167257173,\n      \"z\": -0.17383015471033883,\n      \"index\": 13\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.09740222979849125,\n      \"y\": 0.21716366497138012,\n      \"z\": -0.2292192623936967,\n      \"index\": 14\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.023241336174634704,\n      \"y\": 0.19562248596761603,\n      \"z\": -0.23090764199636785,\n      \"index\": 15\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.28580178035699855,\n      \"y\": 0.1334263418920025,\n      \"z\": -0.003246758337452944,\n      \"index\": 16\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.24267296259123233,\n      \"y\": 0.18575439634295943,\n      \"z\": -0.012733043020194295,\n      \"index\": 17\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.28784618879770635,\n      \"y\": 0.08072113077429709,\n      \"z\": -0.020413731257233527,\n      \"index\": 18\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.28058257383562263,\n      \"y\": 0.042830915122791614,\n      \"z\": -0.05498741571801334,\n      \"index\": 19\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.2553557641453731,\n      \"y\": 0.020628125731457236,\n      \"z\": -0.07668175620828768,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": 0.0013921172859166942,\n      \"y\": 0.10690413094868292,\n      \"z\": 0.07716210889432819,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": 0.021975240731932858,\n      \"y\": -0.008115188994125333,\n      \"z\": 0.07009786525839977,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.04817236844431942,\n      \"y\": -0.06400332962916312,\n      \"z\": -0.009675413688096626,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.05015736201712925,\n      \"y\": 0.057859780486198185,\n      \"z\": -0.057478263255616224,\n      \"index\": 24\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.11360601073437589,\n      \"y\": 0.03864808307045599,\n      \"z\": 0.16000000000000003,\n      \"index\": 25\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.06716445689472866,\n      \"y\": 0.17055478805954447,\n      \"z\": 0.08000000000000002,\n      \"index\": 26\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.18242254438833713,\n      \"y\": -0.08198789727078731,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 27\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.08295419823200749,\n      \"y\": -0.16345825459634886,\n      \"z\": -0.08,\n      \"index\": 28\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": 0.10432483200452466,\n      \"y\": 0.05929864608258527,\n      \"z\": -0.16000000000000003,\n      \"index\": 29\n    }\n  ]\n}"
  },
  {
    "timestamp": 97329,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.05767665437511898,\n    \"_y\": 0.1676270810025578,\n    \"_z\": -0.33486297790022795\n  }\n}"
  },
  {
    "timestamp": 97329,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n    \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n    \"x\": -0.05767665437511898,\n    \"y\": 0.1676270810025578,\n    \"z\": -0.33486297790022795,\n    \"index\": 15\n  }\n}"
  },
  {
    "timestamp": 97329,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 97365,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.05729122682041639,\n    \"_y\": 0.16709955805511265,\n    \"_z\": -0.33548817571099454\n  }\n}"
  },
  {
    "timestamp": 97365,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 97365,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 97365,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 98804,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.057441953210280366,\n    \"_y\": 0.16816461758991794,\n    \"_z\": -0.3361873448004756\n  }\n}"
  },
  {
    "timestamp": 98804,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n    \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n    \"x\": -0.057441953210280366,\n    \"y\": 0.16816461758991794,\n    \"z\": -0.3361873448004756,\n    \"index\": 15\n  }\n}"
  },
  {
    "timestamp": 98804,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 98970,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.057531119871684334,\n    \"_y\": 0.16860653221901725,\n    \"_z\": -0.33637806432170597\n  }\n}"
  },
  {
    "timestamp": 98970,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 98970,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 98970,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 107473,
    "eventType": "Socket - on createClustersGemini",
    "eventData": "{\n  \"data\": {\n    \"status\": \"success\",\n    \"clusters\": [\n      {\n        \"name\": \"Image Classification and Neural Network Architectures\",\n        \"paperIds\": [\n          \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n          \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n          \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n          \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n          \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n          \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n          \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n          \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n        ]\n      },\n      {\n        \"name\": \"Dataset Pruning and Distillation\",\n        \"paperIds\": [\n          \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n          \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n          \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n          \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n          \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n        ]\n      },\n      {\n        \"name\": \"Generalization and Robustness in Deep Learning\",\n        \"paperIds\": [\n          \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n          \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n          \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n          \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n          \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n          \"357e28348a770052ff9b048ee3cb61be388fac21\",\n          \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n          \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n          \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n          \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n        ]\n      },\n      {\n        \"name\": \"Image Processing and Computer Vision Techniques\",\n        \"paperIds\": [\n          \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n          \"f99c4e2092b186a815140e888768de9845b356c4\",\n          \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n          \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n          \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n          \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n          \"1d10aa5e7122d1df6d559999987c76de3a088f62\"\n        ]\n      }\n    ]\n  }\n}"
  },
  {
    "timestamp": 107474,
    "eventType": "createClustersFromGemini() called",
    "eventData": "{\n  \"response\": [\n    {\n      \"name\": \"Image Classification and Neural Network Architectures\",\n      \"paperIds\": [\n        \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n        \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      ]\n    },\n    {\n      \"name\": \"Dataset Pruning and Distillation\",\n      \"paperIds\": [\n        \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      ]\n    },\n    {\n      \"name\": \"Generalization and Robustness in Deep Learning\",\n      \"paperIds\": [\n        \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      ]\n    },\n    {\n      \"name\": \"Image Processing and Computer Vision Techniques\",\n      \"paperIds\": [\n        \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n        \"f99c4e2092b186a815140e888768de9845b356c4\",\n        \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n        \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n        \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n        \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n        \"1d10aa5e7122d1df6d559999987c76de3a088f62\"\n      ]\n    }\n  ]\n}"
  },
  {
    "timestamp": 107474,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 4,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.25,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.06549143735324586,\n      \"_y\": -0.15183748428305138,\n      \"_z\": 0.1875\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.2265463548044702,\n      \"_y\": -0.0852672218663603,\n      \"_z\": 0.0625\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.07447456637592242,\n      \"_y\": 0.2303199708299702,\n      \"_z\": -0.06250000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.15956534462542546,\n      \"_y\": 0.04338952401869845,\n      \"_z\": -0.1875\n    }\n  ]\n}"
  },
  {
    "timestamp": 107474,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 8,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": -0.06549143735324586,\n    \"_y\": -0.15183748428305138,\n    \"_z\": 0.1875\n  },\n  \"radius\": 0.08,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.09838895208114695,\n      \"_y\": -0.17227650394465774,\n      \"_z\": 0.2575\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.030066450947935267,\n      \"_y\": -0.2032677315912606,\n      \"_z\": 0.2375\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.006470465446009752,\n      \"_y\": -0.10693175107307869,\n      \"_z\": 0.2175\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.11648138210636404,\n      \"_y\": -0.09100964909163628,\n      \"_z\": 0.1975\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.12384366954848036,\n      \"_y\": -0.2056428464492281,\n      \"_z\": 0.1775\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.01269979027604505,\n      \"_y\": -0.20392435401887132,\n      \"_z\": 0.1575\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.02377844238069373,\n      \"_y\": -0.10536140387151235,\n      \"_z\": 0.1375\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.09550407767996395,\n      \"_y\": -0.1273580761893279,\n      \"_z\": 0.1175\n    }\n  ]\n}"
  },
  {
    "timestamp": 107474,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0.2265463548044702,\n    \"_y\": -0.0852672218663603,\n    \"_z\": 0.0625\n  },\n  \"radius\": 0.08,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.1904707049702033,\n      \"_y\": -0.05360419154651632,\n      \"_z\": 0.1265\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.18083636159917812,\n      \"_y\": -0.14259606732108887,\n      \"_z\": 0.0945\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.2913825188784994,\n      \"_y\": -0.13213162016790214,\n      \"_z\": 0.0625\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.266644397669617,\n      \"_y\": -0.023881987824411338,\n      \"_z\": 0.0305\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.1851655700517289,\n      \"_y\": -0.060943762958398734,\n      \"_z\": -0.0015000000000000013\n    }\n  ]\n}"
  },
  {
    "timestamp": 107474,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 10,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0.07447456637592242,\n    \"_y\": 0.2303199708299702,\n    \"_z\": -0.06250000000000003\n  },\n  \"radius\": 0.08,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.04985887653367206,\n      \"_y\": 0.20562041995166205,\n      \"_z\": 0.00949999999999998\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.1168004363861313,\n      \"_y\": 0.1919465330392418,\n      \"_z\": -0.0065000000000000335\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.11853358912834164,\n      \"_y\": 0.2837877416279173,\n      \"_z\": -0.022500000000000034\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.01335309135372073,\n      \"_y\": 0.2760164180782014,\n      \"_z\": -0.03850000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.029875311473101823,\n      \"_y\": 0.16438889725981487,\n      \"_z\": -0.05450000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.14243807554252957,\n      \"_y\": 0.18888373763050448,\n      \"_z\": -0.07050000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.11108018569334135,\n      \"_y\": 0.2972828608093327,\n      \"_z\": -0.08650000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.012181479285062906,\n      \"_y\": 0.26064440488389096,\n      \"_z\": -0.10250000000000005\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.0519219027406135,\n      \"_y\": 0.17782828231690545,\n      \"_z\": -0.11850000000000005\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.10712807515470196,\n      \"_y\": 0.21808279940704045,\n      \"_z\": -0.13450000000000004\n    }\n  ]\n}"
  },
  {
    "timestamp": 107474,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 7,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": -0.15956534462542546,\n    \"_y\": 0.04338952401869845,\n    \"_z\": -0.1875\n  },\n  \"radius\": 0.08,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.1369555396463977,\n      \"_y\": 0.008940200331813107,\n      \"_z\": -0.11892857142857143\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.10644103067069295,\n      \"_y\": 0.0819642741601014,\n      \"_z\": -0.1417857142857143\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.20749003807746177,\n      \"_y\": 0.10322909936759703,\n      \"_z\": -0.16464285714285715\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.21957674522002021,\n      \"_y\": -0.009512572335558356,\n      \"_z\": -0.1875\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.10620941305946394,\n      \"_y\": -0.011662229696661017,\n      \"_z\": -0.21035714285714285\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.11463197453416864,\n      \"_y\": 0.09125596668864,\n      \"_z\": -0.2332142857142857\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.1909067216943809,\n      \"_y\": 0.07014166911203672,\n      \"_z\": -0.2560714285714286\n    }\n  ]\n}"
  },
  {
    "timestamp": 107478,
    "eventType": "regenerateUserLinkData() called",
    "eventData": "{\n  \"oldUserLinkData\": [],\n  \"newUserLinkData\": [\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": 0.11682790764906274,\n        \"y\": 0.012613863264772448,\n        \"z\": 0.01376996209154891,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": 0.17610041725747508,\n        \"y\": 0.038065591940832734,\n        \"z\": 0.10310934526513221,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": 0.11682790764906274,\n        \"y\": 0.012613863264772448,\n        \"z\": 0.01376996209154891,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": 0.11609234813987081,\n        \"y\": -0.08307492602176278,\n        \"z\": -0.18259618176841066,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": 0.11682790764906274,\n        \"y\": 0.012613863264772448,\n        \"z\": 0.01376996209154891,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": 0.043406568051661605,\n        \"y\": -0.17066427667827994,\n        \"z\": -0.01814289546624399,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": 0.11682790764906274,\n        \"y\": 0.012613863264772448,\n        \"z\": 0.01376996209154891,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.14828459296730276,\n        \"y\": -0.05226975776473653,\n        \"z\": -0.08250713154505894,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": 0.11682790764906274,\n        \"y\": 0.012613863264772448,\n        \"z\": 0.01376996209154891,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.026120129835961597,\n        \"y\": -0.011591420601220905,\n        \"z\": -0.26040769241435474,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": 0.11682790764906274,\n        \"y\": 0.012613863264772448,\n        \"z\": 0.01376996209154891,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n        \"title\": \"Building Efficient Lightweight CNN Models\",\n        \"x\": 0.06785594859317809,\n        \"y\": 0.20078316167698038,\n        \"z\": 0.06061078202549092,\n        \"index\": 4,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": 0.11682790764906274,\n        \"y\": 0.012613863264772448,\n        \"z\": 0.01376996209154891,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.026270992042877785,\n        \"y\": 0.10650734739049897,\n        \"z\": -0.09553394589118,\n        \"index\": 1,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": 0.17610041725747508,\n        \"y\": 0.038065591940832734,\n        \"z\": 0.10310934526513221,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": 0.11609234813987081,\n        \"y\": -0.08307492602176278,\n        \"z\": -0.18259618176841066,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": 0.17610041725747508,\n        \"y\": 0.038065591940832734,\n        \"z\": 0.10310934526513221,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": 0.043406568051661605,\n        \"y\": -0.17066427667827994,\n        \"z\": -0.01814289546624399,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": 0.17610041725747508,\n        \"y\": 0.038065591940832734,\n        \"z\": 0.10310934526513221,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.14828459296730276,\n        \"y\": -0.05226975776473653,\n        \"z\": -0.08250713154505894,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": 0.17610041725747508,\n        \"y\": 0.038065591940832734,\n        \"z\": 0.10310934526513221,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.026120129835961597,\n        \"y\": -0.011591420601220905,\n        \"z\": -0.26040769241435474,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": 0.17610041725747508,\n        \"y\": 0.038065591940832734,\n        \"z\": 0.10310934526513221,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n        \"title\": \"Building Efficient Lightweight CNN Models\",\n        \"x\": 0.06785594859317809,\n        \"y\": 0.20078316167698038,\n        \"z\": 0.06061078202549092,\n        \"index\": 4,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": 0.17610041725747508,\n        \"y\": 0.038065591940832734,\n        \"z\": 0.10310934526513221,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.026270992042877785,\n        \"y\": 0.10650734739049897,\n        \"z\": -0.09553394589118,\n        \"index\": 1,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": 0.11609234813987081,\n        \"y\": -0.08307492602176278,\n        \"z\": -0.18259618176841066,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": 0.043406568051661605,\n        \"y\": -0.17066427667827994,\n        \"z\": -0.01814289546624399,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": 0.11609234813987081,\n        \"y\": -0.08307492602176278,\n        \"z\": -0.18259618176841066,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.14828459296730276,\n        \"y\": -0.05226975776473653,\n        \"z\": -0.08250713154505894,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": 0.11609234813987081,\n        \"y\": -0.08307492602176278,\n        \"z\": -0.18259618176841066,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.026120129835961597,\n        \"y\": -0.011591420601220905,\n        \"z\": -0.26040769241435474,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": 0.11609234813987081,\n        \"y\": -0.08307492602176278,\n        \"z\": -0.18259618176841066,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n        \"title\": \"Building Efficient Lightweight CNN Models\",\n        \"x\": 0.06785594859317809,\n        \"y\": 0.20078316167698038,\n        \"z\": 0.06061078202549092,\n        \"index\": 4,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": 0.11609234813987081,\n        \"y\": -0.08307492602176278,\n        \"z\": -0.18259618176841066,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.026270992042877785,\n        \"y\": 0.10650734739049897,\n        \"z\": -0.09553394589118,\n        \"index\": 1,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": 0.043406568051661605,\n        \"y\": -0.17066427667827994,\n        \"z\": -0.01814289546624399,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.14828459296730276,\n        \"y\": -0.05226975776473653,\n        \"z\": -0.08250713154505894,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": 0.043406568051661605,\n        \"y\": -0.17066427667827994,\n        \"z\": -0.01814289546624399,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.026120129835961597,\n        \"y\": -0.011591420601220905,\n        \"z\": -0.26040769241435474,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": 0.043406568051661605,\n        \"y\": -0.17066427667827994,\n        \"z\": -0.01814289546624399,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n        \"title\": \"Building Efficient Lightweight CNN Models\",\n        \"x\": 0.06785594859317809,\n        \"y\": 0.20078316167698038,\n        \"z\": 0.06061078202549092,\n        \"index\": 4,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": 0.043406568051661605,\n        \"y\": -0.17066427667827994,\n        \"z\": -0.01814289546624399,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.026270992042877785,\n        \"y\": 0.10650734739049897,\n        \"z\": -0.09553394589118,\n        \"index\": 1,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.14828459296730276,\n        \"y\": -0.05226975776473653,\n        \"z\": -0.08250713154505894,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.026120129835961597,\n        \"y\": -0.011591420601220905,\n        \"z\": -0.26040769241435474,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.14828459296730276,\n        \"y\": -0.05226975776473653,\n        \"z\": -0.08250713154505894,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n        \"title\": \"Building Efficient Lightweight CNN Models\",\n        \"x\": 0.06785594859317809,\n        \"y\": 0.20078316167698038,\n        \"z\": 0.06061078202549092,\n        \"index\": 4,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.14828459296730276,\n        \"y\": -0.05226975776473653,\n        \"z\": -0.08250713154505894,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.026270992042877785,\n        \"y\": 0.10650734739049897,\n        \"z\": -0.09553394589118,\n        \"index\": 1,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.026120129835961597,\n        \"y\": -0.011591420601220905,\n        \"z\": -0.26040769241435474,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n        \"title\": \"Building Efficient Lightweight CNN Models\",\n        \"x\": 0.06785594859317809,\n        \"y\": 0.20078316167698038,\n        \"z\": 0.06061078202549092,\n        \"index\": 4,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.026120129835961597,\n        \"y\": -0.011591420601220905,\n        \"z\": -0.26040769241435474,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.026270992042877785,\n        \"y\": 0.10650734739049897,\n        \"z\": -0.09553394589118,\n        \"index\": 1,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n        \"title\": \"Building Efficient Lightweight CNN Models\",\n        \"x\": 0.06785594859317809,\n        \"y\": 0.20078316167698038,\n        \"z\": 0.06061078202549092,\n        \"index\": 4,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.026270992042877785,\n        \"y\": 0.10650734739049897,\n        \"z\": -0.09553394589118,\n        \"index\": 1,\n        \"clusterName\": \"Image Classification and Neural Network Architectures\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n        \"x\": -0.17800263931942514,\n        \"y\": 0.27919973844976465,\n        \"z\": -0.13016527047755314,\n        \"index\": 11,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": -0.1374211751945131,\n        \"y\": 0.3756678278198811,\n        \"z\": -0.07323664081997579,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n        \"x\": -0.17800263931942514,\n        \"y\": 0.27919973844976465,\n        \"z\": -0.13016527047755314,\n        \"index\": 11,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": -0.2003368127788648,\n        \"y\": 0.23487930093679416,\n        \"z\": -0.021230509416448478,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n        \"x\": -0.17800263931942514,\n        \"y\": 0.27919973844976465,\n        \"z\": -0.13016527047755314,\n        \"index\": 11,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": -0.2851463188285482,\n        \"y\": 0.24955245037746673,\n        \"z\": -0.08959906232302721,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n        \"x\": -0.17800263931942514,\n        \"y\": 0.27919973844976465,\n        \"z\": -0.13016527047755314,\n        \"index\": 11,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": -0.19961893539022954,\n        \"y\": 0.17172507141672,\n        \"z\": -0.10570276579949746,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": -0.1374211751945131,\n        \"y\": 0.3756678278198811,\n        \"z\": -0.07323664081997579,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": -0.2003368127788648,\n        \"y\": 0.23487930093679416,\n        \"z\": -0.021230509416448478,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": -0.1374211751945131,\n        \"y\": 0.3756678278198811,\n        \"z\": -0.07323664081997579,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": -0.2851463188285482,\n        \"y\": 0.24955245037746673,\n        \"z\": -0.08959906232302721,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": -0.1374211751945131,\n        \"y\": 0.3756678278198811,\n        \"z\": -0.07323664081997579,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": -0.19961893539022954,\n        \"y\": 0.17172507141672,\n        \"z\": -0.10570276579949746,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": -0.2003368127788648,\n        \"y\": 0.23487930093679416,\n        \"z\": -0.021230509416448478,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": -0.2851463188285482,\n        \"y\": 0.24955245037746673,\n        \"z\": -0.08959906232302721,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": -0.2003368127788648,\n        \"y\": 0.23487930093679416,\n        \"z\": -0.021230509416448478,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": -0.19961893539022954,\n        \"y\": 0.17172507141672,\n        \"z\": -0.10570276579949746,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": -0.2851463188285482,\n        \"y\": 0.24955245037746673,\n        \"z\": -0.08959906232302721,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": -0.19961893539022954,\n        \"y\": 0.17172507141672,\n        \"z\": -0.10570276579949746,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Pruning and Distillation\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.031866067921324,\n        \"y\": 0.2937001202073389,\n        \"z\": -0.14123020167680764,\n        \"index\": 8,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.348453964258471,\n        \"y\": 0.19735233353261553,\n        \"z\": -0.19932659835144123,\n        \"index\": 9,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.031866067921324,\n        \"y\": 0.2937001202073389,\n        \"z\": -0.14123020167680764,\n        \"index\": 8,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.37184841756182596,\n        \"y\": 0.009606150238565817,\n        \"z\": 0.07352049131881812,\n        \"index\": 18,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.031866067921324,\n        \"y\": 0.2937001202073389,\n        \"z\": -0.14123020167680764,\n        \"index\": 8,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.37446321257783083,\n        \"y\": 0.012200376872688929,\n        \"z\": -0.127294843100722,\n        \"index\": 19,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.031866067921324,\n        \"y\": 0.2937001202073389,\n        \"z\": -0.14123020167680764,\n        \"index\": 8,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.38323218868134273,\n        \"y\": 0.20570518883692712,\n        \"z\": 0.11388623055624522,\n        \"index\": 16,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.031866067921324,\n        \"y\": 0.2937001202073389,\n        \"z\": -0.14123020167680764,\n        \"index\": 8,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.3028509984750435,\n        \"y\": 0.309927140611988,\n        \"z\": -0.03694942206269386,\n        \"index\": 17,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.031866067921324,\n        \"y\": 0.2937001202073389,\n        \"z\": -0.14123020167680764,\n        \"index\": 8,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.1450476371542206,\n        \"y\": 0.3668347572232174,\n        \"z\": 0.07279863658411015,\n        \"index\": 6,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.031866067921324,\n        \"y\": 0.2937001202073389,\n        \"z\": -0.14123020167680764,\n        \"index\": 8,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n        \"x\": 0.16711300825169786,\n        \"y\": 0.14557105452093133,\n        \"z\": -0.1292229193991991,\n        \"index\": 2,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.031866067921324,\n        \"y\": 0.2937001202073389,\n        \"z\": -0.14123020167680764,\n        \"index\": 8,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0336766661733847,\n        \"y\": 0.47701976790518363,\n        \"z\": -0.05194549073700938,\n        \"index\": 12,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.031866067921324,\n        \"y\": 0.2937001202073389,\n        \"z\": -0.14123020167680764,\n        \"index\": 8,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.24900219906345825,\n        \"y\": -0.14308173601191712,\n        \"z\": -0.139419179651995,\n        \"index\": 20,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.348453964258471,\n        \"y\": 0.19735233353261553,\n        \"z\": -0.19932659835144123,\n        \"index\": 9,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.37184841756182596,\n        \"y\": 0.009606150238565817,\n        \"z\": 0.07352049131881812,\n        \"index\": 18,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.348453964258471,\n        \"y\": 0.19735233353261553,\n        \"z\": -0.19932659835144123,\n        \"index\": 9,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.37446321257783083,\n        \"y\": 0.012200376872688929,\n        \"z\": -0.127294843100722,\n        \"index\": 19,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.348453964258471,\n        \"y\": 0.19735233353261553,\n        \"z\": -0.19932659835144123,\n        \"index\": 9,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.38323218868134273,\n        \"y\": 0.20570518883692712,\n        \"z\": 0.11388623055624522,\n        \"index\": 16,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.348453964258471,\n        \"y\": 0.19735233353261553,\n        \"z\": -0.19932659835144123,\n        \"index\": 9,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.3028509984750435,\n        \"y\": 0.309927140611988,\n        \"z\": -0.03694942206269386,\n        \"index\": 17,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.348453964258471,\n        \"y\": 0.19735233353261553,\n        \"z\": -0.19932659835144123,\n        \"index\": 9,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.1450476371542206,\n        \"y\": 0.3668347572232174,\n        \"z\": 0.07279863658411015,\n        \"index\": 6,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.348453964258471,\n        \"y\": 0.19735233353261553,\n        \"z\": -0.19932659835144123,\n        \"index\": 9,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n        \"x\": 0.16711300825169786,\n        \"y\": 0.14557105452093133,\n        \"z\": -0.1292229193991991,\n        \"index\": 2,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.348453964258471,\n        \"y\": 0.19735233353261553,\n        \"z\": -0.19932659835144123,\n        \"index\": 9,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0336766661733847,\n        \"y\": 0.47701976790518363,\n        \"z\": -0.05194549073700938,\n        \"index\": 12,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.348453964258471,\n        \"y\": 0.19735233353261553,\n        \"z\": -0.19932659835144123,\n        \"index\": 9,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.24900219906345825,\n        \"y\": -0.14308173601191712,\n        \"z\": -0.139419179651995,\n        \"index\": 20,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.37184841756182596,\n        \"y\": 0.009606150238565817,\n        \"z\": 0.07352049131881812,\n        \"index\": 18,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.37446321257783083,\n        \"y\": 0.012200376872688929,\n        \"z\": -0.127294843100722,\n        \"index\": 19,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.37184841756182596,\n        \"y\": 0.009606150238565817,\n        \"z\": 0.07352049131881812,\n        \"index\": 18,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.38323218868134273,\n        \"y\": 0.20570518883692712,\n        \"z\": 0.11388623055624522,\n        \"index\": 16,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.37184841756182596,\n        \"y\": 0.009606150238565817,\n        \"z\": 0.07352049131881812,\n        \"index\": 18,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.3028509984750435,\n        \"y\": 0.309927140611988,\n        \"z\": -0.03694942206269386,\n        \"index\": 17,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.37184841756182596,\n        \"y\": 0.009606150238565817,\n        \"z\": 0.07352049131881812,\n        \"index\": 18,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.1450476371542206,\n        \"y\": 0.3668347572232174,\n        \"z\": 0.07279863658411015,\n        \"index\": 6,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.37184841756182596,\n        \"y\": 0.009606150238565817,\n        \"z\": 0.07352049131881812,\n        \"index\": 18,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n        \"x\": 0.16711300825169786,\n        \"y\": 0.14557105452093133,\n        \"z\": -0.1292229193991991,\n        \"index\": 2,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.37184841756182596,\n        \"y\": 0.009606150238565817,\n        \"z\": 0.07352049131881812,\n        \"index\": 18,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0336766661733847,\n        \"y\": 0.47701976790518363,\n        \"z\": -0.05194549073700938,\n        \"index\": 12,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.37184841756182596,\n        \"y\": 0.009606150238565817,\n        \"z\": 0.07352049131881812,\n        \"index\": 18,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.24900219906345825,\n        \"y\": -0.14308173601191712,\n        \"z\": -0.139419179651995,\n        \"index\": 20,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.37446321257783083,\n        \"y\": 0.012200376872688929,\n        \"z\": -0.127294843100722,\n        \"index\": 19,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.38323218868134273,\n        \"y\": 0.20570518883692712,\n        \"z\": 0.11388623055624522,\n        \"index\": 16,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.37446321257783083,\n        \"y\": 0.012200376872688929,\n        \"z\": -0.127294843100722,\n        \"index\": 19,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.3028509984750435,\n        \"y\": 0.309927140611988,\n        \"z\": -0.03694942206269386,\n        \"index\": 17,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.37446321257783083,\n        \"y\": 0.012200376872688929,\n        \"z\": -0.127294843100722,\n        \"index\": 19,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.1450476371542206,\n        \"y\": 0.3668347572232174,\n        \"z\": 0.07279863658411015,\n        \"index\": 6,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.37446321257783083,\n        \"y\": 0.012200376872688929,\n        \"z\": -0.127294843100722,\n        \"index\": 19,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n        \"x\": 0.16711300825169786,\n        \"y\": 0.14557105452093133,\n        \"z\": -0.1292229193991991,\n        \"index\": 2,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.37446321257783083,\n        \"y\": 0.012200376872688929,\n        \"z\": -0.127294843100722,\n        \"index\": 19,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0336766661733847,\n        \"y\": 0.47701976790518363,\n        \"z\": -0.05194549073700938,\n        \"index\": 12,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.37446321257783083,\n        \"y\": 0.012200376872688929,\n        \"z\": -0.127294843100722,\n        \"index\": 19,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.24900219906345825,\n        \"y\": -0.14308173601191712,\n        \"z\": -0.139419179651995,\n        \"index\": 20,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.38323218868134273,\n        \"y\": 0.20570518883692712,\n        \"z\": 0.11388623055624522,\n        \"index\": 16,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.3028509984750435,\n        \"y\": 0.309927140611988,\n        \"z\": -0.03694942206269386,\n        \"index\": 17,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.38323218868134273,\n        \"y\": 0.20570518883692712,\n        \"z\": 0.11388623055624522,\n        \"index\": 16,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.1450476371542206,\n        \"y\": 0.3668347572232174,\n        \"z\": 0.07279863658411015,\n        \"index\": 6,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.38323218868134273,\n        \"y\": 0.20570518883692712,\n        \"z\": 0.11388623055624522,\n        \"index\": 16,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n        \"x\": 0.16711300825169786,\n        \"y\": 0.14557105452093133,\n        \"z\": -0.1292229193991991,\n        \"index\": 2,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.38323218868134273,\n        \"y\": 0.20570518883692712,\n        \"z\": 0.11388623055624522,\n        \"index\": 16,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0336766661733847,\n        \"y\": 0.47701976790518363,\n        \"z\": -0.05194549073700938,\n        \"index\": 12,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.38323218868134273,\n        \"y\": 0.20570518883692712,\n        \"z\": 0.11388623055624522,\n        \"index\": 16,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.24900219906345825,\n        \"y\": -0.14308173601191712,\n        \"z\": -0.139419179651995,\n        \"index\": 20,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.3028509984750435,\n        \"y\": 0.309927140611988,\n        \"z\": -0.03694942206269386,\n        \"index\": 17,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.1450476371542206,\n        \"y\": 0.3668347572232174,\n        \"z\": 0.07279863658411015,\n        \"index\": 6,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.3028509984750435,\n        \"y\": 0.309927140611988,\n        \"z\": -0.03694942206269386,\n        \"index\": 17,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n        \"x\": 0.16711300825169786,\n        \"y\": 0.14557105452093133,\n        \"z\": -0.1292229193991991,\n        \"index\": 2,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.3028509984750435,\n        \"y\": 0.309927140611988,\n        \"z\": -0.03694942206269386,\n        \"index\": 17,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0336766661733847,\n        \"y\": 0.47701976790518363,\n        \"z\": -0.05194549073700938,\n        \"index\": 12,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.3028509984750435,\n        \"y\": 0.309927140611988,\n        \"z\": -0.03694942206269386,\n        \"index\": 17,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.24900219906345825,\n        \"y\": -0.14308173601191712,\n        \"z\": -0.139419179651995,\n        \"index\": 20,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.1450476371542206,\n        \"y\": 0.3668347572232174,\n        \"z\": 0.07279863658411015,\n        \"index\": 6,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n        \"x\": 0.16711300825169786,\n        \"y\": 0.14557105452093133,\n        \"z\": -0.1292229193991991,\n        \"index\": 2,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.1450476371542206,\n        \"y\": 0.3668347572232174,\n        \"z\": 0.07279863658411015,\n        \"index\": 6,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0336766661733847,\n        \"y\": 0.47701976790518363,\n        \"z\": -0.05194549073700938,\n        \"index\": 12,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.1450476371542206,\n        \"y\": 0.3668347572232174,\n        \"z\": 0.07279863658411015,\n        \"index\": 6,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.24900219906345825,\n        \"y\": -0.14308173601191712,\n        \"z\": -0.139419179651995,\n        \"index\": 20,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n        \"x\": 0.16711300825169786,\n        \"y\": 0.14557105452093133,\n        \"z\": -0.1292229193991991,\n        \"index\": 2,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0336766661733847,\n        \"y\": 0.47701976790518363,\n        \"z\": -0.05194549073700938,\n        \"index\": 12,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n        \"x\": 0.16711300825169786,\n        \"y\": 0.14557105452093133,\n        \"z\": -0.1292229193991991,\n        \"index\": 2,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.24900219906345825,\n        \"y\": -0.14308173601191712,\n        \"z\": -0.139419179651995,\n        \"index\": 20,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0336766661733847,\n        \"y\": 0.47701976790518363,\n        \"z\": -0.05194549073700938,\n        \"index\": 12,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.24900219906345825,\n        \"y\": -0.14308173601191712,\n        \"z\": -0.139419179651995,\n        \"index\": 20,\n        \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n        \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n        \"x\": 0.2032983080543747,\n        \"y\": 0.38280481133125205,\n        \"z\": -0.19454616422300167,\n        \"index\": 13,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n        \"title\": \"Automatic Image White Balancing using Deep Learning\",\n        \"x\": -0.004465766798329964,\n        \"y\": -0.07261880182361498,\n        \"z\": 0.15248435944362954,\n        \"index\": 22,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n        \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n        \"x\": 0.2032983080543747,\n        \"y\": 0.38280481133125205,\n        \"z\": -0.19454616422300167,\n        \"index\": 13,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n        \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n        \"x\": -0.05785879085248784,\n        \"y\": 0.17036176375500078,\n        \"z\": -0.33712598465639154,\n        \"index\": 15,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n        \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n        \"x\": 0.2032983080543747,\n        \"y\": 0.38280481133125205,\n        \"z\": -0.19454616422300167,\n        \"index\": 13,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n        \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n        \"x\": 0.12549456499487088,\n        \"y\": 0.24986849036436437,\n        \"z\": -0.32442139504822515,\n        \"index\": 14,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n        \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n        \"x\": 0.2032983080543747,\n        \"y\": 0.38280481133125205,\n        \"z\": -0.19454616422300167,\n        \"index\": 13,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n        \"title\": \"On the Internal Representations of Graph Metanetworks\",\n        \"x\": -0.0710390773758163,\n        \"y\": 0.1151891936742885,\n        \"z\": 0.1762907049445498,\n        \"index\": 21,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n        \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n        \"x\": 0.2032983080543747,\n        \"y\": 0.38280481133125205,\n        \"z\": -0.19454616422300167,\n        \"index\": 13,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n        \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n        \"x\": 0.20417337319729792,\n        \"y\": 0.06175133476325971,\n        \"z\": -0.3073861422642848,\n        \"index\": 7,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n        \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n        \"x\": 0.2032983080543747,\n        \"y\": 0.38280481133125205,\n        \"z\": -0.19454616422300167,\n        \"index\": 13,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n        \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n        \"x\": -0.16115335358226246,\n        \"y\": 0.29511780207610444,\n        \"z\": -0.23976411532273859,\n        \"index\": 29,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n        \"title\": \"Automatic Image White Balancing using Deep Learning\",\n        \"x\": -0.004465766798329964,\n        \"y\": -0.07261880182361498,\n        \"z\": 0.15248435944362954,\n        \"index\": 22,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n        \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n        \"x\": -0.05785879085248784,\n        \"y\": 0.17036176375500078,\n        \"z\": -0.33712598465639154,\n        \"index\": 15,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n        \"title\": \"Automatic Image White Balancing using Deep Learning\",\n        \"x\": -0.004465766798329964,\n        \"y\": -0.07261880182361498,\n        \"z\": 0.15248435944362954,\n        \"index\": 22,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n        \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n        \"x\": 0.12549456499487088,\n        \"y\": 0.24986849036436437,\n        \"z\": -0.32442139504822515,\n        \"index\": 14,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n        \"title\": \"Automatic Image White Balancing using Deep Learning\",\n        \"x\": -0.004465766798329964,\n        \"y\": -0.07261880182361498,\n        \"z\": 0.15248435944362954,\n        \"index\": 22,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n        \"title\": \"On the Internal Representations of Graph Metanetworks\",\n        \"x\": -0.0710390773758163,\n        \"y\": 0.1151891936742885,\n        \"z\": 0.1762907049445498,\n        \"index\": 21,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n        \"title\": \"Automatic Image White Balancing using Deep Learning\",\n        \"x\": -0.004465766798329964,\n        \"y\": -0.07261880182361498,\n        \"z\": 0.15248435944362954,\n        \"index\": 22,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n        \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n        \"x\": 0.20417337319729792,\n        \"y\": 0.06175133476325971,\n        \"z\": -0.3073861422642848,\n        \"index\": 7,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n        \"title\": \"Automatic Image White Balancing using Deep Learning\",\n        \"x\": -0.004465766798329964,\n        \"y\": -0.07261880182361498,\n        \"z\": 0.15248435944362954,\n        \"index\": 22,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n        \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n        \"x\": -0.16115335358226246,\n        \"y\": 0.29511780207610444,\n        \"z\": -0.23976411532273859,\n        \"index\": 29,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n        \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n        \"x\": -0.05785879085248784,\n        \"y\": 0.17036176375500078,\n        \"z\": -0.33712598465639154,\n        \"index\": 15,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n        \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n        \"x\": 0.12549456499487088,\n        \"y\": 0.24986849036436437,\n        \"z\": -0.32442139504822515,\n        \"index\": 14,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n        \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n        \"x\": -0.05785879085248784,\n        \"y\": 0.17036176375500078,\n        \"z\": -0.33712598465639154,\n        \"index\": 15,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n        \"title\": \"On the Internal Representations of Graph Metanetworks\",\n        \"x\": -0.0710390773758163,\n        \"y\": 0.1151891936742885,\n        \"z\": 0.1762907049445498,\n        \"index\": 21,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n        \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n        \"x\": -0.05785879085248784,\n        \"y\": 0.17036176375500078,\n        \"z\": -0.33712598465639154,\n        \"index\": 15,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n        \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n        \"x\": 0.20417337319729792,\n        \"y\": 0.06175133476325971,\n        \"z\": -0.3073861422642848,\n        \"index\": 7,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n        \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n        \"x\": -0.05785879085248784,\n        \"y\": 0.17036176375500078,\n        \"z\": -0.33712598465639154,\n        \"index\": 15,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n        \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n        \"x\": -0.16115335358226246,\n        \"y\": 0.29511780207610444,\n        \"z\": -0.23976411532273859,\n        \"index\": 29,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n        \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n        \"x\": 0.12549456499487088,\n        \"y\": 0.24986849036436437,\n        \"z\": -0.32442139504822515,\n        \"index\": 14,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n        \"title\": \"On the Internal Representations of Graph Metanetworks\",\n        \"x\": -0.0710390773758163,\n        \"y\": 0.1151891936742885,\n        \"z\": 0.1762907049445498,\n        \"index\": 21,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n        \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n        \"x\": 0.12549456499487088,\n        \"y\": 0.24986849036436437,\n        \"z\": -0.32442139504822515,\n        \"index\": 14,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n        \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n        \"x\": 0.20417337319729792,\n        \"y\": 0.06175133476325971,\n        \"z\": -0.3073861422642848,\n        \"index\": 7,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n        \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n        \"x\": 0.12549456499487088,\n        \"y\": 0.24986849036436437,\n        \"z\": -0.32442139504822515,\n        \"index\": 14,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n        \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n        \"x\": -0.16115335358226246,\n        \"y\": 0.29511780207610444,\n        \"z\": -0.23976411532273859,\n        \"index\": 29,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n        \"title\": \"On the Internal Representations of Graph Metanetworks\",\n        \"x\": -0.0710390773758163,\n        \"y\": 0.1151891936742885,\n        \"z\": 0.1762907049445498,\n        \"index\": 21,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n        \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n        \"x\": 0.20417337319729792,\n        \"y\": 0.06175133476325971,\n        \"z\": -0.3073861422642848,\n        \"index\": 7,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n        \"title\": \"On the Internal Representations of Graph Metanetworks\",\n        \"x\": -0.0710390773758163,\n        \"y\": 0.1151891936742885,\n        \"z\": 0.1762907049445498,\n        \"index\": 21,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n        \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n        \"x\": -0.16115335358226246,\n        \"y\": 0.29511780207610444,\n        \"z\": -0.23976411532273859,\n        \"index\": 29,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n        \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n        \"x\": 0.20417337319729792,\n        \"y\": 0.06175133476325971,\n        \"z\": -0.3073861422642848,\n        \"index\": 7,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      },\n      \"target\": {\n        \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n        \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n        \"x\": -0.16115335358226246,\n        \"y\": 0.29511780207610444,\n        \"z\": -0.23976411532273859,\n        \"index\": 29,\n        \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n      }\n    }\n  ]\n}"
  },
  {
    "timestamp": 107480,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 107481,
    "eventType": "createClustersFromGemini() finished",
    "eventData": "{\n  \"response\": [\n    {\n      \"name\": \"Image Classification and Neural Network Architectures\",\n      \"paperIds\": [\n        \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n        \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      ]\n    },\n    {\n      \"name\": \"Dataset Pruning and Distillation\",\n      \"paperIds\": [\n        \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n        \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      ]\n    },\n    {\n      \"name\": \"Generalization and Robustness in Deep Learning\",\n      \"paperIds\": [\n        \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n        \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      ]\n    },\n    {\n      \"name\": \"Image Processing and Computer Vision Techniques\",\n      \"paperIds\": [\n        \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n        \"f99c4e2092b186a815140e888768de9845b356c4\",\n        \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n        \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n        \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n        \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n        \"1d10aa5e7122d1df6d559999987c76de3a088f62\"\n      ]\n    }\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.11682790764906274,\n      \"y\": 0.012613863264772448,\n      \"z\": 0.01376996209154891,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.026270992042877785,\n      \"y\": 0.10650734739049897,\n      \"z\": -0.09553394589118,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.16711300825169786,\n      \"y\": 0.14557105452093133,\n      \"z\": -0.1292229193991991,\n      \"index\": 2,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.17610041725747508,\n      \"y\": 0.038065591940832734,\n      \"z\": 0.10310934526513221,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": 0.06785594859317809,\n      \"y\": 0.20078316167698038,\n      \"z\": 0.06061078202549092,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.026120129835961597,\n      \"y\": -0.011591420601220905,\n      \"z\": -0.26040769241435474,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.1450476371542206,\n      \"y\": 0.3668347572232174,\n      \"z\": 0.07279863658411015,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": 0.20417337319729792,\n      \"y\": 0.06175133476325971,\n      \"z\": -0.3073861422642848,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.031866067921324,\n      \"y\": 0.2937001202073389,\n      \"z\": -0.14123020167680764,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.348453964258471,\n      \"y\": 0.19735233353261553,\n      \"z\": -0.19932659835144123,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.11609234813987081,\n      \"y\": -0.08307492602176278,\n      \"z\": -0.18259618176841066,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": -0.17800263931942514,\n      \"y\": 0.27919973844976465,\n      \"z\": -0.13016527047755314,\n      \"index\": 11,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0336766661733847,\n      \"y\": 0.47701976790518363,\n      \"z\": -0.05194549073700938,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": 0.2032983080543747,\n      \"y\": 0.38280481133125205,\n      \"z\": -0.19454616422300167,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": 0.12549456499487088,\n      \"y\": 0.24986849036436437,\n      \"z\": -0.32442139504822515,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.05785879085248784,\n      \"y\": 0.17036176375500078,\n      \"z\": -0.33712598465639154,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.38323218868134273,\n      \"y\": 0.20570518883692712,\n      \"z\": 0.11388623055624522,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.3028509984750435,\n      \"y\": 0.309927140611988,\n      \"z\": -0.03694942206269386,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.37184841756182596,\n      \"y\": 0.009606150238565817,\n      \"z\": 0.07352049131881812,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.37446321257783083,\n      \"y\": 0.012200376872688929,\n      \"z\": -0.127294843100722,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.24900219906345825,\n      \"y\": -0.14308173601191712,\n      \"z\": -0.139419179651995,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.0710390773758163,\n      \"y\": 0.1151891936742885,\n      \"z\": 0.1762907049445498,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.004465766798329964,\n      \"y\": -0.07261880182361498,\n      \"z\": 0.15248435944362954,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.043406568051661605,\n      \"y\": -0.17066427667827994,\n      \"z\": -0.01814289546624399,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.14828459296730276,\n      \"y\": -0.05226975776473653,\n      \"z\": -0.08250713154505894,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": -0.1374211751945131,\n      \"y\": 0.3756678278198811,\n      \"z\": -0.07323664081997579,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.2003368127788648,\n      \"y\": 0.23487930093679416,\n      \"z\": -0.021230509416448478,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.2851463188285482,\n      \"y\": 0.24955245037746673,\n      \"z\": -0.08959906232302721,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": -0.19961893539022954,\n      \"y\": 0.17172507141672,\n      \"z\": -0.10570276579949746,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.16115335358226246,\n      \"y\": 0.29511780207610444,\n      \"z\": -0.23976411532273859,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 108955,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11648138210636405,\n    \"_y\": -0.09100964909163628,\n    \"_z\": 0.1975\n  }\n}"
  },
  {
    "timestamp": 108955,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n    \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n    \"x\": -0.11648138210636405,\n    \"y\": -0.09100964909163628,\n    \"z\": 0.1975,\n    \"index\": 23,\n    \"clusterName\": \"Image Classification and Neural Network Architectures\"\n  }\n}"
  },
  {
    "timestamp": 108955,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 108962,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11648138210636405,\n    \"_y\": -0.09100964909163628,\n    \"_z\": 0.1975\n  }\n}"
  },
  {
    "timestamp": 108963,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 108963,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 108963,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 109337,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.18516557005172887,\n    \"_y\": -0.060943762958398734,\n    \"_z\": -0.0015000000000000013\n  }\n}"
  },
  {
    "timestamp": 109337,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n    \"title\": \"Multisize Dataset Condensation\",\n    \"x\": 0.18516557005172887,\n    \"y\": -0.060943762958398734,\n    \"z\": -0.0015000000000000013,\n    \"index\": 28,\n    \"clusterName\": \"Dataset Pruning and Distillation\"\n  }\n}"
  },
  {
    "timestamp": 109337,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 110795,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.18516557005172887,\n    \"_y\": -0.060943762958398734,\n    \"_z\": -0.0015000000000000013\n  }\n}"
  },
  {
    "timestamp": 110796,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 110796,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 110796,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 111417,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.023778442380693737,\n    \"_y\": -0.10536140387151235,\n    \"_z\": 0.1375\n  }\n}"
  },
  {
    "timestamp": 111417,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n    \"title\": \"Building Efficient Lightweight CNN Models\",\n    \"x\": -0.023778442380693737,\n    \"y\": -0.10536140387151235,\n    \"z\": 0.1375,\n    \"index\": 4,\n    \"clusterName\": \"Image Classification and Neural Network Architectures\"\n  }\n}"
  },
  {
    "timestamp": 111417,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 112262,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.023778442380693737,\n    \"_y\": -0.10536140387151235,\n    \"_z\": 0.1375\n  }\n}"
  },
  {
    "timestamp": 112263,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 112263,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 112263,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 112597,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.029875311473101795,\n    \"_y\": 0.16438889725981487,\n    \"_z\": -0.05450000000000002\n  }\n}"
  },
  {
    "timestamp": 112597,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n    \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n    \"x\": 0.029875311473101795,\n    \"y\": 0.16438889725981487,\n    \"z\": -0.05450000000000002,\n    \"index\": 16,\n    \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n  }\n}"
  },
  {
    "timestamp": 112597,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 112627,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.029875311473101795,\n    \"_y\": 0.16438889725981487,\n    \"_z\": -0.05450000000000002\n  }\n}"
  },
  {
    "timestamp": 112628,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 112628,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 112628,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 113146,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.10712807515470196,\n    \"_y\": 0.21808279940704042,\n    \"_z\": -0.13450000000000004\n  }\n}"
  },
  {
    "timestamp": 113146,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n    \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n    \"x\": 0.10712807515470196,\n    \"y\": 0.21808279940704042,\n    \"z\": -0.13450000000000004,\n    \"index\": 20,\n    \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n  }\n}"
  },
  {
    "timestamp": 113146,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 113716,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.10712807515470196,\n    \"_y\": 0.21808279940704042,\n    \"_z\": -0.13450000000000004\n  }\n}"
  },
  {
    "timestamp": 113716,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 113716,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 113716,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 113834,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 113834,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n    \"title\": \"Automatic Image White Balancing using Deep Learning\",\n    \"x\": -0.10644103067069295,\n    \"y\": 0.0819642741601014,\n    \"z\": -0.1417857142857143,\n    \"index\": 22,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 113834,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 113962,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 113962,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 113962,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 113962,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 114514,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 114514,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n    \"title\": \"Automatic Image White Balancing using Deep Learning\",\n    \"x\": -0.10644103067069295,\n    \"y\": 0.0819642741601014,\n    \"z\": -0.1417857142857143,\n    \"index\": 22,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 114514,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 115145,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 115145,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 115546,
    "eventType": "node onPickDownTrigger - long press detected",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 115547,
    "eventType": "updatePaperPanelToNode()",
    "eventData": "{\n  \"paperDetailsPanelId\": null,\n  \"paperDetailsPanelVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n    \"title\": \"Automatic Image White Balancing using Deep Learning\",\n    \"x\": -0.10644103067069295,\n    \"y\": 0.0819642741601014,\n    \"z\": -0.1417857142857143,\n    \"index\": 22,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 115547,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 115547,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 115547,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 115547,
    "eventType": "updatePaperPanelToNode()",
    "eventData": "{\n  \"paperDetailsPanelId\": null,\n  \"paperDetailsPanelVisibility\": false,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 115547,
    "eventType": "updatePaperPanelToNode() finished",
    "eventData": "{\n  \"paperDetailsPanelId\": null,\n  \"paperDetailsPanelVisibility\": false\n}"
  },
  {
    "timestamp": 115547,
    "eventType": "updateInsightsAndNotesText()",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\"\n}"
  },
  {
    "timestamp": 115548,
    "eventType": "updateInsightsAndNotesText() finished",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\"\n}"
  },
  {
    "timestamp": 115548,
    "eventType": "sendCurrentlyViewingNodeData() called",
    "eventData": "{\n  \"currentlyViewingPaper\": {\n    \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n    \"title\": \"Automatic Image White Balancing using Deep Learning\",\n    \"x\": -0.10644103067069295,\n    \"y\": 0.0819642741601014,\n    \"z\": -0.1417857142857143,\n    \"index\": 22,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 115548,
    "eventType": "updatePaperPanelToNode() finished",
    "eventData": "{\n  \"paperDetailsPanelId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelVisibility\": true\n}"
  },
  {
    "timestamp": 115779,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 115779,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 116427,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 116428,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 116829,
    "eventType": "node onPickDownTrigger - long press detected",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 116829,
    "eventType": "updatePaperPanelToNode()",
    "eventData": "{\n  \"paperDetailsPanelId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n    \"title\": \"Automatic Image White Balancing using Deep Learning\",\n    \"x\": -0.10644103067069295,\n    \"y\": 0.0819642741601014,\n    \"z\": -0.1417857142857143,\n    \"index\": 22,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 116830,
    "eventType": "updatePaperPanelToNode()",
    "eventData": "{\n  \"paperDetailsPanelId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 116830,
    "eventType": "updatePaperPanelToNode() finished",
    "eventData": "{\n  \"paperDetailsPanelId\": null,\n  \"paperDetailsPanelVisibility\": false\n}"
  },
  {
    "timestamp": 116830,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n    \"title\": \"Automatic Image White Balancing using Deep Learning\",\n    \"x\": -0.10644103067069295,\n    \"y\": 0.0819642741601014,\n    \"z\": -0.1417857142857143,\n    \"index\": 22,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 116830,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 117012,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 117012,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 117334,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 117335,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 117335,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 117335,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 118020,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.012181479285062913,\n    \"_y\": 0.26064440488389096,\n    \"_z\": -0.10250000000000005\n  }\n}"
  },
  {
    "timestamp": 118020,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n    \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n    \"x\": 0.012181479285062913,\n    \"y\": 0.26064440488389096,\n    \"z\": -0.10250000000000005,\n    \"index\": 2,\n    \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n  }\n}"
  },
  {
    "timestamp": 118020,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 118077,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.012181479285062913,\n    \"_y\": 0.26064440488389096,\n    \"_z\": -0.10250000000000005\n  }\n}"
  },
  {
    "timestamp": 118078,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.012181479285062913,\n    \"_y\": 0.26064440488389096,\n    \"_z\": -0.10250000000000005\n  }\n}"
  },
  {
    "timestamp": 118095,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": 0.012181479285062913,\n    \"_y\": 0.26064440488389096,\n    \"_z\": -0.10250000000000005\n  }\n}"
  },
  {
    "timestamp": 118097,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.012170125531555775,\n    \"_y\": 0.26100259899666867,\n    \"_z\": -0.10247438862919812\n  }\n}"
  },
  {
    "timestamp": 118114,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.012164448654802207,\n    \"_y\": 0.2611816960530575,\n    \"_z\": -0.10246158108115201\n  }\n}"
  },
  {
    "timestamp": 118129,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.012161610449256066,\n    \"_y\": 0.26127125203183255,\n    \"_z\": -0.10245517730712896\n  }\n}"
  },
  {
    "timestamp": 118147,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.012160191113652352,\n    \"_y\": 0.26131603002122006,\n    \"_z\": -0.10245197728276258\n  }\n}"
  },
  {
    "timestamp": 118164,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.012159481445850495,\n    \"_y\": 0.2613384115653332,\n    \"_z\": -0.10245037540793424\n  }\n}"
  },
  {
    "timestamp": 118180,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": 0.012159126611949567,\n    \"_y\": 0.2613496023373898,\n    \"_z\": -0.10244957447052007\n  }\n}"
  },
  {
    "timestamp": 118195,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.012159126611949567,\n    \"_y\": 0.2613496023373898,\n    \"_z\": -0.10244957447052007\n  }\n}"
  },
  {
    "timestamp": 118195,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.012159126611949567,\n    \"_y\": 0.2613496023373898,\n    \"_z\": -0.10244957447052007\n  }\n}"
  },
  {
    "timestamp": 118195,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.012159126611949567,\n    \"_y\": 0.2613496023373898,\n    \"_z\": -0.10244957447052007\n  }\n}"
  },
  {
    "timestamp": 118638,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n  ]\n}"
  },
  {
    "timestamp": 118639,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n      \"title\": \"Shortcut Learning Susceptibility in Vision Classifiers\",\n      \"x\": 0.012159126611949567,\n      \"y\": 0.2613496023373898,\n      \"z\": -0.10244957447052007,\n      \"index\": 2,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.023778442380693737,\n      \"y\": -0.10536140387151235,\n      \"z\": 0.1375,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.19047070497020327,\n      \"y\": -0.0536041915465163,\n      \"z\": 0.12650000000000003,\n      \"index\": 11,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 118640,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.023778442380693737,\n      \"y\": -0.10536140387151235,\n      \"z\": 0.1375,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.19047070497020327,\n      \"y\": -0.0536041915465163,\n      \"z\": 0.12650000000000003,\n      \"index\": 11,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 118657,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.023778442380693737,\n      \"y\": -0.10536140387151235,\n      \"z\": 0.1375,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.19047070497020327,\n      \"y\": -0.0536041915465163,\n      \"z\": 0.12650000000000003,\n      \"index\": 11,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 118658,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 118659,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.023778442380693737,\n      \"y\": -0.10536140387151235,\n      \"z\": 0.1375,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.19047070497020327,\n      \"y\": -0.0536041915465163,\n      \"z\": 0.12650000000000003,\n      \"index\": 11,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 119709,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.19047070497020327,\n    \"_y\": -0.0536041915465163,\n    \"_z\": 0.12650000000000003\n  }\n}"
  },
  {
    "timestamp": 119709,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"6a0ff043003eef1c800e27a14c0cb6d774f5bf2d\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n    \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n    \"x\": 0.19047070497020327,\n    \"y\": -0.0536041915465163,\n    \"z\": 0.12650000000000003,\n    \"index\": 11,\n    \"clusterName\": \"Dataset Pruning and Distillation\"\n  }\n}"
  },
  {
    "timestamp": 119709,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 119980,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.19047070497020327,\n    \"_y\": -0.0536041915465163,\n    \"_z\": 0.12650000000000003\n  }\n}"
  },
  {
    "timestamp": 119980,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.19047070497020327,\n    \"_y\": -0.0536041915465163,\n    \"_z\": 0.12650000000000003\n  }\n}"
  },
  {
    "timestamp": 120045,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.19047070497020327,\n    \"_y\": -0.0536041915465163,\n    \"_z\": 0.12650000000000003\n  }\n}"
  },
  {
    "timestamp": 120045,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.19047070497020327,\n    \"_y\": -0.0536041915465163,\n    \"_z\": 0.12650000000000003\n  }\n}"
  },
  {
    "timestamp": 120046,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.19047070497020327,\n    \"_y\": -0.0536041915465163,\n    \"_z\": 0.12650000000000003\n  }\n}"
  },
  {
    "timestamp": 120200,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"95e706662b99267d21a1ccc7ed380d1cd0e06057\"\n  ]\n}"
  },
  {
    "timestamp": 120200,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"95e706662b99267d21a1ccc7ed380d1cd0e06057\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.023778442380693737,\n      \"y\": -0.10536140387151235,\n      \"z\": 0.1375,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n      \"title\": \"Training-Free Dataset Pruning for Instance Segmentation\",\n      \"x\": 0.19047070497020327,\n      \"y\": -0.0536041915465163,\n      \"z\": 0.12650000000000003,\n      \"index\": 11,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 120202,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.023778442380693737,\n      \"y\": -0.10536140387151235,\n      \"z\": 0.1375,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 120220,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.023778442380693737,\n      \"y\": -0.10536140387151235,\n      \"z\": 0.1375,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 120221,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 120222,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.023778442380693737,\n      \"y\": -0.10536140387151235,\n      \"z\": 0.1375,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 120567,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.023778442380693737,\n    \"_y\": -0.10536140387151235,\n    \"_z\": 0.1375\n  }\n}"
  },
  {
    "timestamp": 120567,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n    \"title\": \"Building Efficient Lightweight CNN Models\",\n    \"x\": -0.023778442380693737,\n    \"y\": -0.10536140387151235,\n    \"z\": 0.1375,\n    \"index\": 4,\n    \"clusterName\": \"Image Classification and Neural Network Architectures\"\n  }\n}"
  },
  {
    "timestamp": 120567,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 120862,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.023778442380693737,\n    \"_y\": -0.10536140387151235,\n    \"_z\": 0.1375\n  }\n}"
  },
  {
    "timestamp": 120862,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.023778442380693737,\n    \"_y\": -0.10536140387151235,\n    \"_z\": 0.1375\n  }\n}"
  },
  {
    "timestamp": 120961,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.023778442380693737,\n    \"_y\": -0.10536140387151235,\n    \"_z\": 0.1375\n  }\n}"
  },
  {
    "timestamp": 120962,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.023778442380693737,\n    \"_y\": -0.10536140387151235,\n    \"_z\": 0.1375\n  }\n}"
  },
  {
    "timestamp": 120962,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.023778442380693737,\n    \"_y\": -0.10536140387151235,\n    \"_z\": 0.1375\n  }\n}"
  },
  {
    "timestamp": 121093,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n  ]\n}"
  },
  {
    "timestamp": 121093,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n      \"title\": \"Building Efficient Lightweight CNN Models\",\n      \"x\": -0.023778442380693737,\n      \"y\": -0.10536140387151235,\n      \"z\": 0.1375,\n      \"index\": 4,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 121094,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 121114,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 121115,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 121116,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.10644103067069295,\n      \"y\": 0.0819642741601014,\n      \"z\": -0.1417857142857143,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 123220,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 123220,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"ff72ca0f93a1b8d351cda1a7f3df3f875b06f62e\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n    \"title\": \"Automatic Image White Balancing using Deep Learning\",\n    \"x\": -0.10644103067069295,\n    \"y\": 0.0819642741601014,\n    \"z\": -0.1417857142857143,\n    \"index\": 22,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 123220,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 123376,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 123377,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 123479,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 123479,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 123480,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 123692,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 123693,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 123693,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 123693,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 124261,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 124261,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n    \"title\": \"Automatic Image White Balancing using Deep Learning\",\n    \"x\": -0.10644103067069295,\n    \"y\": 0.0819642741601014,\n    \"z\": -0.1417857142857143,\n    \"index\": 22,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 124262,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 124496,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 124496,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 124629,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10644103067069295,\n    \"_y\": 0.0819642741601014,\n    \"_z\": -0.1417857142857143\n  }\n}"
  },
  {
    "timestamp": 124631,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.10654309989958051,\n    \"_y\": 0.08308254670305489,\n    \"_z\": -0.14158239539180484\n  }\n}"
  },
  {
    "timestamp": 124645,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10654309989958051,\n    \"_y\": 0.08308254670305489,\n    \"_z\": -0.14158239539180484\n  }\n}"
  },
  {
    "timestamp": 124647,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.1068281851902509,\n    \"_y\": 0.08625164743466614,\n    \"_z\": -0.14101202364478793\n  }\n}"
  },
  {
    "timestamp": 124663,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1068281851902509,\n    \"_y\": 0.08625164743466614,\n    \"_z\": -0.14101202364478793\n  }\n}"
  },
  {
    "timestamp": 124664,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1068281851902509,\n    \"_y\": 0.08625164743466614,\n    \"_z\": -0.14101202364478793\n  }\n}"
  },
  {
    "timestamp": 124665,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.10767003374247792,\n    \"_y\": 0.09604433294339416,\n    \"_z\": -0.13930619831596103\n  }\n}"
  },
  {
    "timestamp": 124677,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10767003374247792,\n    \"_y\": 0.09604433294339416,\n    \"_z\": -0.13930619831596103\n  }\n}"
  },
  {
    "timestamp": 124680,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.10911671297698262,\n    \"_y\": 0.11438285674853561,\n    \"_z\": -0.13630090977464404\n  }\n}"
  },
  {
    "timestamp": 124693,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10911671297698262,\n    \"_y\": 0.11438285674853561,\n    \"_z\": -0.13630090977464404\n  }\n}"
  },
  {
    "timestamp": 124697,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.11087248327284101,\n    \"_y\": 0.13960762809915778,\n    \"_z\": -0.13250825877700534\n  }\n}"
  },
  {
    "timestamp": 124708,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11087248327284101,\n    \"_y\": 0.13960762809915778,\n    \"_z\": -0.13250825877700534\n  }\n}"
  },
  {
    "timestamp": 124714,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.11203607397227529,\n    \"_y\": 0.17010373365087744,\n    \"_z\": -0.1279929945937225\n  }\n}"
  },
  {
    "timestamp": 124725,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11203607397227529,\n    \"_y\": 0.17010373365087744,\n    \"_z\": -0.1279929945937225\n  }\n}"
  },
  {
    "timestamp": 124730,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.11138796659260038,\n    \"_y\": 0.2024207461993241,\n    \"_z\": -0.12272518079195704\n  }\n}"
  },
  {
    "timestamp": 124742,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11138796659260038,\n    \"_y\": 0.2024207461993241,\n    \"_z\": -0.12272518079195704\n  }\n}"
  },
  {
    "timestamp": 124747,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.10925911964922193,\n    \"_y\": 0.23335792612238165,\n    \"_z\": -0.11739398490105357\n  }\n}"
  },
  {
    "timestamp": 124759,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10925911964922193,\n    \"_y\": 0.23335792612238165,\n    \"_z\": -0.11739398490105357\n  }\n}"
  },
  {
    "timestamp": 124764,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.1061982125237489,\n    \"_y\": 0.26059610884590384,\n    \"_z\": -0.11247951488409724\n  }\n}"
  },
  {
    "timestamp": 124775,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1061982125237489,\n    \"_y\": 0.26059610884590384,\n    \"_z\": -0.11247951488409724\n  }\n}"
  },
  {
    "timestamp": 124780,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.10256434084921125,\n    \"_y\": 0.2841031674663567,\n    \"_z\": -0.10804016839180675\n  }\n}"
  },
  {
    "timestamp": 124793,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10256434084921125,\n    \"_y\": 0.2841031674663567,\n    \"_z\": -0.10804016839180675\n  }\n}"
  },
  {
    "timestamp": 124797,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09951183797865155,\n    \"_y\": 0.30315530043049094,\n    \"_z\": -0.1046782466343471\n  }\n}"
  },
  {
    "timestamp": 124810,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09951183797865155,\n    \"_y\": 0.30315530043049094,\n    \"_z\": -0.1046782466343471\n  }\n}"
  },
  {
    "timestamp": 124814,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09703983591943029,\n    \"_y\": 0.317047489098742,\n    \"_z\": -0.10222288172159877\n  }\n}"
  },
  {
    "timestamp": 124826,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09703983591943029,\n    \"_y\": 0.317047489098742,\n    \"_z\": -0.10222288172159877\n  }\n}"
  },
  {
    "timestamp": 124830,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09517293276338819,\n    \"_y\": 0.32580944638653037,\n    \"_z\": -0.10052778150354114\n  }\n}"
  },
  {
    "timestamp": 124847,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09423947932272199,\n    \"_y\": 0.33019041757984396,\n    \"_z\": -0.09968023325715747\n  }\n}"
  },
  {
    "timestamp": 124864,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09377275260238889,\n    \"_y\": 0.33238090317650076,\n    \"_z\": -0.09925645913396564\n  }\n}"
  },
  {
    "timestamp": 124881,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09353938924222234,\n    \"_y\": 0.33347615342540976,\n    \"_z\": -0.09904457207236972\n  }\n}"
  },
  {
    "timestamp": 124893,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09353938924222234,\n    \"_y\": 0.33347615342540976,\n    \"_z\": -0.09904457207236972\n  }\n}"
  },
  {
    "timestamp": 124893,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n    \"title\": \"Automatic Image White Balancing using Deep Learning\",\n    \"x\": -0.09353938924222234,\n    \"y\": 0.33347615342540976,\n    \"z\": -0.09904457207236972,\n    \"index\": 22,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 124893,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 124893,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09353938924222234,\n    \"_y\": 0.33347615342540976,\n    \"_z\": -0.09904457207236972\n  }\n}"
  },
  {
    "timestamp": 124897,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09310752006321195,\n    \"_y\": 0.33474953215523,\n    \"_z\": -0.09871251087103572\n  }\n}"
  },
  {
    "timestamp": 124914,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0928915836110616,\n    \"_y\": 0.33538622897072073,\n    \"_z\": -0.09854647840772357\n  }\n}"
  },
  {
    "timestamp": 124930,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09278361724763158,\n    \"_y\": 0.3357045773784661,\n    \"_z\": -0.09846346403871264\n  }\n}"
  },
  {
    "timestamp": 124947,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09272963406591657,\n    \"_y\": 0.3358637515823388,\n    \"_z\": -0.09842195685420718\n  }\n}"
  },
  {
    "timestamp": 124964,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09270264061241391,\n    \"_y\": 0.3359433386842751,\n    \"_z\": -0.09840120326195445\n  }\n}"
  },
  {
    "timestamp": 124978,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09270264061241391,\n    \"_y\": 0.3359433386842751,\n    \"_z\": -0.09840120326195445\n  }\n}"
  },
  {
    "timestamp": 124981,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0920652061894441,\n    \"_y\": 0.3363449547807717,\n    \"_z\": -0.09797425519142833\n  }\n}"
  },
  {
    "timestamp": 124997,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09174648897795919,\n    \"_y\": 0.33654576282902,\n    \"_z\": -0.09776078115616527\n  }\n}"
  },
  {
    "timestamp": 125014,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09158713223486188,\n    \"_y\": 0.33664616685314414,\n    \"_z\": -0.09765404413853374\n  }\n}"
  },
  {
    "timestamp": 125031,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09150745200066808,\n    \"_y\": 0.3366963688652062,\n    \"_z\": -0.09760067562971797\n  }\n}"
  },
  {
    "timestamp": 125045,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09150745200066808,\n    \"_y\": 0.3366963688652062,\n    \"_z\": -0.09760067562971797\n  }\n}"
  },
  {
    "timestamp": 125047,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09115425350218061,\n    \"_y\": 0.337083933166697,\n    \"_z\": -0.09736046518598285\n  }\n}"
  },
  {
    "timestamp": 125064,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09097765239029172,\n    \"_y\": 0.3372777078668618,\n    \"_z\": -0.09724036182676044\n  }\n}"
  },
  {
    "timestamp": 125079,
    "eventType": "node drag onDragObservable (drag target changed)",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"nodePosition\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09097765239029172,\n    \"_y\": 0.3372777078668618,\n    \"_z\": -0.09724036182676044\n  }\n}"
  },
  {
    "timestamp": 125081,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09057582022695783,\n    \"_y\": 0.33773700635833975,\n    \"_z\": -0.09696713040981975\n  }\n}"
  },
  {
    "timestamp": 125097,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09037490414529088,\n    \"_y\": 0.33796666305465933,\n    \"_z\": -0.09683051283870425\n  }\n}"
  },
  {
    "timestamp": 125114,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09027444796710256,\n    \"_y\": 0.3380814914028191,\n    \"_z\": -0.09676220591579165\n  }\n}"
  },
  {
    "timestamp": 125131,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.0902242198780084,\n    \"_y\": 0.338138905576899,\n    \"_z\": -0.09672805245433536\n  }\n}"
  },
  {
    "timestamp": 125147,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09019910397081617,\n    \"_y\": 0.33816760521335837,\n    \"_z\": -0.0967109757236072\n  }\n}"
  },
  {
    "timestamp": 125164,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09018654601722005,\n    \"_y\": 0.33818195503158804,\n    \"_z\": -0.09670243735824313\n  }\n}"
  },
  {
    "timestamp": 125180,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09018026890306714,\n    \"_y\": 0.3381891373912835,\n    \"_z\": -0.0966981681755611\n  }\n}"
  },
  {
    "timestamp": 125197,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09017712848334554,\n    \"_y\": 0.3381927285711312,\n    \"_z\": -0.09669603358422008\n  }\n}"
  },
  {
    "timestamp": 125213,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09017556013612989,\n    \"_y\": 0.33819451671047446,\n    \"_z\": -0.09669496442590442\n  }\n}"
  },
  {
    "timestamp": 125230,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09017477409987691,\n    \"_y\": 0.3381954107801461,\n    \"_z\": -0.09669443170939174\n  }\n}"
  },
  {
    "timestamp": 125247,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09017438294439557,\n    \"_y\": 0.3381958578149819,\n    \"_z\": -0.09669416348849025\n  }\n}"
  },
  {
    "timestamp": 125264,
    "eventType": "node drag onPositionChangedObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": true,\n    \"_x\": -0.09017418550400975,\n    \"_y\": 0.3381960813323998,\n    \"_z\": -0.0966940293780395\n  }\n}"
  },
  {
    "timestamp": 125278,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09017418550400975,\n    \"_y\": 0.3381960813323998,\n    \"_z\": -0.0966940293780395\n  }\n}"
  },
  {
    "timestamp": 125278,
    "eventType": "node onPickUpTrigger - node is already being dragged",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09017418550400975,\n    \"_y\": 0.3381960813323998,\n    \"_z\": -0.0966940293780395\n  }\n}"
  },
  {
    "timestamp": 125278,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09017418550400975,\n    \"_y\": 0.3381960813323998,\n    \"_z\": -0.0966940293780395\n  }\n}"
  },
  {
    "timestamp": 125448,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.09017418550400975,\n    \"_y\": 0.3381960813323998,\n    \"_z\": -0.0966940293780395\n  }\n}"
  },
  {
    "timestamp": 125448,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 125448,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 125448,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 126161,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"f99c4e2092b186a815140e888768de9845b356c4\"\n  ]\n}"
  },
  {
    "timestamp": 126161,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"f99c4e2092b186a815140e888768de9845b356c4\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"f99c4e2092b186a815140e888768de9845b356c4\",\n      \"title\": \"Automatic Image White Balancing using Deep Learning\",\n      \"x\": -0.09017418550400975,\n      \"y\": 0.3381960813323998,\n      \"z\": -0.0966940293780395,\n      \"index\": 22,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 126163,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 126184,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 126186,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 126186,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 126885,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.2074900380774618,\n    \"_y\": 0.10322909936759703,\n    \"_z\": -0.16464285714285715\n  }\n}"
  },
  {
    "timestamp": 126885,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n    \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n    \"x\": -0.2074900380774618,\n    \"y\": 0.10322909936759703,\n    \"z\": -0.16464285714285715,\n    \"index\": 15,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 126885,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 126943,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.2074900380774618,\n    \"_y\": 0.10322909936759703,\n    \"_z\": -0.16464285714285715\n  }\n}"
  },
  {
    "timestamp": 126943,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.2074900380774618,\n    \"_y\": 0.10322909936759703,\n    \"_z\": -0.16464285714285715\n  }\n}"
  },
  {
    "timestamp": 127059,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.2074900380774618,\n    \"_y\": 0.10322909936759703,\n    \"_z\": -0.16464285714285715\n  }\n}"
  },
  {
    "timestamp": 127059,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.2074900380774618,\n    \"_y\": 0.10322909936759703,\n    \"_z\": -0.16464285714285715\n  }\n}"
  },
  {
    "timestamp": 127059,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.2074900380774618,\n    \"_y\": 0.10322909936759703,\n    \"_z\": -0.16464285714285715\n  }\n}"
  },
  {
    "timestamp": 127129,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\"\n  ]\n}"
  },
  {
    "timestamp": 127129,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n      \"title\": \"Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining\",\n      \"x\": -0.2074900380774618,\n      \"y\": 0.10322909936759703,\n      \"z\": -0.16464285714285715,\n      \"index\": 15,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 127129,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 127137,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 127137,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 127138,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 127420,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11463197453416865,\n    \"_y\": 0.09125596668864,\n    \"_z\": -0.2332142857142857\n  }\n}"
  },
  {
    "timestamp": 127420,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"2a1e4f5b076ae34fc8216aec4c742abc4fe58fea\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n    \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n    \"x\": -0.11463197453416865,\n    \"y\": 0.09125596668864,\n    \"z\": -0.2332142857142857,\n    \"index\": 7,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 127420,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 127495,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11463197453416865,\n    \"_y\": 0.09125596668864,\n    \"_z\": -0.2332142857142857\n  }\n}"
  },
  {
    "timestamp": 127496,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11463197453416865,\n    \"_y\": 0.09125596668864,\n    \"_z\": -0.2332142857142857\n  }\n}"
  },
  {
    "timestamp": 127578,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11463197453416865,\n    \"_y\": 0.09125596668864,\n    \"_z\": -0.2332142857142857\n  }\n}"
  },
  {
    "timestamp": 127578,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11463197453416865,\n    \"_y\": 0.09125596668864,\n    \"_z\": -0.2332142857142857\n  }\n}"
  },
  {
    "timestamp": 127578,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.11463197453416865,\n    \"_y\": 0.09125596668864,\n    \"_z\": -0.2332142857142857\n  }\n}"
  },
  {
    "timestamp": 127589,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"cd18ea985c15101531c93d2bb09504b26d0fa770\"\n  ]\n}"
  },
  {
    "timestamp": 127589,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"cd18ea985c15101531c93d2bb09504b26d0fa770\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n      \"title\": \"A Novel Non-iterative Training Method for CNN Classifiers Using Gram–Schmidt Process\",\n      \"x\": -0.11463197453416865,\n      \"y\": 0.09125596668864,\n      \"z\": -0.2332142857142857,\n      \"index\": 7,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 127590,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 127601,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 127602,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 127602,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 128266,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": []\n}"
  },
  {
    "timestamp": 128266,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 128267,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 128279,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 128280,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 128280,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 128747,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.13695553964639767,\n    \"_y\": 0.008940200331813086,\n    \"_z\": -0.11892857142857143\n  }\n}"
  },
  {
    "timestamp": 128748,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"cd18ea985c15101531c93d2bb09504b26d0fa770\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n    \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n    \"x\": -0.13695553964639767,\n    \"y\": 0.008940200331813086,\n    \"z\": -0.11892857142857143,\n    \"index\": 13,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 128748,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 128976,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.13695553964639767,\n    \"_y\": 0.008940200331813086,\n    \"_z\": -0.11892857142857143\n  }\n}"
  },
  {
    "timestamp": 128976,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.13695553964639767,\n    \"_y\": 0.008940200331813086,\n    \"_z\": -0.11892857142857143\n  }\n}"
  },
  {
    "timestamp": 129077,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.13695553964639767,\n    \"_y\": 0.008940200331813086,\n    \"_z\": -0.11892857142857143\n  }\n}"
  },
  {
    "timestamp": 129077,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.13695553964639767,\n    \"_y\": 0.008940200331813086,\n    \"_z\": -0.11892857142857143\n  }\n}"
  },
  {
    "timestamp": 129077,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.13695553964639767,\n    \"_y\": 0.008940200331813086,\n    \"_z\": -0.11892857142857143\n  }\n}"
  },
  {
    "timestamp": 129084,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\"\n  ]\n}"
  },
  {
    "timestamp": 129084,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n      \"title\": \"T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting\",\n      \"x\": -0.13695553964639767,\n      \"y\": 0.008940200331813086,\n      \"z\": -0.11892857142857143,\n      \"index\": 13,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 129085,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 129091,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 129091,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 129092,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 129368,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10620941305946394,\n    \"_y\": -0.011662229696661017,\n    \"_z\": -0.21035714285714285\n  }\n}"
  },
  {
    "timestamp": 129368,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"44d6de1abfd1ae8bfbf05010cbafe681f613f694\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n    \"title\": \"On the Internal Representations of Graph Metanetworks\",\n    \"x\": -0.10620941305946394,\n    \"y\": -0.011662229696661017,\n    \"z\": -0.21035714285714285,\n    \"index\": 21,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 129368,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 129747,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10620941305946394,\n    \"_y\": -0.011662229696661017,\n    \"_z\": -0.21035714285714285\n  }\n}"
  },
  {
    "timestamp": 129748,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10620941305946394,\n    \"_y\": -0.011662229696661017,\n    \"_z\": -0.21035714285714285\n  }\n}"
  },
  {
    "timestamp": 129828,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10620941305946394,\n    \"_y\": -0.011662229696661017,\n    \"_z\": -0.21035714285714285\n  }\n}"
  },
  {
    "timestamp": 129829,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10620941305946394,\n    \"_y\": -0.011662229696661017,\n    \"_z\": -0.21035714285714285\n  }\n}"
  },
  {
    "timestamp": 129829,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.10620941305946394,\n    \"_y\": -0.011662229696661017,\n    \"_z\": -0.21035714285714285\n  }\n}"
  },
  {
    "timestamp": 129986,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"41163e665789ee13f2db5e442eea15fcb188c01c\"\n  ]\n}"
  },
  {
    "timestamp": 129986,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"41163e665789ee13f2db5e442eea15fcb188c01c\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n      \"title\": \"On the Internal Representations of Graph Metanetworks\",\n      \"x\": -0.10620941305946394,\n      \"y\": -0.011662229696661017,\n      \"z\": -0.21035714285714285,\n      \"index\": 21,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 129987,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 129999,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 130001,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 130001,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 130371,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": []\n}"
  },
  {
    "timestamp": 130371,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 130372,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 130387,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 130389,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 130389,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 131366,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1909067216943809,\n    \"_y\": 0.07014166911203673,\n    \"_z\": -0.2560714285714286\n  }\n}"
  },
  {
    "timestamp": 131366,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"41163e665789ee13f2db5e442eea15fcb188c01c\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n    \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n    \"x\": -0.1909067216943809,\n    \"y\": 0.07014166911203673,\n    \"z\": -0.2560714285714286,\n    \"index\": 29,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 131366,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 131378,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1909067216943809,\n    \"_y\": 0.07014166911203673,\n    \"_z\": -0.2560714285714286\n  }\n}"
  },
  {
    "timestamp": 131379,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 131379,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 131379,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 131885,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.21957674522002024,\n    \"_y\": -0.009512572335558356,\n    \"_z\": -0.1875\n  }\n}"
  },
  {
    "timestamp": 131885,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n    \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n    \"x\": -0.21957674522002024,\n    \"y\": -0.009512572335558356,\n    \"z\": -0.1875,\n    \"index\": 14,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 131885,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 132229,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.21957674522002024,\n    \"_y\": -0.009512572335558356,\n    \"_z\": -0.1875\n  }\n}"
  },
  {
    "timestamp": 132230,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.21957674522002024,\n    \"_y\": -0.009512572335558356,\n    \"_z\": -0.1875\n  }\n}"
  },
  {
    "timestamp": 132311,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.21957674522002024,\n    \"_y\": -0.009512572335558356,\n    \"_z\": -0.1875\n  }\n}"
  },
  {
    "timestamp": 132311,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.21957674522002024,\n    \"_y\": -0.009512572335558356,\n    \"_z\": -0.1875\n  }\n}"
  },
  {
    "timestamp": 132312,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.21957674522002024,\n    \"_y\": -0.009512572335558356,\n    \"_z\": -0.1875\n  }\n}"
  },
  {
    "timestamp": 133262,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"03e254756631ec4873a24587e7a9c8d5f09129cc\"\n  ]\n}"
  },
  {
    "timestamp": 133262,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"03e254756631ec4873a24587e7a9c8d5f09129cc\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n      \"title\": \"Open-source framework for detecting bias and overfitting for large pathology images\",\n      \"x\": -0.21957674522002024,\n      \"y\": -0.009512572335558356,\n      \"z\": -0.1875,\n      \"index\": 14,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 133263,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 133280,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 133282,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 133283,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 133833,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1909067216943809,\n    \"_y\": 0.07014166911203673,\n    \"_z\": -0.2560714285714286\n  }\n}"
  },
  {
    "timestamp": 133833,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"03e254756631ec4873a24587e7a9c8d5f09129cc\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": {\n    \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n    \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n    \"x\": -0.1909067216943809,\n    \"y\": 0.07014166911203673,\n    \"z\": -0.2560714285714286,\n    \"index\": 29,\n    \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n  }\n}"
  },
  {
    "timestamp": 133833,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 134245,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1909067216943809,\n    \"_y\": 0.07014166911203673,\n    \"_z\": -0.2560714285714286\n  }\n}"
  },
  {
    "timestamp": 134246,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1909067216943809,\n    \"_y\": 0.07014166911203673,\n    \"_z\": -0.2560714285714286\n  }\n}"
  },
  {
    "timestamp": 134360,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1909067216943809,\n    \"_y\": 0.07014166911203673,\n    \"_z\": -0.2560714285714286\n  }\n}"
  },
  {
    "timestamp": 134361,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1909067216943809,\n    \"_y\": 0.07014166911203673,\n    \"_z\": -0.2560714285714286\n  }\n}"
  },
  {
    "timestamp": 134361,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1909067216943809,\n    \"_y\": 0.07014166911203673,\n    \"_z\": -0.2560714285714286\n  }\n}"
  },
  {
    "timestamp": 134600,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.1909067216943809,\n    \"_y\": 0.07014166911203673,\n    \"_z\": -0.2560714285714286\n  }\n}"
  },
  {
    "timestamp": 134601,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 134601,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 134601,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 134982,
    "eventType": "removeSelectedNodesFromGraph() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"1d10aa5e7122d1df6d559999987c76de3a088f62\"\n  ]\n}"
  },
  {
    "timestamp": 134982,
    "eventType": "removeNodesFromGraph() called",
    "eventData": "{\n  \"idsToRemove\": [\n    \"1d10aa5e7122d1df6d559999987c76de3a088f62\"\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"1d10aa5e7122d1df6d559999987c76de3a088f62\",\n      \"title\": \"Training Machine Learning models at the Edge: A Survey\",\n      \"x\": -0.1909067216943809,\n      \"y\": 0.07014166911203673,\n      \"z\": -0.2560714285714286,\n      \"index\": 29,\n      \"clusterName\": \"Image Processing and Computer Vision Techniques\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 134983,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 134997,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 134999,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 135000,
    "eventType": "removeNodesFromGraph() finished",
    "eventData": "{\n  \"newPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Generalization and Robustness in Deep Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Neural Network Architectures\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Pruning and Distillation\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 152722,
    "eventType": "Socket - on createClustersGemini",
    "eventData": "{\n  \"data\": {\n    \"status\": \"success\",\n    \"clusters\": [\n      {\n        \"name\": \"Image Classification and Deep Learning\",\n        \"paperIds\": [\n          \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n          \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n          \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n          \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n          \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n          \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n        ]\n      },\n      {\n        \"name\": \"Robustness and Generalization in Deep Learning\",\n        \"paperIds\": [\n          \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n          \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n          \"357e28348a770052ff9b048ee3cb61be388fac21\",\n          \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n          \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n        ]\n      },\n      {\n        \"name\": \"Dataset Distillation and Pruning\",\n        \"paperIds\": [\n          \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n          \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n          \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n          \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n        ]\n      },\n      {\n        \"name\": \"Privacy and Bias in Machine Learning\",\n        \"paperIds\": [\n          \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n          \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n          \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n          \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n          \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n        ]\n      }\n    ]\n  }\n}"
  },
  {
    "timestamp": 152722,
    "eventType": "createClustersFromGemini() called",
    "eventData": "{\n  \"response\": [\n    {\n      \"name\": \"Image Classification and Deep Learning\",\n      \"paperIds\": [\n        \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      ]\n    },\n    {\n      \"name\": \"Robustness and Generalization in Deep Learning\",\n      \"paperIds\": [\n        \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      ]\n    },\n    {\n      \"name\": \"Dataset Distillation and Pruning\",\n      \"paperIds\": [\n        \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      ]\n    },\n    {\n      \"name\": \"Privacy and Bias in Machine Learning\",\n      \"paperIds\": [\n        \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      ]\n    }\n  ]\n}"
  },
  {
    "timestamp": 152723,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 4,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.25,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.1647713102876082,\n      \"_y\": 0.013934321156940025,\n      \"_z\": 0.1875\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.03176451489194737,\n      \"_y\": 0.23996825955463205,\n      \"_z\": 0.0625\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.2382006536929117,\n      \"_y\": -0.043060406178640945,\n      \"_z\": -0.06250000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.03706679402019098,\n      \"_y\": -0.16115149016085684,\n      \"_z\": -0.1875\n    }\n  ]\n}"
  },
  {
    "timestamp": 152723,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 6,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0.1647713102876082,\n    \"_y\": 0.013934321156940025,\n    \"_z\": 0.1875\n  },\n  \"radius\": 0.08,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.1206275431066337,\n      \"_y\": 0.016557939770129662,\n      \"_z\": 0.25416666666666665\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.16393121648177938,\n      \"_y\": -0.055342617591805275,\n      \"_z\": 0.22749999999999998\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.24360375565242318,\n      \"_y\": 0.016703396819626536,\n      \"_z\": 0.20083333333333334\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.15828284784554586,\n      \"_y\": 0.09254807362659491,\n      \"_z\": 0.17416666666666666\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.09607018352481327,\n      \"_y\": 0.004981378538874129,\n      \"_z\": 0.14749999999999996\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.17255010523187594,\n      \"_y\": -0.029597803817274032,\n      \"_z\": 0.12083333333333333\n    }\n  ]\n}"
  },
  {
    "timestamp": 152723,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": -0.03176451489194737,\n    \"_y\": 0.23996825955463205,\n    \"_z\": 0.0625\n  },\n  \"radius\": 0.08,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.06096905394645133,\n      \"_y\": 0.278061499094135,\n      \"_z\": 0.1265\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.08778147068534217,\n      \"_y\": 0.19265969094765711,\n      \"_z\": 0.0945\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.022681855113819684,\n      \"_y\": 0.1813543295277595,\n      \"_z\": 0.0625\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.019539788186140827,\n      \"_y\": 0.2923502076443287,\n      \"_z\": 0.0305\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.06760425717457741,\n      \"_y\": 0.2718980712220168,\n      \"_z\": -0.0015000000000000013\n    }\n  ]\n}"
  },
  {
    "timestamp": 152723,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 4,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": -0.2382006536929117,\n    \"_y\": -0.043060406178640945,\n    \"_z\": -0.06250000000000003\n  },\n  \"radius\": 0.08,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.19586302960624674,\n      \"_y\": -0.07480194972485568,\n      \"_z\": -0.00250000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.19471413247743763,\n      \"_y\": 0.021040471136541894,\n      \"_z\": -0.042500000000000024\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.3042834647800015,\n      \"_y\": -0.0026492433788896513,\n      \"_z\": -0.08250000000000005\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.26364427498660964,\n      \"_y\": -0.08945676525414256,\n      \"_z\": -0.12250000000000003\n    }\n  ]\n}"
  },
  {
    "timestamp": 152723,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0.03706679402019098,\n    \"_y\": -0.16115149016085684,\n    \"_z\": -0.1875\n  },\n  \"radius\": 0.08,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.0828808396506205,\n      \"_y\": -0.14683111226874376,\n      \"_z\": -0.1235\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.011911894533447032,\n      \"_y\": -0.09228037116448935,\n      \"_z\": -0.1555\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.0366979199908458,\n      \"_y\": -0.1921154525505439,\n      \"_z\": -0.1875\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.06860646222046178,\n      \"_y\": -0.22734249657273148,\n      \"_z\": -0.2195\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.0793756629271107,\n      \"_y\": -0.1384808128040357,\n      \"_z\": -0.2515\n    }\n  ]\n}"
  },
  {
    "timestamp": 152723,
    "eventType": "regenerateUserLinkData() called",
    "eventData": "{\n  \"oldUserLinkData\": [\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 0\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 1\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 2\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 3\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 4\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 5\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 6\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 7\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 8\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 9\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 10\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 11\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 12\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 13\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 14\n    },\n    {\n      \"source\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 15\n    },\n    {\n      \"source\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 16\n    },\n    {\n      \"source\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 17\n    },\n    {\n      \"source\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"index\": 18\n    },\n    {\n      \"source\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 19\n    },\n    {\n      \"source\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 20\n    },\n    {\n      \"source\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": 0.18083636159917812,\n        \"y\": -0.14259606732108882,\n        \"z\": 0.09450000000000001,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": 0.2913825188784994,\n        \"y\": -0.13213162016790214,\n        \"z\": 0.0625,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"index\": 21\n    },\n    {\n      \"source\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": 0.18083636159917812,\n        \"y\": -0.14259606732108882,\n        \"z\": 0.09450000000000001,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": 0.26664439766961706,\n        \"y\": -0.023881987824411338,\n        \"z\": 0.0305,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"index\": 22\n    },\n    {\n      \"source\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": 0.18083636159917812,\n        \"y\": -0.14259606732108882,\n        \"z\": 0.09450000000000001,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": 0.18516557005172887,\n        \"y\": -0.060943762958398734,\n        \"z\": -0.0015000000000000013,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"index\": 23\n    },\n    {\n      \"source\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": 0.2913825188784994,\n        \"y\": -0.13213162016790214,\n        \"z\": 0.0625,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": 0.26664439766961706,\n        \"y\": -0.023881987824411338,\n        \"z\": 0.0305,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"index\": 24\n    },\n    {\n      \"source\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": 0.2913825188784994,\n        \"y\": -0.13213162016790214,\n        \"z\": 0.0625,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": 0.18516557005172887,\n        \"y\": -0.060943762958398734,\n        \"z\": -0.0015000000000000013,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"index\": 25\n    },\n    {\n      \"source\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": 0.26664439766961706,\n        \"y\": -0.023881987824411338,\n        \"z\": 0.0305,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": 0.18516557005172887,\n        \"y\": -0.060943762958398734,\n        \"z\": -0.0015000000000000013,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"index\": 26\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 27\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 28\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 29\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 30\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 31\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 32\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 33\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 34\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 35\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 36\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 37\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 38\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 39\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 40\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 41\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 42\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 43\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 44\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 45\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 46\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 47\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 48\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 49\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 50\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 51\n    },\n    {\n      \"source\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 52\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 53\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 54\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 55\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 56\n    },\n    {\n      \"source\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 57\n    },\n    {\n      \"source\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 58\n    },\n    {\n      \"source\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 59\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"index\": 60\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 61\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"index\": 62\n    }\n  ],\n  \"newUserLinkData\": [\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n        \"x\": -0.09838895208114697,\n        \"y\": -0.17227650394465774,\n        \"z\": 0.2575,\n        \"index\": 0,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n        \"x\": -0.03006645094793528,\n        \"y\": -0.2032677315912606,\n        \"z\": 0.2375,\n        \"index\": 3,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n        \"x\": -0.01269979027604505,\n        \"y\": -0.20392435401887132,\n        \"z\": 0.15750000000000003,\n        \"index\": 5,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n        \"x\": -0.006470465446009752,\n        \"y\": -0.10693175107307869,\n        \"z\": 0.2175,\n        \"index\": 10,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n        \"x\": -0.11648138210636405,\n        \"y\": -0.09100964909163628,\n        \"z\": 0.1975,\n        \"index\": 23,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n        \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n        \"x\": -0.12384366954848036,\n        \"y\": -0.2056428464492281,\n        \"z\": 0.1775,\n        \"index\": 24,\n        \"clusterName\": \"Image Classification and Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n        \"x\": 0.0519219027406135,\n        \"y\": 0.17782828231690545,\n        \"z\": -0.11850000000000005,\n        \"index\": 12,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n        \"x\": 0.029875311473101795,\n        \"y\": 0.16438889725981487,\n        \"z\": -0.05450000000000002,\n        \"index\": 16,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n        \"x\": 0.14243807554252957,\n        \"y\": 0.18888373763050448,\n        \"z\": -0.07050000000000003,\n        \"index\": 17,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n        \"x\": 0.11853358912834167,\n        \"y\": 0.2837877416279173,\n        \"z\": -0.022500000000000034,\n        \"index\": 18,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n        \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n        \"x\": 0.013353091353720703,\n        \"y\": 0.2760164180782014,\n        \"z\": -0.03850000000000002,\n        \"index\": 19,\n        \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": 0.18083636159917812,\n        \"y\": -0.14259606732108882,\n        \"z\": 0.09450000000000001,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": 0.2913825188784994,\n        \"y\": -0.13213162016790214,\n        \"z\": 0.0625,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": 0.18083636159917812,\n        \"y\": -0.14259606732108882,\n        \"z\": 0.09450000000000001,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": 0.26664439766961706,\n        \"y\": -0.023881987824411338,\n        \"z\": 0.0305,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n        \"x\": 0.18083636159917812,\n        \"y\": -0.14259606732108882,\n        \"z\": 0.09450000000000001,\n        \"index\": 25,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": 0.18516557005172887,\n        \"y\": -0.060943762958398734,\n        \"z\": -0.0015000000000000013,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": 0.2913825188784994,\n        \"y\": -0.13213162016790214,\n        \"z\": 0.0625,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": 0.26664439766961706,\n        \"y\": -0.023881987824411338,\n        \"z\": 0.0305,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n        \"x\": 0.2913825188784994,\n        \"y\": -0.13213162016790214,\n        \"z\": 0.0625,\n        \"index\": 26,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": 0.18516557005172887,\n        \"y\": -0.060943762958398734,\n        \"z\": -0.0015000000000000013,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n        \"x\": 0.26664439766961706,\n        \"y\": -0.023881987824411338,\n        \"z\": 0.0305,\n        \"index\": 27,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      },\n      \"target\": {\n        \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"title\": \"Multisize Dataset Condensation\",\n        \"x\": 0.18516557005172887,\n        \"y\": -0.060943762958398734,\n        \"z\": -0.0015000000000000013,\n        \"index\": 28,\n        \"clusterName\": \"Dataset Distillation and Pruning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n        \"x\": 0.11108018569334135,\n        \"y\": 0.2972828608093327,\n        \"z\": -0.08650000000000002,\n        \"index\": 6,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n        \"x\": 0.04985887653367206,\n        \"y\": 0.20562041995166205,\n        \"z\": 0.00949999999999998,\n        \"index\": 8,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n        \"x\": 0.1168004363861313,\n        \"y\": 0.1919465330392418,\n        \"z\": -0.0065000000000000335,\n        \"index\": 9,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    },\n    {\n      \"source\": {\n        \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n        \"x\": 0.10712807515470196,\n        \"y\": 0.21808279940704042,\n        \"z\": -0.13450000000000004,\n        \"index\": 20,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      },\n      \"target\": {\n        \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n        \"x\": -0.09550407767996394,\n        \"y\": -0.1273580761893279,\n        \"z\": 0.1175,\n        \"index\": 1,\n        \"clusterName\": \"Privacy and Bias in Machine Learning\"\n      }\n    }\n  ]\n}"
  },
  {
    "timestamp": 152725,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 152727,
    "eventType": "createClustersFromGemini() finished",
    "eventData": "{\n  \"response\": [\n    {\n      \"name\": \"Image Classification and Deep Learning\",\n      \"paperIds\": [\n        \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      ]\n    },\n    {\n      \"name\": \"Robustness and Generalization in Deep Learning\",\n      \"paperIds\": [\n        \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      ]\n    },\n    {\n      \"name\": \"Dataset Distillation and Pruning\",\n      \"paperIds\": [\n        \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      ]\n    },\n    {\n      \"name\": \"Privacy and Bias in Machine Learning\",\n      \"paperIds\": [\n        \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      ]\n    }\n  ],\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": -0.09838895208114697,\n      \"y\": -0.17227650394465774,\n      \"z\": 0.2575,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": -0.09550407767996394,\n      \"y\": -0.1273580761893279,\n      \"z\": 0.1175,\n      \"index\": 1,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": -0.03006645094793528,\n      \"y\": -0.2032677315912606,\n      \"z\": 0.2375,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": -0.01269979027604505,\n      \"y\": -0.20392435401887132,\n      \"z\": 0.15750000000000003,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.11108018569334135,\n      \"y\": 0.2972828608093327,\n      \"z\": -0.08650000000000002,\n      \"index\": 6,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.04985887653367206,\n      \"y\": 0.20562041995166205,\n      \"z\": 0.00949999999999998,\n      \"index\": 8,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": 0.1168004363861313,\n      \"y\": 0.1919465330392418,\n      \"z\": -0.0065000000000000335,\n      \"index\": 9,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": -0.006470465446009752,\n      \"y\": -0.10693175107307869,\n      \"z\": 0.2175,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": 0.0519219027406135,\n      \"y\": 0.17782828231690545,\n      \"z\": -0.11850000000000005,\n      \"index\": 12,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": 0.029875311473101795,\n      \"y\": 0.16438889725981487,\n      \"z\": -0.05450000000000002,\n      \"index\": 16,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.14243807554252957,\n      \"y\": 0.18888373763050448,\n      \"z\": -0.07050000000000003,\n      \"index\": 17,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.11853358912834167,\n      \"y\": 0.2837877416279173,\n      \"z\": -0.022500000000000034,\n      \"index\": 18,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": 0.013353091353720703,\n      \"y\": 0.2760164180782014,\n      \"z\": -0.03850000000000002,\n      \"index\": 19,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.10712807515470196,\n      \"y\": 0.21808279940704042,\n      \"z\": -0.13450000000000004,\n      \"index\": 20,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": -0.11648138210636405,\n      \"y\": -0.09100964909163628,\n      \"z\": 0.1975,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": -0.12384366954848036,\n      \"y\": -0.2056428464492281,\n      \"z\": 0.1775,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": 0.18083636159917812,\n      \"y\": -0.14259606732108882,\n      \"z\": 0.09450000000000001,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": 0.2913825188784994,\n      \"y\": -0.13213162016790214,\n      \"z\": 0.0625,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": 0.26664439766961706,\n      \"y\": -0.023881987824411338,\n      \"z\": 0.0305,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": 0.18516557005172887,\n      \"y\": -0.060943762958398734,\n      \"z\": -0.0015000000000000013,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 156419,
    "eventType": "Socket - on unpinNodes",
    "eventData": "{\n  \"data\": {\n    \"info\": \"Event: \\\"unpinNodes\\\"\"\n  }\n}"
  },
  {
    "timestamp": 156419,
    "eventType": "unpinNodes() called",
    "eventData": "{\n  \"pinnedNodeIds\": [\n    \"95e706662b99267d21a1ccc7ed380d1cd0e06057\",\n    \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n    \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n    \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n    \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n    \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n    \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n    \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n    \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n    \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n    \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n    \"357e28348a770052ff9b048ee3cb61be388fac21\",\n    \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n    \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n    \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n    \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n    \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n    \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n    \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n    \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n    \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n    \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n    \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n    \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n    \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n    \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n    \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n    \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n    \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n    \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n    \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n    \"357e28348a770052ff9b048ee3cb61be388fac21\",\n    \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n    \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n    \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n    \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n    \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n    \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n    \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n    \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n    \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n  ]\n}"
  },
  {
    "timestamp": 156468,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.15828284784554586,\n    \"_y\": 0.09254807362659491,\n    \"_z\": 0.17416666666666666\n  }\n}"
  },
  {
    "timestamp": 156468,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n    \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n    \"x\": 0.15828284784554586,\n    \"y\": 0.09254807362659491,\n    \"z\": 0.17416666666666666,\n    \"index\": 10,\n    \"clusterName\": \"Image Classification and Deep Learning\"\n  }\n}"
  },
  {
    "timestamp": 156468,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 156762,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.15828284784554586,\n    \"_y\": 0.09254807362659491,\n    \"_z\": 0.17416666666666666\n  }\n}"
  },
  {
    "timestamp": 156763,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.15828284784554586,\n    \"_y\": 0.09254807362659491,\n    \"_z\": 0.17416666666666666\n  }\n}"
  },
  {
    "timestamp": 156877,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.15828284784554586,\n    \"_y\": 0.09254807362659491,\n    \"_z\": 0.17416666666666666\n  }\n}"
  },
  {
    "timestamp": 156877,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.15828284784554586,\n    \"_y\": 0.09254807362659491,\n    \"_z\": 0.17416666666666666\n  }\n}"
  },
  {
    "timestamp": 156877,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.15828284784554586,\n    \"_y\": 0.09254807362659491,\n    \"_z\": 0.17416666666666666\n  }\n}"
  },
  {
    "timestamp": 157011,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": 0.15828284784554586,\n    \"_y\": 0.09254807362659491,\n    \"_z\": 0.17416666666666666\n  }\n}"
  },
  {
    "timestamp": 157011,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 157011,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 157011,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 160270,
    "eventType": "Socket - on recommendByThematicSimilarity",
    "eventData": "{\n  \"data\": {\n    \"info\": \"Event: \\\"recommendByThematicSimilarity\\\"\"\n  }\n}"
  },
  {
    "timestamp": 160270,
    "eventType": "addRecommendationsFromSelectedPapers() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n  ]\n}"
  },
  {
    "timestamp": 173484,
    "eventType": "addPapersToGraph() called",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\",\n      \"title\": \"Application of Deep Learning and Transfer Learning Techniques for Medical Image Classification\"\n    },\n    {\n      \"paperId\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\",\n      \"title\": \"Research on image feature extraction and classification based on deep learning\"\n    },\n    {\n      \"paperId\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\",\n      \"title\": \"Research on the Application of Deep Learning Methods in the Field of Image Classification\"\n    },\n    {\n      \"paperId\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\",\n      \"title\": \"Review on Image Processing Method based on AI Large Models\"\n    },\n    {\n      \"paperId\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\",\n      \"title\": \"Analysis of The Role of Deep Learning Models in Image Classification Applications\"\n    }\n  ],\n  \"prevPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.12062754310663369,\n      \"y\": 0.016557939770129676,\n      \"z\": 0.25416666666666665,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.07937566292711068,\n      \"y\": -0.1384808128040357,\n      \"z\": -0.2515,\n      \"index\": 1,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.16393121648177938,\n      \"y\": -0.05534261759180528,\n      \"z\": 0.22749999999999998,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.24360375565242315,\n      \"y\": 0.016703396819626543,\n      \"z\": 0.20083333333333334,\n      \"index\": 5,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.0828808396506205,\n      \"y\": -0.14683111226874374,\n      \"z\": -0.1235,\n      \"index\": 6,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.011911894533447029,\n      \"y\": -0.09228037116448937,\n      \"z\": -0.1555,\n      \"index\": 8,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.03669791999084579,\n      \"y\": -0.1921154525505439,\n      \"z\": -0.1875,\n      \"index\": 9,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.15828284784554586,\n      \"y\": 0.09254807362659491,\n      \"z\": 0.17416666666666666,\n      \"index\": 10,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.060969053946451336,\n      \"y\": 0.278061499094135,\n      \"z\": 0.1265,\n      \"index\": 12,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": -0.08778147068534217,\n      \"y\": 0.19265969094765711,\n      \"z\": 0.0945,\n      \"index\": 16,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.022681855113819677,\n      \"y\": 0.1813543295277595,\n      \"z\": 0.0625,\n      \"index\": 17,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.019539788186140827,\n      \"y\": 0.2923502076443287,\n      \"z\": 0.0305,\n      \"index\": 18,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": -0.06760425717457741,\n      \"y\": 0.2718980712220168,\n      \"z\": -0.0015000000000000013,\n      \"index\": 19,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.06860646222046178,\n      \"y\": -0.22734249657273145,\n      \"z\": -0.2195,\n      \"index\": 20,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.09607018352481328,\n      \"y\": 0.004981378538874134,\n      \"z\": 0.14749999999999996,\n      \"index\": 23,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.17255010523187597,\n      \"y\": -0.029597803817274032,\n      \"z\": 0.12083333333333333,\n      \"index\": 24,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": -0.1958630296062467,\n      \"y\": -0.07480194972485568,\n      \"z\": -0.00250000000000003,\n      \"index\": 25,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.19471413247743763,\n      \"y\": 0.021040471136541894,\n      \"z\": -0.042500000000000024,\n      \"index\": 26,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.3042834647800015,\n      \"y\": -0.0026492433788896513,\n      \"z\": -0.08250000000000005,\n      \"index\": 27,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": -0.2636442749866097,\n      \"y\": -0.08945676525414256,\n      \"z\": -0.12250000000000003,\n      \"index\": 28,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    }\n  ]\n}"
  },
  {
    "timestamp": 173484,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.2,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.09775672941540008,\n      \"_y\": 0.06959613390127536,\n      \"_z\": 0.16000000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.11324244487808473,\n      \"_y\": 0.1441393377188682,\n      \"_z\": 0.08000000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.1512590753317466,\n      \"_y\": -0.13084606272175336,\n      \"_z\": 1.2246467991473533e-17\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.12633480515851142,\n      \"_y\": -0.13281384342590555,\n      \"_z\": -0.08\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.08294471770826958,\n      \"_y\": 0.08671893567321655,\n      \"_z\": -0.16000000000000003\n    }\n  ]\n}"
  },
  {
    "timestamp": 173484,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.12062754310663369,\n      \"y\": 0.016557939770129676,\n      \"z\": 0.25416666666666665,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.07937566292711068,\n      \"y\": -0.1384808128040357,\n      \"z\": -0.2515,\n      \"index\": 1,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.16393121648177938,\n      \"y\": -0.05534261759180528,\n      \"z\": 0.22749999999999998,\n      \"index\": 2,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.24360375565242315,\n      \"y\": 0.016703396819626543,\n      \"z\": 0.20083333333333334,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.0828808396506205,\n      \"y\": -0.14683111226874374,\n      \"z\": -0.1235,\n      \"index\": 4,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.011911894533447029,\n      \"y\": -0.09228037116448937,\n      \"z\": -0.1555,\n      \"index\": 5,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.03669791999084579,\n      \"y\": -0.1921154525505439,\n      \"z\": -0.1875,\n      \"index\": 6,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.15828284784554586,\n      \"y\": 0.09254807362659491,\n      \"z\": 0.17416666666666666,\n      \"index\": 7,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.060969053946451336,\n      \"y\": 0.278061499094135,\n      \"z\": 0.1265,\n      \"index\": 8,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": -0.08778147068534217,\n      \"y\": 0.19265969094765711,\n      \"z\": 0.0945,\n      \"index\": 9,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.022681855113819677,\n      \"y\": 0.1813543295277595,\n      \"z\": 0.0625,\n      \"index\": 10,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.019539788186140827,\n      \"y\": 0.2923502076443287,\n      \"z\": 0.0305,\n      \"index\": 11,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": -0.06760425717457741,\n      \"y\": 0.2718980712220168,\n      \"z\": -0.0015000000000000013,\n      \"index\": 12,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.06860646222046178,\n      \"y\": -0.22734249657273145,\n      \"z\": -0.2195,\n      \"index\": 13,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.09607018352481328,\n      \"y\": 0.004981378538874134,\n      \"z\": 0.14749999999999996,\n      \"index\": 14,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.17255010523187597,\n      \"y\": -0.029597803817274032,\n      \"z\": 0.12083333333333333,\n      \"index\": 15,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": -0.1958630296062467,\n      \"y\": -0.07480194972485568,\n      \"z\": -0.00250000000000003,\n      \"index\": 16,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.19471413247743763,\n      \"y\": 0.021040471136541894,\n      \"z\": -0.042500000000000024,\n      \"index\": 17,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.3042834647800015,\n      \"y\": -0.0026492433788896513,\n      \"z\": -0.08250000000000005,\n      \"index\": 18,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": -0.2636442749866097,\n      \"y\": -0.08945676525414256,\n      \"z\": -0.12250000000000003,\n      \"index\": 19,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\",\n      \"title\": \"Application of Deep Learning and Transfer Learning Techniques for Medical Image Classification\",\n      \"x\": 0.09775672941540008,\n      \"y\": 0.06959613390127536,\n      \"z\": 0.16000000000000003,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\",\n      \"title\": \"Research on image feature extraction and classification based on deep learning\",\n      \"x\": -0.11324244487808473,\n      \"y\": 0.1441393377188682,\n      \"z\": 0.08000000000000002,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\",\n      \"title\": \"Research on the Application of Deep Learning Methods in the Field of Image Classification\",\n      \"x\": -0.1512590753317466,\n      \"y\": -0.13084606272175336,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\",\n      \"title\": \"Review on Image Processing Method based on AI Large Models\",\n      \"x\": 0.12633480515851142,\n      \"y\": -0.13281384342590555,\n      \"z\": -0.08,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\",\n      \"title\": \"Analysis of The Role of Deep Learning Models in Image Classification Applications\",\n      \"x\": 0.08294471770826958,\n      \"y\": 0.08671893567321655,\n      \"z\": -0.16000000000000003,\n      \"index\": 24\n    }\n  ]\n}"
  },
  {
    "timestamp": 173502,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.12062754310663369,\n      \"y\": 0.016557939770129676,\n      \"z\": 0.25416666666666665,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.07937566292711068,\n      \"y\": -0.1384808128040357,\n      \"z\": -0.2515,\n      \"index\": 1,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.16393121648177938,\n      \"y\": -0.05534261759180528,\n      \"z\": 0.22749999999999998,\n      \"index\": 2,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.24360375565242315,\n      \"y\": 0.016703396819626543,\n      \"z\": 0.20083333333333334,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.0828808396506205,\n      \"y\": -0.14683111226874374,\n      \"z\": -0.1235,\n      \"index\": 4,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.011911894533447029,\n      \"y\": -0.09228037116448937,\n      \"z\": -0.1555,\n      \"index\": 5,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.03669791999084579,\n      \"y\": -0.1921154525505439,\n      \"z\": -0.1875,\n      \"index\": 6,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.15828284784554586,\n      \"y\": 0.09254807362659491,\n      \"z\": 0.17416666666666666,\n      \"index\": 7,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.060969053946451336,\n      \"y\": 0.278061499094135,\n      \"z\": 0.1265,\n      \"index\": 8,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": -0.08778147068534217,\n      \"y\": 0.19265969094765711,\n      \"z\": 0.0945,\n      \"index\": 9,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.022681855113819677,\n      \"y\": 0.1813543295277595,\n      \"z\": 0.0625,\n      \"index\": 10,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.019539788186140827,\n      \"y\": 0.2923502076443287,\n      \"z\": 0.0305,\n      \"index\": 11,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": -0.06760425717457741,\n      \"y\": 0.2718980712220168,\n      \"z\": -0.0015000000000000013,\n      \"index\": 12,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.06860646222046178,\n      \"y\": -0.22734249657273145,\n      \"z\": -0.2195,\n      \"index\": 13,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.09607018352481328,\n      \"y\": 0.004981378538874134,\n      \"z\": 0.14749999999999996,\n      \"index\": 14,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.17255010523187597,\n      \"y\": -0.029597803817274032,\n      \"z\": 0.12083333333333333,\n      \"index\": 15,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": -0.1958630296062467,\n      \"y\": -0.07480194972485568,\n      \"z\": -0.00250000000000003,\n      \"index\": 16,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.19471413247743763,\n      \"y\": 0.021040471136541894,\n      \"z\": -0.042500000000000024,\n      \"index\": 17,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.3042834647800015,\n      \"y\": -0.0026492433788896513,\n      \"z\": -0.08250000000000005,\n      \"index\": 18,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": -0.2636442749866097,\n      \"y\": -0.08945676525414256,\n      \"z\": -0.12250000000000003,\n      \"index\": 19,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\",\n      \"title\": \"Application of Deep Learning and Transfer Learning Techniques for Medical Image Classification\",\n      \"x\": 0.09775672941540008,\n      \"y\": 0.06959613390127536,\n      \"z\": 0.16000000000000003,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\",\n      \"title\": \"Research on image feature extraction and classification based on deep learning\",\n      \"x\": -0.11324244487808473,\n      \"y\": 0.1441393377188682,\n      \"z\": 0.08000000000000002,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\",\n      \"title\": \"Research on the Application of Deep Learning Methods in the Field of Image Classification\",\n      \"x\": -0.1512590753317466,\n      \"y\": -0.13084606272175336,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\",\n      \"title\": \"Review on Image Processing Method based on AI Large Models\",\n      \"x\": 0.12633480515851142,\n      \"y\": -0.13281384342590555,\n      \"z\": -0.08,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\",\n      \"title\": \"Analysis of The Role of Deep Learning Models in Image Classification Applications\",\n      \"x\": 0.08294471770826958,\n      \"y\": 0.08671893567321655,\n      \"z\": -0.16000000000000003,\n      \"index\": 24\n    }\n  ]\n}"
  },
  {
    "timestamp": 173505,
    "eventType": "generateLinkData() finished",
    "eventData": "{\n  \"newLinkData\": {\n    \"citationLinkData\": [\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      }\n    ],\n    \"recommendationLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\"\n      }\n    ],\n    \"authorLinkData\": [\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      }\n    ],\n    \"userLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      }\n    ]\n  }\n}"
  },
  {
    "timestamp": 173505,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"custom\"\n}"
  },
  {
    "timestamp": 173506,
    "eventType": "addPapersToGraph() finished",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\",\n      \"title\": \"Application of Deep Learning and Transfer Learning Techniques for Medical Image Classification\",\n      \"x\": 0.09775672941540008,\n      \"y\": 0.06959613390127536,\n      \"z\": 0.16000000000000003,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\",\n      \"title\": \"Research on image feature extraction and classification based on deep learning\",\n      \"x\": -0.11324244487808473,\n      \"y\": 0.1441393377188682,\n      \"z\": 0.08000000000000002,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\",\n      \"title\": \"Research on the Application of Deep Learning Methods in the Field of Image Classification\",\n      \"x\": -0.1512590753317466,\n      \"y\": -0.13084606272175336,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\",\n      \"title\": \"Review on Image Processing Method based on AI Large Models\",\n      \"x\": 0.12633480515851142,\n      \"y\": -0.13281384342590555,\n      \"z\": -0.08,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\",\n      \"title\": \"Analysis of The Role of Deep Learning Models in Image Classification Applications\",\n      \"x\": 0.08294471770826958,\n      \"y\": 0.08671893567321655,\n      \"z\": -0.16000000000000003,\n      \"index\": 24\n    }\n  ],\n  \"currPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.12062754310663369,\n      \"y\": 0.016557939770129676,\n      \"z\": 0.25416666666666665,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.07937566292711068,\n      \"y\": -0.1384808128040357,\n      \"z\": -0.2515,\n      \"index\": 1,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.16393121648177938,\n      \"y\": -0.05534261759180528,\n      \"z\": 0.22749999999999998,\n      \"index\": 2,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.24360375565242315,\n      \"y\": 0.016703396819626543,\n      \"z\": 0.20083333333333334,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.0828808396506205,\n      \"y\": -0.14683111226874374,\n      \"z\": -0.1235,\n      \"index\": 4,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": 0.011911894533447029,\n      \"y\": -0.09228037116448937,\n      \"z\": -0.1555,\n      \"index\": 5,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.03669791999084579,\n      \"y\": -0.1921154525505439,\n      \"z\": -0.1875,\n      \"index\": 6,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.15828284784554586,\n      \"y\": 0.09254807362659491,\n      \"z\": 0.17416666666666666,\n      \"index\": 7,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.060969053946451336,\n      \"y\": 0.278061499094135,\n      \"z\": 0.1265,\n      \"index\": 8,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": -0.08778147068534217,\n      \"y\": 0.19265969094765711,\n      \"z\": 0.0945,\n      \"index\": 9,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.022681855113819677,\n      \"y\": 0.1813543295277595,\n      \"z\": 0.0625,\n      \"index\": 10,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.019539788186140827,\n      \"y\": 0.2923502076443287,\n      \"z\": 0.0305,\n      \"index\": 11,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": -0.06760425717457741,\n      \"y\": 0.2718980712220168,\n      \"z\": -0.0015000000000000013,\n      \"index\": 12,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.06860646222046178,\n      \"y\": -0.22734249657273145,\n      \"z\": -0.2195,\n      \"index\": 13,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.09607018352481328,\n      \"y\": 0.004981378538874134,\n      \"z\": 0.14749999999999996,\n      \"index\": 14,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.17255010523187597,\n      \"y\": -0.029597803817274032,\n      \"z\": 0.12083333333333333,\n      \"index\": 15,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": -0.1958630296062467,\n      \"y\": -0.07480194972485568,\n      \"z\": -0.00250000000000003,\n      \"index\": 16,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.19471413247743763,\n      \"y\": 0.021040471136541894,\n      \"z\": -0.042500000000000024,\n      \"index\": 17,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.3042834647800015,\n      \"y\": -0.0026492433788896513,\n      \"z\": -0.08250000000000005,\n      \"index\": 18,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": -0.2636442749866097,\n      \"y\": -0.08945676525414256,\n      \"z\": -0.12250000000000003,\n      \"index\": 19,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\",\n      \"title\": \"Application of Deep Learning and Transfer Learning Techniques for Medical Image Classification\",\n      \"x\": 0.09775672941540008,\n      \"y\": 0.06959613390127536,\n      \"z\": 0.16000000000000003,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\",\n      \"title\": \"Research on image feature extraction and classification based on deep learning\",\n      \"x\": -0.11324244487808473,\n      \"y\": 0.1441393377188682,\n      \"z\": 0.08000000000000002,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\",\n      \"title\": \"Research on the Application of Deep Learning Methods in the Field of Image Classification\",\n      \"x\": -0.1512590753317466,\n      \"y\": -0.13084606272175336,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\",\n      \"title\": \"Review on Image Processing Method based on AI Large Models\",\n      \"x\": 0.12633480515851142,\n      \"y\": -0.13281384342590555,\n      \"z\": -0.08,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\",\n      \"title\": \"Analysis of The Role of Deep Learning Models in Image Classification Applications\",\n      \"x\": 0.08294471770826958,\n      \"y\": 0.08671893567321655,\n      \"z\": -0.16000000000000003,\n      \"index\": 24\n    }\n  ]\n}"
  },
  {
    "timestamp": 173506,
    "eventType": "setLinkType() called",
    "eventData": "{\n  \"currLinkType\": \"custom\",\n  \"newLinkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 173506,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type recommendation\"\n}"
  },
  {
    "timestamp": 173506,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 184478,
    "eventType": "node onPointerOverTrigger",
    "eventData": "{\n  \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.22021808580936547,\n    \"_y\": 0.0807631516784766,\n    \"_z\": -0.019942678808225624\n  }\n}"
  },
  {
    "timestamp": 184478,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false,\n  \"nodeData\": {\n    \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n    \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n    \"x\": -0.22021808580936547,\n    \"y\": 0.0807631516784766,\n    \"z\": -0.019942678808225624,\n    \"index\": 17,\n    \"clusterName\": \"Dataset Distillation and Pruning\"\n  }\n}"
  },
  {
    "timestamp": 184478,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true\n}"
  },
  {
    "timestamp": 184592,
    "eventType": "node onPickDownTrigger",
    "eventData": "{\n  \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.220218085987211,\n    \"_y\": 0.08076315254883056,\n    \"_z\": -0.01994267853428454\n  }\n}"
  },
  {
    "timestamp": 184593,
    "eventType": "node drag onDragStartObservable",
    "eventData": "{\n  \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.220218085987211,\n    \"_y\": 0.08076315254883056,\n    \"_z\": -0.01994267853428454\n  }\n}"
  },
  {
    "timestamp": 184694,
    "eventType": "node onPickUpTrigger",
    "eventData": "{\n  \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.22021808616549618,\n    \"_y\": 0.08076315309573855,\n    \"_z\": -0.019942678383611096\n  }\n}"
  },
  {
    "timestamp": 184694,
    "eventType": "node onPickUpTrigger - short click detected",
    "eventData": "{\n  \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.22021808616549618,\n    \"_y\": 0.08076315309573855,\n    \"_z\": -0.019942678383611096\n  }\n}"
  },
  {
    "timestamp": 184695,
    "eventType": "node drag onDragEndObservable",
    "eventData": "{\n  \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.22021808616549618,\n    \"_y\": 0.08076315309573855,\n    \"_z\": -0.019942678383611096\n  }\n}"
  },
  {
    "timestamp": 184865,
    "eventType": "node onPointerOutTrigger",
    "eventData": "{\n  \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n  \"position\": {\n    \"_isDirty\": false,\n    \"_x\": -0.22021808648311547,\n    \"_y\": 0.080763153748192,\n    \"_z\": -0.01994267823771102\n  }\n}"
  },
  {
    "timestamp": 184865,
    "eventType": "setHoverPlaneToNode() called",
    "eventData": "{\n  \"hoverPlaneId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": true,\n  \"nodeData\": null\n}"
  },
  {
    "timestamp": 184866,
    "eventType": "setHoverPlaneToNode() - hiding hover plane",
    "eventData": "{}"
  },
  {
    "timestamp": 184866,
    "eventType": "setHoverPlaneToNode() finished",
    "eventData": "{\n  \"hoverPlaneId\": null,\n  \"paperDetailsPanelId\": null,\n  \"hoverPlaneVisibility\": false\n}"
  },
  {
    "timestamp": 187907,
    "eventType": "Socket - on recommendByThematicSimilarity",
    "eventData": "{\n  \"data\": {\n    \"info\": \"Event: \\\"recommendByThematicSimilarity\\\"\"\n  }\n}"
  },
  {
    "timestamp": 187908,
    "eventType": "addRecommendationsFromSelectedPapers() called",
    "eventData": "{\n  \"selectedIds\": [\n    \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n  ]\n}"
  },
  {
    "timestamp": 194427,
    "eventType": "addPapersToGraph() called",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"b77c3594adc3503efc12c69d10061fcf86a01297\",\n      \"title\": \"The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions\"\n    },\n    {\n      \"paperId\": \"99bfd821693ff6fd7dafbd8aba80794d45b4bd44\",\n      \"title\": \"Efficient Dataset Distillation through Low-Rank Space Sampling\"\n    },\n    {\n      \"paperId\": \"bb96ea820db5f255f88fd7dda059021063e7c830\",\n      \"title\": \"Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images\"\n    },\n    {\n      \"paperId\": \"5ae0f81025069b54e875691d80f2dbbd84439198\",\n      \"title\": \"Understanding Dataset Distillation via Spectral Filtering\"\n    },\n    {\n      \"paperId\": \"ed343a29ef8e1152cbde39147f4af93c8c31c885\",\n      \"title\": \"Dataset Distillation with Neural Characteristic Function: A Minmax Perspective\"\n    }\n  ],\n  \"prevPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.11782325886059475,\n      \"y\": -0.014489499337869147,\n      \"z\": 0.13909266170761908,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.1628728913618648,\n      \"y\": -0.11889153856182978,\n      \"z\": 0.11584221764211293,\n      \"index\": 1,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.06364510726864028,\n      \"y\": -0.05245475958113947,\n      \"z\": 0.04436013534382017,\n      \"index\": 2,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.17303963805641226,\n      \"y\": -0.01826887714787332,\n      \"z\": 0.24761986887860485,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14432415678483243,\n      \"y\": -0.20440478598955736,\n      \"z\": -0.18356033215029743,\n      \"index\": 4,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": -0.06341159886710368,\n      \"y\": 0.182850027430651,\n      \"z\": -0.10341832360759183,\n      \"index\": 5,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.029568015787392727,\n      \"y\": -0.05579098031356123,\n      \"z\": -0.08353296529655033,\n      \"index\": 6,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.17030656311491754,\n      \"y\": 0.09806343651936783,\n      \"z\": 0.12161041999961723,\n      \"index\": 7,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.0677601710371987,\n      \"y\": 0.21239001361829546,\n      \"z\": 0.002252378723024705,\n      \"index\": 8,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": -0.0462400057660568,\n      \"y\": -0.09766678431239634,\n      \"z\": 0.03043677985517685,\n      \"index\": 9,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.0913000942547181,\n      \"y\": -0.04816718775777932,\n      \"z\": -0.07051935864259923,\n      \"index\": 10,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.0490726545511154,\n      \"y\": 0.02768916238823264,\n      \"z\": -0.04275225128079375,\n      \"index\": 11,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": -0.035494771184504156,\n      \"y\": 0.01171416117854184,\n      \"z\": 0.013366968873453592,\n      \"index\": 12,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.025192282351804453,\n      \"y\": -0.145473489298086,\n      \"z\": -0.0267672133141672,\n      \"index\": 13,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.024416593711720246,\n      \"y\": -0.022999118167969727,\n      \"z\": 0.22054118828123184,\n      \"index\": 14,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.20609868060358574,\n      \"y\": -0.08995654080691573,\n      \"z\": 0.17963983023185345,\n      \"index\": 15,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": -0.24412453639492962,\n      \"y\": -0.1276539910355628,\n      \"z\": 0.03980161343940828,\n      \"index\": 16,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.22021808784772468,\n      \"y\": 0.08076315628555283,\n      \"z\": -0.01994267771205947,\n      \"index\": 17,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.3935838814506611,\n      \"y\": 0.019991746702558197,\n      \"z\": -0.09900681234793562,\n      \"index\": 18,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": -0.26607371148935216,\n      \"y\": -0.13401479877404876,\n      \"z\": -0.16918522998832153,\n      \"index\": 19,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\",\n      \"title\": \"Application of Deep Learning and Transfer Learning Techniques for Medical Image Classification\",\n      \"x\": 0.1844386040570544,\n      \"y\": 0.15223988793649643,\n      \"z\": 0.227204563307068,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\",\n      \"title\": \"Research on image feature extraction and classification based on deep learning\",\n      \"x\": 0.09417750244960996,\n      \"y\": 0.18492440728890153,\n      \"z\": 0.11636561360241372,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\",\n      \"title\": \"Research on the Application of Deep Learning Methods in the Field of Image Classification\",\n      \"x\": 0.05775219547796931,\n      \"y\": 0.1173139499124176,\n      \"z\": 0.1553306537636692,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\",\n      \"title\": \"Review on Image Processing Method based on AI Large Models\",\n      \"x\": 0.26523650160985884,\n      \"y\": 0.06417387036096468,\n      \"z\": 0.0712123700776994,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\",\n      \"title\": \"Analysis of The Role of Deep Learning Models in Image Classification Applications\",\n      \"x\": 0.2053919493262745,\n      \"y\": 0.14662946368823465,\n      \"z\": 0.023637435503685737,\n      \"index\": 24\n    }\n  ]\n}"
  },
  {
    "timestamp": 194427,
    "eventType": "generateFibonacciLatticePositions() called",
    "eventData": "{\n  \"n\": 5,\n  \"center\": {\n    \"_isDirty\": true,\n    \"_x\": 0,\n    \"_y\": 0,\n    \"_z\": 0\n  },\n  \"radius\": 0.2,\n  \"positions\": [\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.007084758760142689,\n      \"_y\": -0.11979067657088584,\n      \"_z\": 0.16000000000000003\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.18226814193376306,\n      \"_y\": 0.01945056389963019,\n      \"_z\": 0.08000000000000002\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.030589332337244216,\n      \"_y\": 0.19764688903992805,\n      \"_z\": 1.2246467991473533e-17\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": -0.1796204557779503,\n      \"_y\": -0.036558061574998774,\n      \"_z\": -0.08\n    },\n    {\n      \"_isDirty\": true,\n      \"_x\": 0.02945874520987503,\n      \"_y\": -0.11632790864904115,\n      \"_z\": -0.16000000000000003\n    }\n  ]\n}"
  },
  {
    "timestamp": 194428,
    "eventType": "createNodes() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.11782325886059475,\n      \"y\": -0.014489499337869147,\n      \"z\": 0.13909266170761908,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.1628728913618648,\n      \"y\": -0.11889153856182978,\n      \"z\": 0.11584221764211293,\n      \"index\": 1,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.06364510726864028,\n      \"y\": -0.05245475958113947,\n      \"z\": 0.04436013534382017,\n      \"index\": 2,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.17303963805641226,\n      \"y\": -0.01826887714787332,\n      \"z\": 0.24761986887860485,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14432415678483243,\n      \"y\": -0.20440478598955736,\n      \"z\": -0.18356033215029743,\n      \"index\": 4,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": -0.06341159886710368,\n      \"y\": 0.182850027430651,\n      \"z\": -0.10341832360759183,\n      \"index\": 5,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.029568015787392727,\n      \"y\": -0.05579098031356123,\n      \"z\": -0.08353296529655033,\n      \"index\": 6,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.17030656311491754,\n      \"y\": 0.09806343651936783,\n      \"z\": 0.12161041999961723,\n      \"index\": 7,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.0677601710371987,\n      \"y\": 0.21239001361829546,\n      \"z\": 0.002252378723024705,\n      \"index\": 8,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": -0.0462400057660568,\n      \"y\": -0.09766678431239634,\n      \"z\": 0.03043677985517685,\n      \"index\": 9,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.0913000942547181,\n      \"y\": -0.04816718775777932,\n      \"z\": -0.07051935864259923,\n      \"index\": 10,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.0490726545511154,\n      \"y\": 0.02768916238823264,\n      \"z\": -0.04275225128079375,\n      \"index\": 11,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": -0.035494771184504156,\n      \"y\": 0.01171416117854184,\n      \"z\": 0.013366968873453592,\n      \"index\": 12,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.025192282351804453,\n      \"y\": -0.145473489298086,\n      \"z\": -0.0267672133141672,\n      \"index\": 13,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.024416593711720246,\n      \"y\": -0.022999118167969727,\n      \"z\": 0.22054118828123184,\n      \"index\": 14,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.20609868060358574,\n      \"y\": -0.08995654080691573,\n      \"z\": 0.17963983023185345,\n      \"index\": 15,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": -0.24412453639492962,\n      \"y\": -0.1276539910355628,\n      \"z\": 0.03980161343940828,\n      \"index\": 16,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.22021808784772468,\n      \"y\": 0.08076315628555283,\n      \"z\": -0.01994267771205947,\n      \"index\": 17,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.3935838814506611,\n      \"y\": 0.019991746702558197,\n      \"z\": -0.09900681234793562,\n      \"index\": 18,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": -0.26607371148935216,\n      \"y\": -0.13401479877404876,\n      \"z\": -0.16918522998832153,\n      \"index\": 19,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\",\n      \"title\": \"Application of Deep Learning and Transfer Learning Techniques for Medical Image Classification\",\n      \"x\": 0.1844386040570544,\n      \"y\": 0.15223988793649643,\n      \"z\": 0.227204563307068,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\",\n      \"title\": \"Research on image feature extraction and classification based on deep learning\",\n      \"x\": 0.09417750244960996,\n      \"y\": 0.18492440728890153,\n      \"z\": 0.11636561360241372,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\",\n      \"title\": \"Research on the Application of Deep Learning Methods in the Field of Image Classification\",\n      \"x\": 0.05775219547796931,\n      \"y\": 0.1173139499124176,\n      \"z\": 0.1553306537636692,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\",\n      \"title\": \"Review on Image Processing Method based on AI Large Models\",\n      \"x\": 0.26523650160985884,\n      \"y\": 0.06417387036096468,\n      \"z\": 0.0712123700776994,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\",\n      \"title\": \"Analysis of The Role of Deep Learning Models in Image Classification Applications\",\n      \"x\": 0.2053919493262745,\n      \"y\": 0.14662946368823465,\n      \"z\": 0.023637435503685737,\n      \"index\": 24\n    },\n    {\n      \"paperId\": \"b77c3594adc3503efc12c69d10061fcf86a01297\",\n      \"title\": \"The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions\",\n      \"x\": 0.007084758760142689,\n      \"y\": -0.11979067657088584,\n      \"z\": 0.16000000000000003,\n      \"index\": 25\n    },\n    {\n      \"paperId\": \"99bfd821693ff6fd7dafbd8aba80794d45b4bd44\",\n      \"title\": \"Efficient Dataset Distillation through Low-Rank Space Sampling\",\n      \"x\": 0.18226814193376306,\n      \"y\": 0.01945056389963019,\n      \"z\": 0.08000000000000002,\n      \"index\": 26\n    },\n    {\n      \"paperId\": \"bb96ea820db5f255f88fd7dda059021063e7c830\",\n      \"title\": \"Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images\",\n      \"x\": -0.030589332337244216,\n      \"y\": 0.19764688903992805,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 27\n    },\n    {\n      \"paperId\": \"5ae0f81025069b54e875691d80f2dbbd84439198\",\n      \"title\": \"Understanding Dataset Distillation via Spectral Filtering\",\n      \"x\": -0.1796204557779503,\n      \"y\": -0.036558061574998774,\n      \"z\": -0.08,\n      \"index\": 28\n    },\n    {\n      \"paperId\": \"ed343a29ef8e1152cbde39147f4af93c8c31c885\",\n      \"title\": \"Dataset Distillation with Neural Characteristic Function: A Minmax Perspective\",\n      \"x\": 0.02945874520987503,\n      \"y\": -0.11632790864904115,\n      \"z\": -0.16000000000000003,\n      \"index\": 29\n    }\n  ]\n}"
  },
  {
    "timestamp": 194448,
    "eventType": "sendAllNodesData() called",
    "eventData": "{\n  \"paperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.11782325886059475,\n      \"y\": -0.014489499337869147,\n      \"z\": 0.13909266170761908,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.1628728913618648,\n      \"y\": -0.11889153856182978,\n      \"z\": 0.11584221764211293,\n      \"index\": 1,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.06364510726864028,\n      \"y\": -0.05245475958113947,\n      \"z\": 0.04436013534382017,\n      \"index\": 2,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.17303963805641226,\n      \"y\": -0.01826887714787332,\n      \"z\": 0.24761986887860485,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14432415678483243,\n      \"y\": -0.20440478598955736,\n      \"z\": -0.18356033215029743,\n      \"index\": 4,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": -0.06341159886710368,\n      \"y\": 0.182850027430651,\n      \"z\": -0.10341832360759183,\n      \"index\": 5,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.029568015787392727,\n      \"y\": -0.05579098031356123,\n      \"z\": -0.08353296529655033,\n      \"index\": 6,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.17030656311491754,\n      \"y\": 0.09806343651936783,\n      \"z\": 0.12161041999961723,\n      \"index\": 7,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.0677601710371987,\n      \"y\": 0.21239001361829546,\n      \"z\": 0.002252378723024705,\n      \"index\": 8,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": -0.0462400057660568,\n      \"y\": -0.09766678431239634,\n      \"z\": 0.03043677985517685,\n      \"index\": 9,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.0913000942547181,\n      \"y\": -0.04816718775777932,\n      \"z\": -0.07051935864259923,\n      \"index\": 10,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.0490726545511154,\n      \"y\": 0.02768916238823264,\n      \"z\": -0.04275225128079375,\n      \"index\": 11,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": -0.035494771184504156,\n      \"y\": 0.01171416117854184,\n      \"z\": 0.013366968873453592,\n      \"index\": 12,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.025192282351804453,\n      \"y\": -0.145473489298086,\n      \"z\": -0.0267672133141672,\n      \"index\": 13,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.024416593711720246,\n      \"y\": -0.022999118167969727,\n      \"z\": 0.22054118828123184,\n      \"index\": 14,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.20609868060358574,\n      \"y\": -0.08995654080691573,\n      \"z\": 0.17963983023185345,\n      \"index\": 15,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": -0.24412453639492962,\n      \"y\": -0.1276539910355628,\n      \"z\": 0.03980161343940828,\n      \"index\": 16,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.22021808784772468,\n      \"y\": 0.08076315628555283,\n      \"z\": -0.01994267771205947,\n      \"index\": 17,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.3935838814506611,\n      \"y\": 0.019991746702558197,\n      \"z\": -0.09900681234793562,\n      \"index\": 18,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": -0.26607371148935216,\n      \"y\": -0.13401479877404876,\n      \"z\": -0.16918522998832153,\n      \"index\": 19,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\",\n      \"title\": \"Application of Deep Learning and Transfer Learning Techniques for Medical Image Classification\",\n      \"x\": 0.1844386040570544,\n      \"y\": 0.15223988793649643,\n      \"z\": 0.227204563307068,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\",\n      \"title\": \"Research on image feature extraction and classification based on deep learning\",\n      \"x\": 0.09417750244960996,\n      \"y\": 0.18492440728890153,\n      \"z\": 0.11636561360241372,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\",\n      \"title\": \"Research on the Application of Deep Learning Methods in the Field of Image Classification\",\n      \"x\": 0.05775219547796931,\n      \"y\": 0.1173139499124176,\n      \"z\": 0.1553306537636692,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\",\n      \"title\": \"Review on Image Processing Method based on AI Large Models\",\n      \"x\": 0.26523650160985884,\n      \"y\": 0.06417387036096468,\n      \"z\": 0.0712123700776994,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\",\n      \"title\": \"Analysis of The Role of Deep Learning Models in Image Classification Applications\",\n      \"x\": 0.2053919493262745,\n      \"y\": 0.14662946368823465,\n      \"z\": 0.023637435503685737,\n      \"index\": 24\n    },\n    {\n      \"paperId\": \"b77c3594adc3503efc12c69d10061fcf86a01297\",\n      \"title\": \"The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions\",\n      \"x\": 0.007084758760142689,\n      \"y\": -0.11979067657088584,\n      \"z\": 0.16000000000000003,\n      \"index\": 25\n    },\n    {\n      \"paperId\": \"99bfd821693ff6fd7dafbd8aba80794d45b4bd44\",\n      \"title\": \"Efficient Dataset Distillation through Low-Rank Space Sampling\",\n      \"x\": 0.18226814193376306,\n      \"y\": 0.01945056389963019,\n      \"z\": 0.08000000000000002,\n      \"index\": 26\n    },\n    {\n      \"paperId\": \"bb96ea820db5f255f88fd7dda059021063e7c830\",\n      \"title\": \"Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images\",\n      \"x\": -0.030589332337244216,\n      \"y\": 0.19764688903992805,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 27\n    },\n    {\n      \"paperId\": \"5ae0f81025069b54e875691d80f2dbbd84439198\",\n      \"title\": \"Understanding Dataset Distillation via Spectral Filtering\",\n      \"x\": -0.1796204557779503,\n      \"y\": -0.036558061574998774,\n      \"z\": -0.08,\n      \"index\": 28\n    },\n    {\n      \"paperId\": \"ed343a29ef8e1152cbde39147f4af93c8c31c885\",\n      \"title\": \"Dataset Distillation with Neural Characteristic Function: A Minmax Perspective\",\n      \"x\": 0.02945874520987503,\n      \"y\": -0.11632790864904115,\n      \"z\": -0.16000000000000003,\n      \"index\": 29\n    }\n  ]\n}"
  },
  {
    "timestamp": 194453,
    "eventType": "generateLinkData() finished",
    "eventData": "{\n  \"newLinkData\": {\n    \"citationLinkData\": [\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"b77c3594adc3503efc12c69d10061fcf86a01297\",\n        \"target\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n      },\n      {\n        \"source\": \"b77c3594adc3503efc12c69d10061fcf86a01297\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      }\n    ],\n    \"recommendationLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"b77c3594adc3503efc12c69d10061fcf86a01297\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"99bfd821693ff6fd7dafbd8aba80794d45b4bd44\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"bb96ea820db5f255f88fd7dda059021063e7c830\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"5ae0f81025069b54e875691d80f2dbbd84439198\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"ed343a29ef8e1152cbde39147f4af93c8c31c885\"\n      }\n    ],\n    \"authorLinkData\": [\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"bb96ea820db5f255f88fd7dda059021063e7c830\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"bb96ea820db5f255f88fd7dda059021063e7c830\"\n      },\n      {\n        \"source\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"target\": \"bb96ea820db5f255f88fd7dda059021063e7c830\"\n      },\n      {\n        \"source\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n        \"target\": \"bb96ea820db5f255f88fd7dda059021063e7c830\"\n      },\n      {\n        \"source\": \"bb96ea820db5f255f88fd7dda059021063e7c830\",\n        \"target\": \"5ae0f81025069b54e875691d80f2dbbd84439198\"\n      },\n      {\n        \"source\": \"bb96ea820db5f255f88fd7dda059021063e7c830\",\n        \"target\": \"5ae0f81025069b54e875691d80f2dbbd84439198\"\n      }\n    ],\n    \"userLinkData\": [\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n        \"target\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"ecbee484d208d406ab191623ddf6e52e5817c356\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\"\n      },\n      {\n        \"source\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n        \"target\": \"e5774b4ff9e368252562b711fdc1f7222350c841\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\"\n      },\n      {\n        \"source\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"357e28348a770052ff9b048ee3cb61be388fac21\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\"\n      },\n      {\n        \"source\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n        \"target\": \"59745da29acc51d07425f7a4deb244e2722ba56d\"\n      },\n      {\n        \"source\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n        \"target\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\"\n      },\n      {\n        \"source\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      },\n      {\n        \"source\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n        \"target\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\"\n      }\n    ]\n  }\n}"
  },
  {
    "timestamp": 194453,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 194454,
    "eventType": "addPapersToGraph() finished",
    "eventData": "{\n  \"newPapers\": [\n    {\n      \"paperId\": \"b77c3594adc3503efc12c69d10061fcf86a01297\",\n      \"title\": \"The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions\",\n      \"x\": 0.007084758760142689,\n      \"y\": -0.11979067657088584,\n      \"z\": 0.16000000000000003,\n      \"index\": 25\n    },\n    {\n      \"paperId\": \"99bfd821693ff6fd7dafbd8aba80794d45b4bd44\",\n      \"title\": \"Efficient Dataset Distillation through Low-Rank Space Sampling\",\n      \"x\": 0.18226814193376306,\n      \"y\": 0.01945056389963019,\n      \"z\": 0.08000000000000002,\n      \"index\": 26\n    },\n    {\n      \"paperId\": \"bb96ea820db5f255f88fd7dda059021063e7c830\",\n      \"title\": \"Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images\",\n      \"x\": -0.030589332337244216,\n      \"y\": 0.19764688903992805,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 27\n    },\n    {\n      \"paperId\": \"5ae0f81025069b54e875691d80f2dbbd84439198\",\n      \"title\": \"Understanding Dataset Distillation via Spectral Filtering\",\n      \"x\": -0.1796204557779503,\n      \"y\": -0.036558061574998774,\n      \"z\": -0.08,\n      \"index\": 28\n    },\n    {\n      \"paperId\": \"ed343a29ef8e1152cbde39147f4af93c8c31c885\",\n      \"title\": \"Dataset Distillation with Neural Characteristic Function: A Minmax Perspective\",\n      \"x\": 0.02945874520987503,\n      \"y\": -0.11632790864904115,\n      \"z\": -0.16000000000000003,\n      \"index\": 29\n    }\n  ],\n  \"currPaperData\": [\n    {\n      \"paperId\": \"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\n      \"title\": \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n      \"x\": 0.11782325886059475,\n      \"y\": -0.014489499337869147,\n      \"z\": 0.13909266170761908,\n      \"index\": 0,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"0748ca9a1e35fccdf89a62022f4c2b6246d6dd81\",\n      \"title\": \"Number Recognition Through Color Distortion Using Convolutional Neural Networks\",\n      \"x\": 0.1628728913618648,\n      \"y\": -0.11889153856182978,\n      \"z\": 0.11584221764211293,\n      \"index\": 1,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"42202cadb372e80b229c96f2670cd141d0d2d01b\",\n      \"title\": \"KAN-Mixers: a new deep learning architecture for image classification\",\n      \"x\": 0.06364510726864028,\n      \"y\": -0.05245475958113947,\n      \"z\": 0.04436013534382017,\n      \"index\": 2,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"613a1791d1e7b8c74ed9d482951c8c2e9e90f5ee\",\n      \"title\": \"Exploration of hyperparameter tuning in handwritten digit recognition datasets using CNN\",\n      \"x\": 0.17303963805641226,\n      \"y\": -0.01826887714787332,\n      \"z\": 0.24761986887860485,\n      \"index\": 3,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"ecbee484d208d406ab191623ddf6e52e5817c356\",\n      \"title\": \"Privacy Preserving Properties of Vision Classifiers\",\n      \"x\": 0.14432415678483243,\n      \"y\": -0.20440478598955736,\n      \"z\": -0.18356033215029743,\n      \"index\": 4,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"fcb82fa7d8a69c22068ff3b79acf1d006fc20b9b\",\n      \"title\": \"Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization\",\n      \"x\": -0.06341159886710368,\n      \"y\": 0.182850027430651,\n      \"z\": -0.10341832360759183,\n      \"index\": 5,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"f854ab4b025fbdae16aadbeeb53d8180fd598a44\",\n      \"title\": \"Elastic Representation: Mitigating Spurious Correlations for Group Robustness\",\n      \"x\": -0.029568015787392727,\n      \"y\": -0.05579098031356123,\n      \"z\": -0.08353296529655033,\n      \"index\": 6,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"9976cbe6d10fef030b81e7f6cc79ac099f1d4fb0\",\n      \"title\": \"Advancements in Image Classification: From Machine Learning to Deep Learning\",\n      \"x\": 0.17030656311491754,\n      \"y\": 0.09806343651936783,\n      \"z\": 0.12161041999961723,\n      \"index\": 7,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"3bbbe6f24a4f4c65ff41ad9eb221bc7c9d6e020f\",\n      \"title\": \"Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation\",\n      \"x\": -0.0677601710371987,\n      \"y\": 0.21239001361829546,\n      \"z\": 0.002252378723024705,\n      \"index\": 8,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"3e0f8ee062a1d59929e7304f88adfd34c7ee64a6\",\n      \"title\": \"Post-hoc Spurious Correlation Neutralization with Single-Weight Fictitious Class Unlearning\",\n      \"x\": -0.0462400057660568,\n      \"y\": -0.09766678431239634,\n      \"z\": 0.03043677985517685,\n      \"index\": 9,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"357e28348a770052ff9b048ee3cb61be388fac21\",\n      \"title\": \"Boosting Adversarial Robustness and Generalization with Structural Prior\",\n      \"x\": 0.0913000942547181,\n      \"y\": -0.04816718775777932,\n      \"z\": -0.07051935864259923,\n      \"index\": 10,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"99c93a1eb91e498a9ebc53ecf547b7fa62df408a\",\n      \"title\": \"FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups\",\n      \"x\": 0.0490726545511154,\n      \"y\": 0.02768916238823264,\n      \"z\": -0.04275225128079375,\n      \"index\": 11,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"59745da29acc51d07425f7a4deb244e2722ba56d\",\n      \"title\": \"Enhancing Classification Models With Sophisticated Counterfactual Images\",\n      \"x\": -0.035494771184504156,\n      \"y\": 0.01171416117854184,\n      \"z\": 0.013366968873453592,\n      \"index\": 12,\n      \"clusterName\": \"Robustness and Generalization in Deep Learning\"\n    },\n    {\n      \"paperId\": \"e5774b4ff9e368252562b711fdc1f7222350c841\",\n      \"title\": \"Deep Learning Meets Oversampling: A Learning Framework to Handle Imbalanced Classification\",\n      \"x\": 0.025192282351804453,\n      \"y\": -0.145473489298086,\n      \"z\": -0.0267672133141672,\n      \"index\": 13,\n      \"clusterName\": \"Privacy and Bias in Machine Learning\"\n    },\n    {\n      \"paperId\": \"0bc9cdc5db3c2681d27990d644719a73d7963ce1\",\n      \"title\": \"Small-Scale Dual Path Network for Image Classification and Machine Learning Applications to Color Quantization\",\n      \"x\": 0.024416593711720246,\n      \"y\": -0.022999118167969727,\n      \"z\": 0.22054118828123184,\n      \"index\": 14,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"1d327f3648a07de8efa38ef8cbd8f7bd6ce8b8bc\",\n      \"title\": \"VERITAS AI: CIFAR-10 IMAGE CLASSIFICATION\",\n      \"x\": 0.20609868060358574,\n      \"y\": -0.08995654080691573,\n      \"z\": 0.17963983023185345,\n      \"index\": 15,\n      \"clusterName\": \"Image Classification and Deep Learning\"\n    },\n    {\n      \"paperId\": \"d20758d3e8238f48cf0f5e05c7171af64b3c4e7a\",\n      \"title\": \"Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural Language Understanding\",\n      \"x\": -0.24412453639492962,\n      \"y\": -0.1276539910355628,\n      \"z\": 0.03980161343940828,\n      \"index\": 16,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"7f0b8d00fec82c6c1110f70863a4285af62ba26e\",\n      \"title\": \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?\",\n      \"x\": -0.22021808784772468,\n      \"y\": 0.08076315628555283,\n      \"z\": -0.01994267771205947,\n      \"index\": 17,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"4ec64d1554853ddb678cef301acf9f3feb59002d\",\n      \"title\": \"Self-supervised Dataset Distillation: A Good Compression Is All You Need\",\n      \"x\": -0.3935838814506611,\n      \"y\": 0.019991746702558197,\n      \"z\": -0.09900681234793562,\n      \"index\": 18,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"c185a8679f13027e6c03e07ea27dbf302020d6e6\",\n      \"title\": \"Multisize Dataset Condensation\",\n      \"x\": -0.26607371148935216,\n      \"y\": -0.13401479877404876,\n      \"z\": -0.16918522998832153,\n      \"index\": 19,\n      \"clusterName\": \"Dataset Distillation and Pruning\"\n    },\n    {\n      \"paperId\": \"aa58d096793f7cb532bb7859009c0dfb34176fbc\",\n      \"title\": \"Application of Deep Learning and Transfer Learning Techniques for Medical Image Classification\",\n      \"x\": 0.1844386040570544,\n      \"y\": 0.15223988793649643,\n      \"z\": 0.227204563307068,\n      \"index\": 20\n    },\n    {\n      \"paperId\": \"7c66aadc0999e8d1a85f52c1b914784031f2588b\",\n      \"title\": \"Research on image feature extraction and classification based on deep learning\",\n      \"x\": 0.09417750244960996,\n      \"y\": 0.18492440728890153,\n      \"z\": 0.11636561360241372,\n      \"index\": 21\n    },\n    {\n      \"paperId\": \"967c8f90ee2a1ae30dc9a30d0cd6f84183ccc269\",\n      \"title\": \"Research on the Application of Deep Learning Methods in the Field of Image Classification\",\n      \"x\": 0.05775219547796931,\n      \"y\": 0.1173139499124176,\n      \"z\": 0.1553306537636692,\n      \"index\": 22\n    },\n    {\n      \"paperId\": \"f79c90003e87a39ca97f06f3d4a9719e5289bf29\",\n      \"title\": \"Review on Image Processing Method based on AI Large Models\",\n      \"x\": 0.26523650160985884,\n      \"y\": 0.06417387036096468,\n      \"z\": 0.0712123700776994,\n      \"index\": 23\n    },\n    {\n      \"paperId\": \"4941a4ffdb3f39feea11061cb01db22f9b85814d\",\n      \"title\": \"Analysis of The Role of Deep Learning Models in Image Classification Applications\",\n      \"x\": 0.2053919493262745,\n      \"y\": 0.14662946368823465,\n      \"z\": 0.023637435503685737,\n      \"index\": 24\n    },\n    {\n      \"paperId\": \"b77c3594adc3503efc12c69d10061fcf86a01297\",\n      \"title\": \"The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions\",\n      \"x\": 0.007084758760142689,\n      \"y\": -0.11979067657088584,\n      \"z\": 0.16000000000000003,\n      \"index\": 25\n    },\n    {\n      \"paperId\": \"99bfd821693ff6fd7dafbd8aba80794d45b4bd44\",\n      \"title\": \"Efficient Dataset Distillation through Low-Rank Space Sampling\",\n      \"x\": 0.18226814193376306,\n      \"y\": 0.01945056389963019,\n      \"z\": 0.08000000000000002,\n      \"index\": 26\n    },\n    {\n      \"paperId\": \"bb96ea820db5f255f88fd7dda059021063e7c830\",\n      \"title\": \"Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images\",\n      \"x\": -0.030589332337244216,\n      \"y\": 0.19764688903992805,\n      \"z\": 1.2246467991473533e-17,\n      \"index\": 27\n    },\n    {\n      \"paperId\": \"5ae0f81025069b54e875691d80f2dbbd84439198\",\n      \"title\": \"Understanding Dataset Distillation via Spectral Filtering\",\n      \"x\": -0.1796204557779503,\n      \"y\": -0.036558061574998774,\n      \"z\": -0.08,\n      \"index\": 28\n    },\n    {\n      \"paperId\": \"ed343a29ef8e1152cbde39147f4af93c8c31c885\",\n      \"title\": \"Dataset Distillation with Neural Characteristic Function: A Minmax Perspective\",\n      \"x\": 0.02945874520987503,\n      \"y\": -0.11632790864904115,\n      \"z\": -0.16000000000000003,\n      \"index\": 29\n    }\n  ]\n}"
  },
  {
    "timestamp": 194454,
    "eventType": "setLinkType() called",
    "eventData": "{\n  \"currLinkType\": \"recommendation\",\n  \"newLinkType\": \"recommendation\"\n}"
  },
  {
    "timestamp": 194454,
    "eventType": "setFullScreenUIText()",
    "eventData": "{\n  \"text\": \"Link Type recommendation\"\n}"
  },
  {
    "timestamp": 194454,
    "eventType": "createLinks() called",
    "eventData": "{\n  \"linkType\": \"recommendation\"\n}"
  }
]